{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f9866c",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e87a4",
   "metadata": {},
   "source": [
    "Steel is one of the most important materials in existence. From bridges to buildings to cars, steel is considered the material of choice due to its cost to strength ratio. In the field of steelmaking, it could be useful to metallurgists to have an estimate for the strength of a grade of steel prior to it being manufactured. In this project, I create a regression model that estimates the strength of a grade of steel solely based on its constituent elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0b7c7",
   "metadata": {},
   "source": [
    "## 1.0 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f4a50",
   "metadata": {},
   "source": [
    "Steel chemistry data was collected from the machine learning data repository Kaggle:\n",
    "- [Steel chemistry data](https://www.kaggle.com/datasets/rohannemade/mechanical-properties-of-low-alloy-steels?resource=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ea263",
   "metadata": {},
   "source": [
    "It consists of 915 samples each with an elemental composition and corresponding strength metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791ac07",
   "metadata": {},
   "source": [
    "Here is an example of the dataset ![example](https://i.imgur.com/VzEnLJl.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3e329",
   "metadata": {},
   "source": [
    "## 2.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b253c8",
   "metadata": {},
   "source": [
    "Various features needed to be dropped, Alloy code wasn't useful in this context, neither was Carbon equivalent (Ceq) since the chemistry was known. Columns were then renamed. 0.2% Proof Stress is another name for Yield strength and was renamed accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e033438",
   "metadata": {},
   "source": [
    "There were no null values, however there was one unusually high strength property observation which was dropped. Additionally the temperatures the samples were pulled ranged from 27degC to 650degC. A cutoff of 450degC was chosen since most steel applications don't reach temperatures that high. 450degC is still unusual, however I couldn't risk removing too much data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64939270",
   "metadata": {},
   "source": [
    "## 3.0 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aed9eb",
   "metadata": {},
   "source": [
    "The first step of EDA was to look for general patterns in the data therefore a heatmap was created\n",
    "![example](https://i.imgur.com/aVKbW2z.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449ea7e",
   "metadata": {},
   "source": [
    "It can be seen that temperature is negatively correlated with both Yield and Tensile strength which is expected. The higher the temperature, the weaker a metal gets. Correlations between the other strength variables are all expected as well, however we want to find relationships between the elements and strength!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfef334",
   "metadata": {},
   "source": [
    "The elements that stick out are Vanadium (v), Molybnenum (mo), Nickel (ni) and Manganese (mn). Surprisingly Carbon doesn't have a huge role to play in determining strength. There are no elements that contribute significantly negatively to steel strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65672259",
   "metadata": {},
   "source": [
    "The target variable 0.2% Proof Strength, otherwise known as Yield Strength was chosen to be the target variable in this project since it is the most important strength parameter. It determines when a material will permanently deform under stress which usually one would try to avoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522bd427",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/xLtVcHU.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092feba",
   "metadata": {},
   "source": [
    "## 4.0 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5734c",
   "metadata": {},
   "source": [
    "The remaining data was split into training and test sets, and the X datasets were transformed using a Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3fda76",
   "metadata": {},
   "source": [
    "## 5.0 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4a875",
   "metadata": {},
   "source": [
    "PyCaret is a low-code machine learning library that automates the model selection process. It scores various different models using k-fold cross-validation and returns a hierarchy of the best models. Using this library, the top 3 models were chosen. The models were put into an ensemble Voting Regressor which returns the average of the weighted predictions of each model. A summary of the models tested is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29321b",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/8ahSfIY.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e68dc3",
   "metadata": {},
   "source": [
    "The CatBoost Regressor, Light Gradient Boosting Machine and Extra Trees Regressor were chosen to be input into the Voting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63a80c",
   "metadata": {},
   "source": [
    "### 5.1 Explaining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a4810",
   "metadata": {},
   "source": [
    "The CatBoost Regressor is a relatively new machine learning model. This model is an evolution of decision trees and gradient boosting and is best at working with categorical data. In this instance it works well with numeric values as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5660dc",
   "metadata": {},
   "source": [
    "The LightGBM is similar to XGBoost. The main difference is in how the trees grows. In LightGBM trees are grown vertically or leaf-wise, whereas in XGBoost, leaves are grown level-wise. This distinction results in LightGBM being faster, but it does tend to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fd52d",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/GAmIotY.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bac7e2",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/Ayc3wdn.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9e1ab",
   "metadata": {},
   "source": [
    "\tExtra Trees models are also an ensemble decision tree model like Random Forest models. The main difference between them is that they do not bootstrap the data to train on each tree. Instead, they train each tree on the entire dataset while splitting randomly, not to reduce loss like Random Forest Regressors. In addition, splitting is random in the Extra Trees, whereas the split is based on the applied criterion in Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f2e7d",
   "metadata": {},
   "source": [
    "### 5.2 Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff65c74",
   "metadata": {},
   "source": [
    "#### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e4fce",
   "metadata": {},
   "source": [
    "![catboost](https://i.imgur.com/LMVC6v8.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea0af3",
   "metadata": {},
   "source": [
    "#### Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce394a31",
   "metadata": {},
   "source": [
    "![lgbm](https://i.imgur.com/o0TEnw9.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63514c21",
   "metadata": {},
   "source": [
    "#### Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2fe898",
   "metadata": {},
   "source": [
    "![xt](https://i.imgur.com/wUDoH30.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30193a96",
   "metadata": {},
   "source": [
    "There are a few elements that are commonly major contributors in these 3 models, Vanadium (v), Manganese (mn) and Nickel (ni). Temperature is also a major contributor. Another interesting feature is that the LGBM model seems to take more input from the other elements in its prediction, whereas the other two models rely heavily on the first 3 or 4 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed518fdd",
   "metadata": {},
   "source": [
    "As it can be seen, Vanadium is the element which contributes most to strength. Interestingly enough, most of the samples didn't contain this element as it can be seen in the histogram below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390925b",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/ENjHGIH.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dac5f",
   "metadata": {},
   "source": [
    "Vanadium forms secondary carbide phases when added to steel. It reduces the grain sizes of the steel thereby reducing the spread of dislocations. Basically, this reduction in grain size prevents the physical movement of the atoms making the steel more resistant to stress. This reduction is evident in the increase in Yield Strength. This process is commonly referred to as grain boundary strengthening [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c5641",
   "metadata": {},
   "source": [
    "Nickel and Manganese are also elements that strengthens steel via grain-boundary strengthening [2] [3]. However, Manganese also contributes to the formation of another phase in the steel known as austenite which interestingly also makes it more ductile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d18d0",
   "metadata": {},
   "source": [
    "Temperature plays a crucial role in reducing Yield strength. An increase in temperature makes the movement of dislocations in most metals since atoms are jostling much more. This makes them less resilient to stress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd4434",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb2fab",
   "metadata": {},
   "source": [
    "Here are the metrics of the untuned and tuned models trained on the training set, and tested on the training set, validation set, test set and cross-validated on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b132d",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/lUtSSES.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1ecab",
   "metadata": {},
   "source": [
    "The untuned Cat Boost Regressor was chosen to be included in the final Voting Regressor model since it performed better than the untuned regressor. Both the tuned Light Gradient Boosting Machine and Extra Trees Regressor performed better than their untuned counterparts. They all tended to overfit on the training sets, but still performed admirally on the other sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f0150",
   "metadata": {},
   "source": [
    "## 6.0 Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd8ef2",
   "metadata": {},
   "source": [
    "As mentioned above, a Voting Regressor was chosen to combine all models. In this meta-model, a weighted average of each model's predictions is used to form a final prediction. The algorithm is shown below:,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f868d9f",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/UIQjlaL.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402dcbd",
   "metadata": {},
   "source": [
    "The most accurate weights for the Cat Boost Regressor, Light Gradient Boosting Machine and Extra Trees Regressor had optimum weights of 0.7, 0.1 and 0.2 respectively. The final metrics table is shows below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4fbc01",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/T9abaDo.png[/img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a633a",
   "metadata": {},
   "source": [
    "## 7.0 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd31e4",
   "metadata": {},
   "source": [
    "It seems as though the Voting Regressor is less prone to overfitting and thus resulted in higher scores on the test, validation and entire datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20dc2c",
   "metadata": {},
   "source": [
    "This model does do quite a good job in predicting steel strength. Surprisingly, data on the samples' microstructure resulting from its heat treatment was not needed in this analysis. This data is probably representative of a certain set of steel samples and may not be generalizable to other steel with different chemistries and heat treatments. Additionally, the inclusion of temperature in this analysis might not be useful in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aed4f9",
   "metadata": {},
   "source": [
    "## 8.0 Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c0ae0",
   "metadata": {},
   "source": [
    "[1] Applications of vanadium in the steel industry. (2021). Vanadium, 267–332. https://doi.org/10.1016/b978-0-12-818898-9.00011-5 \n",
    "<br>\n",
    "[2] Applications of vanadium in the steel industry. (2021). Vanadium, 267–332. https://doi.org/10.1016/b978-0-12-818898-9.00011-5 \n",
    "<br>\n",
    "[3] Kaar, S., Krizan, D., Schneider, R., Béal, C., &amp; Sommitsch, C. (2019). Effect of manganese on the structure-properties relationship of cold rolled AHSS treated by a quenching and partitioning process. Metals, 9(10), 1122. https://doi.org/10.3390/met9101122 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
