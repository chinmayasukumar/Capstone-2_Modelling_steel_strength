{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d173d6-6c32-4181-bcfe-87c602be0044",
   "metadata": {},
   "source": [
    "# 05 - Generating Chemistries using VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e821d-cd9b-4d9b-ac33-056ae876bec7",
   "metadata": {},
   "source": [
    "## 1.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd32a6c-4a84-4d84-9a56-0007e7d9cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb75dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1002adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, cross_validate, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f2af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "600558db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Checkpoint' from 'ray.air' (/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/ray/air/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04 - Generating Chemistries using VAE.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m \u001b[39mimport\u001b[39;00m tune\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mair\u001b[39;00m \u001b[39mimport\u001b[39;00m Checkpoint, sessionpp \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschedulers\u001b[39;00m \u001b[39mimport\u001b[39;00m ASHAScheduler\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Checkpoint' from 'ray.air' (/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/ray/air/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.air import Checkpoint, sessionpp \n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030e31b",
   "metadata": {},
   "source": [
    "### 2.1 Creating Training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ecb1f",
   "metadata": {},
   "source": [
    "## 1.1 Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c086bf37-4682-49a2-be14-e7454a760b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/data/raw/steel_clean_final.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a3efbc-ddb6-422f-9a0b-675cce014359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>si</th>\n",
       "      <th>mn</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>ni</th>\n",
       "      <th>cr</th>\n",
       "      <th>mo</th>\n",
       "      <th>cu</th>\n",
       "      <th>v</th>\n",
       "      <th>al</th>\n",
       "      <th>n</th>\n",
       "      <th>nb+ta</th>\n",
       "      <th>temp</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      c    si    mn      p      s     ni    cr    mo    cu    v     al  \\\n",
       "0  0.12  0.36  0.52  0.009  0.003  0.089  0.97  0.61  0.04  0.0  0.003   \n",
       "1  0.12  0.36  0.52  0.009  0.003  0.089  0.97  0.61  0.04  0.0  0.003   \n",
       "2  0.12  0.36  0.52  0.009  0.003  0.089  0.97  0.61  0.04  0.0  0.003   \n",
       "3  0.12  0.36  0.52  0.009  0.003  0.089  0.97  0.61  0.04  0.0  0.003   \n",
       "4  0.12  0.36  0.52  0.009  0.003  0.089  0.97  0.61  0.04  0.0  0.003   \n",
       "\n",
       "        n  nb+ta  temp  yield  \n",
       "0  0.0066    0.0    27    342  \n",
       "1  0.0066    0.0   100    338  \n",
       "2  0.0066    0.0   200    337  \n",
       "3  0.0066    0.0   300    346  \n",
       "4  0.0066    0.0   400    316  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5661dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for X\n",
    "X = data.iloc[:,:14]\n",
    "\n",
    "# Target is yield strength\n",
    "y = data.iloc[:,14]\n",
    "\n",
    "# SPlitting to train and test & validation sets\n",
    "X_train, X_test_val, _,  y_test_val = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# Splitting to test and validation sets\n",
    "X_test, X_val, y_test, _ = train_test_split(X_test_val, y_test_val, test_size=0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1796d370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((432, 14), (111, 14), (75, 14))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the shapes of the train and test sets\n",
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b6093",
   "metadata": {},
   "source": [
    "## 2.0 Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9600c",
   "metadata": {},
   "source": [
    "### 2.1 Creating Training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fcc5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the data loading\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "train_dataset = TensorDataset(X_train_tensor, X_train_tensor) # creating datset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a12bd",
   "metadata": {},
   "source": [
    "### 2.2 Creating VAE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2a17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, num_epochs, lr):\n",
    "\n",
    "    # Define the optimizer and criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            input_data = data[0]  # Assuming the input data is the first element in the batch\n",
    "            target_data = data[0]  # Assuming the target data is the second element in the batch\n",
    "            input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "            target_data = torch.tensor(target_data, dtype=torch.float32)\n",
    "            recon_batch, mu, logvar = model(input_data)\n",
    "            loss = criterion(recon_batch, target_data) + 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Append the average loss for the epoch to the train_losses list\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        \n",
    "    \n",
    "        # print('Epoch: {}, Loss: {:.6f}'.format(epoch+1, train_loss / len(train_loader)))\n",
    "\n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600652f5",
   "metadata": {},
   "source": [
    "### 2.3 Creating Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664eecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating VAE\n",
    "\n",
    "def evaluate_vae(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "            input_data = data[0]\n",
    "            target_data = data[0]\n",
    "            input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "            target_data = torch.tensor(target_data, dtype=torch.float32)\n",
    "            recon_batch, _, _ = model(input_data)\n",
    "            loss = criterion(recon_batch, target_data)\n",
    "            total_loss += loss.item() * input_data.size(0)\n",
    "            num_samples += input_data.size(0)\n",
    "\n",
    "    average_loss = total_loss / num_samples\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fded6",
   "metadata": {},
   "source": [
    "## 3.0 Model Training & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef7575",
   "metadata": {},
   "source": [
    "### 3.1 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d219c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation sets\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "val_dataset = TensorDataset(X_val_tensor, X_val_tensor) \n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a0b04",
   "metadata": {},
   "source": [
    "### 3.2 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ebafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'batch_size': [32, 64, 128], 'lr': [0.001, 0.01, 0.05,  0.1], 'latent_dim': [2, 4, 8, 10, 12], 'n_nodes': [16, 32, 64]}\n",
    "\n",
    "grid = RandomizedSearchCV(VAE, param_distributions=param_grid, n_iter=10, cv=3, random_state=123, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90913dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <class '__main__.VAE'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04 - Generating Chemistries using VAE.ipynb Cell 25\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train_tensor, X_train_tensor)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:793\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    791\u001b[0m     scorers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring\n\u001b[1;32m    792\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 793\u001b[0m     scorers \u001b[39m=\u001b[39m check_scoring(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring)\n\u001b[1;32m    794\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m     scorers \u001b[39m=\u001b[39m _check_multimetric_scoring(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:448\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determine scorer from user options.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \n\u001b[1;32m    424\u001b[0m \u001b[39mA TypeError will be thrown if the estimator cannot be scored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m    ``scorer(estimator, X, y)``.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    449\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mestimator should be an estimator implementing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method, \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m was passed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m         \u001b[39m%\u001b[39m estimator\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scoring, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m get_scorer(scoring)\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <class '__main__.VAE'> was passed"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train_tensor, X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6288a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_70230/931870296.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32)\n",
      "/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_70230/931870296.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_data = torch.tensor(target_data, dtype=torch.float32)\n",
      "/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_70230/87308926.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32)\n",
      "/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_70230/87308926.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_data = torch.tensor(target_data, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04 - Generating Chemistries using VAE.ipynb Cell 23\u001b[0m line \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_losses \u001b[39m=\u001b[39m train_vae(model, train_loader, \u001b[39m150\u001b[39;49m, lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m val_loss \u001b[39m=\u001b[39m evaluate_vae(model, val_loader, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m losses[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_losses)\n",
      "\u001b[1;32m/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04 - Generating Chemistries using VAE.ipynb Cell 23\u001b[0m line \u001b[0;36mtrain_vae\u001b[0;34m(model, train_loader, num_epochs, lr)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(recon_batch, target_data) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msum(logvar\u001b[39m.\u001b[39mexp() \u001b[39m-\u001b[39m logvar \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m mu\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Append the average loss for the epoch to the train_losses list\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:432\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    434\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    436\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.005]\n",
    "n_nodes = [16, 32, 64]\n",
    "latent_dims = [5, 10, 20, 30]\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_hyperparameters = {}\n",
    "losses = {'lr':[], 'n_nodes':[], 'latent_dims':[], 'train_loss':[], 'val_loss':[]}\n",
    "\n",
    "for lr, nodes, latent_dim in itertools.product(learning_rates, n_nodes, latent_dims):\n",
    "    model = VAE(latent_dim=latent_dim, n_nodes=nodes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    train_losses = train_vae(model, train_loader, 150, lr)\n",
    "    val_loss = evaluate_vae(model, val_loader, criterion)\n",
    "\n",
    "    losses['train_loss'].append(train_losses)\n",
    "    losses['val_loss'].append(val_loss)\n",
    "    losses['lr'].append(lr)\n",
    "    losses['n_nodes'].append(nodes)\n",
    "    losses['latent_dims'].append(latent_dim)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_hyperparameters = {'lr': lr, 'n_nodes': nodes, 'latent_dims': latent_dim}\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "best_model_path = '/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/models/best_vae.pth'\n",
    "torch.save({'hyperparameters': best_hyperparameters, 'model_state_dict': best_model}, best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a003bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_df = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "594292a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>latent_dims</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>[1068806384273.4286, 94376674.85714285, 166046...</td>\n",
       "      <td>16.616360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>[6763.48601422991, 6123.44287109375, 5942.0514...</td>\n",
       "      <td>18.606594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>[2119033568.890904, 6346.346784319197, 6143.13...</td>\n",
       "      <td>20.049708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>[80513.78867885044, 6638.915422712053, 6240.16...</td>\n",
       "      <td>25.299865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>[23618186806.1596, 22193.789620535714, 7180.95...</td>\n",
       "      <td>26.267933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>[321660490.50558037, 69060.85309709821, 15310....</td>\n",
       "      <td>27.717617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>[145755437.91524833, 12564.15966796875, 7404.4...</td>\n",
       "      <td>29.751145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>[99748559905.25781, 65763.44761439732, 8743.03...</td>\n",
       "      <td>39.549047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>[1015636548.2009975, 6385.760166713169, 6249.9...</td>\n",
       "      <td>40.633386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>[9005.272705078125, 6868.837995256697, 6435.00...</td>\n",
       "      <td>47.572509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>[1.6333454611879954e+16, 1814811.9107142857, 1...</td>\n",
       "      <td>49.364881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>[364726.44308035716, 13392.506870814732, 8565....</td>\n",
       "      <td>75.943253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>[11495.287667410714, 7113.682338169643, 6392.2...</td>\n",
       "      <td>80.394547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>[84508.93191964286, 10290.678431919643, 8973.1...</td>\n",
       "      <td>88.290549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>[34643.694126674105, 9249.722202845982, 7664.6...</td>\n",
       "      <td>99.258056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>[311336341.48214287, 6591009.9375, 3135993.736...</td>\n",
       "      <td>167.872498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>[28472547296.57143, 96338417.14285715, 3383979...</td>\n",
       "      <td>170.666538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>[152544327.57142857, 2300140.1272321427, 10661...</td>\n",
       "      <td>173.119946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>[5590291.478515625, 122884.77497209821, 44843....</td>\n",
       "      <td>180.140733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>[983811244.8571428, 2467404.5758928573, 467513...</td>\n",
       "      <td>196.303044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>[386309.3575613839, 22331.941266741072, 14297....</td>\n",
       "      <td>215.317476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>[86429819006.28572, 51099865.71428572, 1619533...</td>\n",
       "      <td>980.310496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>[20812.77315848214, 6043.239536830357, 5799.79...</td>\n",
       "      <td>1369.526717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>[6566.777727399553, 6064.662562779018, 5930.09...</td>\n",
       "      <td>1431.765841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr  n_nodes  latent_dims  \\\n",
       "23  0.005       64           30   \n",
       "13  0.005       16           10   \n",
       "17  0.005       32           10   \n",
       "15  0.005       16           30   \n",
       "18  0.005       32           20   \n",
       "14  0.005       16           20   \n",
       "20  0.005       64            5   \n",
       "22  0.005       64           20   \n",
       "12  0.005       16            5   \n",
       "8   0.001       64            5   \n",
       "19  0.005       32           30   \n",
       "0   0.001       16            5   \n",
       "9   0.001       64           10   \n",
       "4   0.001       32            5   \n",
       "1   0.001       16           10   \n",
       "2   0.001       16           20   \n",
       "3   0.001       16           30   \n",
       "7   0.001       32           30   \n",
       "10  0.001       64           20   \n",
       "11  0.001       64           30   \n",
       "6   0.001       32           20   \n",
       "5   0.001       32           10   \n",
       "21  0.005       64           10   \n",
       "16  0.005       32            5   \n",
       "\n",
       "                                           train_loss     val_loss  \n",
       "23  [1068806384273.4286, 94376674.85714285, 166046...    16.616360  \n",
       "13  [6763.48601422991, 6123.44287109375, 5942.0514...    18.606594  \n",
       "17  [2119033568.890904, 6346.346784319197, 6143.13...    20.049708  \n",
       "15  [80513.78867885044, 6638.915422712053, 6240.16...    25.299865  \n",
       "18  [23618186806.1596, 22193.789620535714, 7180.95...    26.267933  \n",
       "14  [321660490.50558037, 69060.85309709821, 15310....    27.717617  \n",
       "20  [145755437.91524833, 12564.15966796875, 7404.4...    29.751145  \n",
       "22  [99748559905.25781, 65763.44761439732, 8743.03...    39.549047  \n",
       "12  [1015636548.2009975, 6385.760166713169, 6249.9...    40.633386  \n",
       "8   [9005.272705078125, 6868.837995256697, 6435.00...    47.572509  \n",
       "19  [1.6333454611879954e+16, 1814811.9107142857, 1...    49.364881  \n",
       "0   [364726.44308035716, 13392.506870814732, 8565....    75.943253  \n",
       "9   [11495.287667410714, 7113.682338169643, 6392.2...    80.394547  \n",
       "4   [84508.93191964286, 10290.678431919643, 8973.1...    88.290549  \n",
       "1   [34643.694126674105, 9249.722202845982, 7664.6...    99.258056  \n",
       "2   [311336341.48214287, 6591009.9375, 3135993.736...   167.872498  \n",
       "3   [28472547296.57143, 96338417.14285715, 3383979...   170.666538  \n",
       "7   [152544327.57142857, 2300140.1272321427, 10661...   173.119946  \n",
       "10  [5590291.478515625, 122884.77497209821, 44843....   180.140733  \n",
       "11  [983811244.8571428, 2467404.5758928573, 467513...   196.303044  \n",
       "6   [386309.3575613839, 22331.941266741072, 14297....   215.317476  \n",
       "5   [86429819006.28572, 51099865.71428572, 1619533...   980.310496  \n",
       "21  [20812.77315848214, 6043.239536830357, 5799.79...  1369.526717  \n",
       "16  [6566.777727399553, 6064.662562779018, 5930.09...  1431.765841  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_df.sort_values(by='val_loss', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5376ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.005, 'n_nodes': 64, 'latent_dims': 30}\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeeeb993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_loss = losses_df['val_loss'].min()\n",
    "\n",
    "best_model_train_loss = losses_df[losses_df['val_loss'] == best_model_loss]['train_loss'].values[0]\n",
    "\n",
    "plt.plot(range(1, 151), best_model_train_loss)\n",
    "plt.title('Best model - Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8115d63",
   "metadata": {},
   "source": [
    "## 4.0 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb118f2",
   "metadata": {},
   "source": [
    "##### Using the Voting Regressor that was used to predict strength, the chemistry ouputs from this VAE model will be fed into the Voting Regressor to evaluate the generated chemistries predicted Yield strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d8526",
   "metadata": {},
   "source": [
    "### 4.1 Loading Ensemble Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c65dbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_model_path = '/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2_Modelling_streel_strength/models/final_vote_reg.h5'\n",
    "\n",
    "with open(ens_model_path, 'rb') as m:\n",
    "    vote_reg = pickle.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b298267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generated chemistries\n",
    "\n",
    "# Generating from X_test\n",
    "\n",
    "best_model_path = '/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/models/best_vae.pth'\n",
    "\n",
    "checkpoint = torch.load(best_model_path)\n",
    "best_model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "best_model = VAE(latent_dim=best_hyperparameters['latent_dims'], n_nodes=best_hyperparameters['n_nodes'])\n",
    "best_model.load_state_dict(best_model_state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f9f83d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7000e-01, 3.5000e-01, 1.4400e+00,  ..., 7.9000e-03, 0.0000e+00,\n",
       "         3.0000e+02],\n",
       "        [1.2000e-01, 3.7000e-01, 1.3200e+00,  ..., 6.4000e-03, 0.0000e+00,\n",
       "         4.0000e+02],\n",
       "        [1.3000e-01, 2.3000e-01, 6.6000e-01,  ..., 5.7000e-03, 0.0000e+00,\n",
       "         4.0000e+02],\n",
       "        ...,\n",
       "        [9.0000e-02, 3.7000e-01, 4.9000e-01,  ..., 8.0000e-03, 0.0000e+00,\n",
       "         3.0000e+02],\n",
       "        [1.2000e-01, 2.5000e-01, 4.8000e-01,  ..., 1.3000e-02, 0.0000e+00,\n",
       "         4.0000e+02],\n",
       "        [2.9000e-01, 2.6000e-01, 7.6000e-01,  ..., 1.0300e-02, 0.0000e+00,\n",
       "         2.7000e+01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "X_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90476fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7729e82",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    chem_predictions = best_model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f3eb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_predictions = chem_predictions[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7492cd4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vote_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04 - Generating Chemistries using VAE.ipynb Cell 35\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chinmayasukumar/Documents/Capstone%20Projects/Capstone-2b_Generating_steel_chemistries/notebooks/04%20-%20Generating%20Chemistries%20using%20VAE.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m yield_predictions \u001b[39m=\u001b[39m vote_reg\u001b[39m.\u001b[39mpredict(chem_predictions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vote_reg' is not defined"
     ]
    }
   ],
   "source": [
    "yield_predictions = vote_reg.predict(chem_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1857b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([414.96777852, 405.94065123, 405.6899133 , 418.22994735,\n",
       "       400.46038579, 394.28579127, 400.9283515 , 400.78768488,\n",
       "       410.8437898 , 415.58631175, 399.83973178, 416.78298936,\n",
       "       391.74607538, 403.77945437, 393.87707572, 388.55616334,\n",
       "       391.72630481, 397.73630674, 404.86492157, 406.51021087,\n",
       "       414.6626523 , 404.09307738, 405.98865999, 400.0624987 ,\n",
       "       405.66876632, 409.23242856, 409.54710277, 400.35874172,\n",
       "       413.74920247, 403.04669877, 395.34366382, 415.53077901,\n",
       "       407.92453007, 395.03090624, 403.47184756, 415.52431144,\n",
       "       403.77021087, 394.22345301, 398.63699735, 397.29079371,\n",
       "       415.42895863, 405.10096008, 406.30490273, 408.10624853,\n",
       "       404.20939765, 393.83050907, 405.65373499, 401.13013247,\n",
       "       397.10109505, 401.86076762, 403.76382024, 393.06617991,\n",
       "       398.28441047, 391.34057669, 406.66222912, 413.03819384,\n",
       "       392.38980162, 386.89694838, 399.7200777 , 399.68429288,\n",
       "       394.79541202, 416.00771158, 401.92195121, 420.1822053 ,\n",
       "       404.33558295, 393.90997819, 382.7138249 , 384.00983309,\n",
       "       411.45976399, 408.04431487, 403.291724  , 406.19941598,\n",
       "       404.10892527, 412.57918987, 407.11937151, 390.05568702,\n",
       "       414.65640195, 399.42205174, 403.94865866, 403.86988692,\n",
       "       413.67282834, 398.01050361, 416.88839562, 402.67833696,\n",
       "       401.40308709, 402.72365415, 393.41947017, 402.42048545,\n",
       "       410.05014426, 408.3948662 , 403.60297544, 405.06041182,\n",
       "       403.37429985, 372.19738542, 402.43885095, 416.07344499,\n",
       "       399.46699879, 406.7310726 , 395.76811063, 405.8904643 ,\n",
       "       406.22935894, 399.22808888, 401.542408  , 399.49568626,\n",
       "       400.66649032, 400.393324  , 404.8372426 , 398.61678041,\n",
       "       401.05299036, 388.94726027, 404.47751058])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc5f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([381, 341, 237, 191, 258, 203, 249, 650, 258, 488, 533, 561, 617,\n",
       "       183, 451, 640, 517, 372, 473, 462, 602, 280, 465, 240, 336, 244,\n",
       "       409, 513, 562, 221, 270, 251, 243, 508, 436, 450, 254, 185, 371,\n",
       "       228, 487, 335, 260, 381, 181, 570, 409, 249, 468, 213, 326, 288,\n",
       "       662, 264, 313, 426, 482, 645, 467, 526, 500, 202, 228, 259, 461,\n",
       "       178, 268, 179, 323, 213, 240, 499, 596, 464, 300, 534, 261, 272,\n",
       "       181, 194, 192, 476, 176, 310, 425, 305, 224, 186, 198, 228, 315,\n",
       "       357, 304, 642, 203, 352, 380, 360, 218, 515, 290, 396, 476, 499,\n",
       "       171, 261, 411, 258, 265, 237, 685])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 148.3309364595066\n",
      "MAE: 130.99292421425562\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", np.sqrt(mean_squared_error(yield_predictions, y_test)))\n",
    "print(\"MAE:\", mean_absolute_error(yield_predictions, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
