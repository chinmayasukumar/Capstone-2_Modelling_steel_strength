2023-07-03 15:31:26,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:31:26,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:31:26,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:31:26,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-03 15:32:19,713:INFO:PyCaret RegressionExperiment
2023-07-03 15:32:19,714:INFO:Logging name: reg-default-name
2023-07-03 15:32:19,714:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-03 15:32:19,714:INFO:version 3.0.4
2023-07-03 15:32:19,714:INFO:Initializing setup()
2023-07-03 15:32:19,714:INFO:self.USI: 0983
2023-07-03 15:32:19,714:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'fold_groups_param', 'X', 'transform_target_param', 'pipeline', 'y', 'exp_name_log', 'gpu_param', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', 'seed', 'USI', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'idx', 'X_test', 'y_train', 'y_test', 'target_param', 'log_plots_param', 'X_train', 'data', 'logging_param', 'memory'}
2023-07-03 15:32:19,714:INFO:Checking environment
2023-07-03 15:32:19,714:INFO:python_version: 3.9.12
2023-07-03 15:32:19,714:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-07-03 15:32:19,714:INFO:machine: x86_64
2023-07-03 15:32:19,714:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-03 15:32:19,715:INFO:Memory: svmem(total=17179869184, available=6512893952, percent=62.1, used=10139762688, free=34086912, active=6480064512, inactive=6477225984, wired=3659698176)
2023-07-03 15:32:19,715:INFO:Physical Core: 2
2023-07-03 15:32:19,715:INFO:Logical Core: 4
2023-07-03 15:32:19,715:INFO:Checking libraries
2023-07-03 15:32:19,715:INFO:System:
2023-07-03 15:32:19,715:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-07-03 15:32:19,715:INFO:executable: /Users/chinmayasukumar/opt/anaconda3/bin/python
2023-07-03 15:32:19,715:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-03 15:32:19,715:INFO:PyCaret required dependencies:
2023-07-03 15:32:19,719:INFO:                 pip: 21.2.4
2023-07-03 15:32:19,719:INFO:          setuptools: 60.10.0
2023-07-03 15:32:19,719:INFO:             pycaret: 3.0.4
2023-07-03 15:32:19,719:INFO:             IPython: 8.2.0
2023-07-03 15:32:19,719:INFO:          ipywidgets: 7.6.5
2023-07-03 15:32:19,719:INFO:                tqdm: 4.64.0
2023-07-03 15:32:19,720:INFO:               numpy: 1.21.6
2023-07-03 15:32:19,720:INFO:              pandas: 1.5.2
2023-07-03 15:32:19,720:INFO:              jinja2: 3.0.0
2023-07-03 15:32:19,720:INFO:               scipy: 1.7.3
2023-07-03 15:32:19,720:INFO:              joblib: 1.2.0
2023-07-03 15:32:19,720:INFO:             sklearn: 1.0.2
2023-07-03 15:32:19,720:INFO:                pyod: 1.0.9
2023-07-03 15:32:19,720:INFO:            imblearn: 0.9.1
2023-07-03 15:32:19,720:INFO:   category_encoders: 2.5.1.post0
2023-07-03 15:32:19,720:INFO:            lightgbm: 3.3.2
2023-07-03 15:32:19,720:INFO:               numba: 0.55.1
2023-07-03 15:32:19,720:INFO:            requests: 2.27.1
2023-07-03 15:32:19,720:INFO:          matplotlib: 3.5.1
2023-07-03 15:32:19,721:INFO:          scikitplot: 0.3.7
2023-07-03 15:32:19,721:INFO:         yellowbrick: 1.4
2023-07-03 15:32:19,721:INFO:              plotly: 5.6.0
2023-07-03 15:32:19,721:INFO:    plotly-resampler: Not installed
2023-07-03 15:32:19,721:INFO:             kaleido: 0.2.1
2023-07-03 15:32:19,721:INFO:           schemdraw: 0.15
2023-07-03 15:32:19,721:INFO:         statsmodels: 0.13.2
2023-07-03 15:32:19,721:INFO:              sktime: 0.17.0
2023-07-03 15:32:19,721:INFO:               tbats: 1.1.3
2023-07-03 15:32:19,721:INFO:            pmdarima: 2.0.1
2023-07-03 15:32:19,721:INFO:              psutil: 5.9.5
2023-07-03 15:32:19,721:INFO:          markupsafe: 2.0.1
2023-07-03 15:32:19,721:INFO:             pickle5: Not installed
2023-07-03 15:32:19,721:INFO:         cloudpickle: 2.0.0
2023-07-03 15:32:19,722:INFO:         deprecation: 2.1.0
2023-07-03 15:32:19,722:INFO:              xxhash: 3.2.0
2023-07-03 15:32:19,722:INFO:           wurlitzer: 3.0.2
2023-07-03 15:32:19,722:INFO:PyCaret optional dependencies:
2023-07-03 15:32:19,748:INFO:                shap: Not installed
2023-07-03 15:32:19,749:INFO:           interpret: Not installed
2023-07-03 15:32:19,749:INFO:                umap: 0.5.3
2023-07-03 15:32:19,749:INFO:    pandas_profiling: 3.2.0
2023-07-03 15:32:19,749:INFO:  explainerdashboard: Not installed
2023-07-03 15:32:19,749:INFO:             autoviz: 0.1.58
2023-07-03 15:32:19,749:INFO:           fairlearn: Not installed
2023-07-03 15:32:19,749:INFO:          deepchecks: Not installed
2023-07-03 15:32:19,752:INFO:             xgboost: 1.6.1
2023-07-03 15:32:19,753:INFO:            catboost: 1.0.6
2023-07-03 15:32:19,753:INFO:              kmodes: 0.12.1
2023-07-03 15:32:19,753:INFO:             mlxtend: 0.20.0
2023-07-03 15:32:19,753:INFO:       statsforecast: Not installed
2023-07-03 15:32:19,753:INFO:        tune_sklearn: Not installed
2023-07-03 15:32:19,754:INFO:                 ray: Not installed
2023-07-03 15:32:19,754:INFO:            hyperopt: Not installed
2023-07-03 15:32:19,754:INFO:              optuna: 3.2.0
2023-07-03 15:32:19,755:INFO:               skopt: Not installed
2023-07-03 15:32:19,755:INFO:              mlflow: 1.26.1
2023-07-03 15:32:19,756:INFO:              gradio: Not installed
2023-07-03 15:32:19,756:INFO:             fastapi: Not installed
2023-07-03 15:32:19,756:INFO:             uvicorn: Not installed
2023-07-03 15:32:19,756:INFO:              m2cgen: Not installed
2023-07-03 15:32:19,756:INFO:           evidently: Not installed
2023-07-03 15:32:19,756:INFO:               fugue: Not installed
2023-07-03 15:32:19,756:INFO:           streamlit: Not installed
2023-07-03 15:32:19,757:INFO:             prophet: Not installed
2023-07-03 15:32:19,757:INFO:None
2023-07-03 15:32:19,757:INFO:Set up data.
2023-07-03 15:32:19,782:INFO:Set up train/test split.
2023-07-03 15:32:19,786:INFO:Set up index.
2023-07-03 15:32:19,786:INFO:Set up folding strategy.
2023-07-03 15:32:19,786:INFO:Assigning column types.
2023-07-03 15:32:19,790:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-03 15:32:19,791:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 15:32:19,797:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 15:32:19,807:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 15:32:19,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:19,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:19,935:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:20,639:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:21,046:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,057:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,067:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,214:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:21,217:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:21,218:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-03 15:32:21,225:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,301:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,355:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:21,359:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:21,365:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,370:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,517:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:21,527:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:21,528:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-03 15:32:21,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,770:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:21,775:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:21,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:21,911:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:21,915:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:21,915:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-03 15:32:21,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:22,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:22,057:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:22,060:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:22,141:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:22,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-03 15:32:22,195:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:22,197:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:22,198:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-03 15:32:22,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:22,334:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:22,336:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:22,421:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-03 15:32:22,472:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:22,475:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:22,476:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-03 15:32:22,607:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:22,611:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:22,755:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:22,758:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:22,763:INFO:Preparing preprocessing pipeline...
2023-07-03 15:32:22,763:INFO:Set up simple imputation.
2023-07-03 15:32:22,764:INFO:Set up column name cleaning.
2023-07-03 15:32:22,793:INFO:Finished creating preprocessing pipeline.
2023-07-03 15:32:22,801:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['c', 'si', 'mn', 'p', 's', 'ni',
                                             'cr', 'mo', 'cu', 'v', 'al', 'n',
                                             'nb+ta', 'temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-03 15:32:22,801:INFO:Creating final display dataframe.
2023-07-03 15:32:22,925:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (618, 15)
4        Transformed data shape         (618, 15)
5   Transformed train set shape         (432, 15)
6    Transformed test set shape         (186, 15)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0983
2023-07-03 15:32:23,175:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:23,180:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:23,348:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-03 15:32:23,352:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-03 15:32:23,353:INFO:setup() successfully completed in 3.68s...............
2023-07-03 15:32:39,236:INFO:Initializing compare_models()
2023-07-03 15:32:39,236:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-03 15:32:39,237:INFO:Checking exceptions
2023-07-03 15:32:39,241:INFO:Preparing display monitor
2023-07-03 15:32:39,415:INFO:Initializing Linear Regression
2023-07-03 15:32:39,416:INFO:Total runtime is 1.2564659118652344e-05 minutes
2023-07-03 15:32:39,429:INFO:SubProcess create_model() called ==================================
2023-07-03 15:32:39,430:INFO:Initializing create_model()
2023-07-03 15:32:39,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:32:39,431:INFO:Checking exceptions
2023-07-03 15:32:39,431:INFO:Importing libraries
2023-07-03 15:32:39,431:INFO:Copying training dataset
2023-07-03 15:32:39,442:INFO:Defining folds
2023-07-03 15:32:39,443:INFO:Declaring metric variables
2023-07-03 15:32:39,452:INFO:Importing untrained model
2023-07-03 15:32:39,462:INFO:Linear Regression Imported successfully
2023-07-03 15:32:39,481:INFO:Starting cross validation
2023-07-03 15:32:39,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:32:57,551:INFO:Calculating mean and std
2023-07-03 15:32:57,555:INFO:Creating metrics dataframe
2023-07-03 15:32:57,614:INFO:Uploading results into container
2023-07-03 15:32:57,615:INFO:Uploading model into container now
2023-07-03 15:32:57,616:INFO:_master_model_container: 1
2023-07-03 15:32:57,616:INFO:_display_container: 2
2023-07-03 15:32:57,617:INFO:LinearRegression(n_jobs=-1)
2023-07-03 15:32:57,617:INFO:create_model() successfully completed......................................
2023-07-03 15:32:57,741:INFO:SubProcess create_model() end ==================================
2023-07-03 15:32:57,741:INFO:Creating metrics dataframe
2023-07-03 15:32:57,759:INFO:Initializing Lasso Regression
2023-07-03 15:32:57,759:INFO:Total runtime is 0.3057322820027669 minutes
2023-07-03 15:32:57,767:INFO:SubProcess create_model() called ==================================
2023-07-03 15:32:57,768:INFO:Initializing create_model()
2023-07-03 15:32:57,768:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:32:57,768:INFO:Checking exceptions
2023-07-03 15:32:57,768:INFO:Importing libraries
2023-07-03 15:32:57,768:INFO:Copying training dataset
2023-07-03 15:32:57,777:INFO:Defining folds
2023-07-03 15:32:57,777:INFO:Declaring metric variables
2023-07-03 15:32:57,782:INFO:Importing untrained model
2023-07-03 15:32:57,789:INFO:Lasso Regression Imported successfully
2023-07-03 15:32:57,798:INFO:Starting cross validation
2023-07-03 15:32:57,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:32:58,385:INFO:Calculating mean and std
2023-07-03 15:32:58,387:INFO:Creating metrics dataframe
2023-07-03 15:32:58,429:INFO:Uploading results into container
2023-07-03 15:32:58,429:INFO:Uploading model into container now
2023-07-03 15:32:58,430:INFO:_master_model_container: 2
2023-07-03 15:32:58,430:INFO:_display_container: 2
2023-07-03 15:32:58,430:INFO:Lasso(random_state=123)
2023-07-03 15:32:58,430:INFO:create_model() successfully completed......................................
2023-07-03 15:32:58,520:INFO:SubProcess create_model() end ==================================
2023-07-03 15:32:58,520:INFO:Creating metrics dataframe
2023-07-03 15:32:58,535:INFO:Initializing Ridge Regression
2023-07-03 15:32:58,535:INFO:Total runtime is 0.31867254972457887 minutes
2023-07-03 15:32:58,540:INFO:SubProcess create_model() called ==================================
2023-07-03 15:32:58,540:INFO:Initializing create_model()
2023-07-03 15:32:58,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:32:58,541:INFO:Checking exceptions
2023-07-03 15:32:58,541:INFO:Importing libraries
2023-07-03 15:32:58,542:INFO:Copying training dataset
2023-07-03 15:32:58,550:INFO:Defining folds
2023-07-03 15:32:58,550:INFO:Declaring metric variables
2023-07-03 15:32:58,557:INFO:Importing untrained model
2023-07-03 15:32:58,566:INFO:Ridge Regression Imported successfully
2023-07-03 15:32:58,578:INFO:Starting cross validation
2023-07-03 15:32:58,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:32:59,297:INFO:Calculating mean and std
2023-07-03 15:32:59,299:INFO:Creating metrics dataframe
2023-07-03 15:32:59,347:INFO:Uploading results into container
2023-07-03 15:32:59,348:INFO:Uploading model into container now
2023-07-03 15:32:59,348:INFO:_master_model_container: 3
2023-07-03 15:32:59,348:INFO:_display_container: 2
2023-07-03 15:32:59,349:INFO:Ridge(random_state=123)
2023-07-03 15:32:59,349:INFO:create_model() successfully completed......................................
2023-07-03 15:32:59,441:INFO:SubProcess create_model() end ==================================
2023-07-03 15:32:59,441:INFO:Creating metrics dataframe
2023-07-03 15:32:59,456:INFO:Initializing Elastic Net
2023-07-03 15:32:59,456:INFO:Total runtime is 0.33401563167572024 minutes
2023-07-03 15:32:59,463:INFO:SubProcess create_model() called ==================================
2023-07-03 15:32:59,463:INFO:Initializing create_model()
2023-07-03 15:32:59,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:32:59,464:INFO:Checking exceptions
2023-07-03 15:32:59,464:INFO:Importing libraries
2023-07-03 15:32:59,464:INFO:Copying training dataset
2023-07-03 15:32:59,473:INFO:Defining folds
2023-07-03 15:32:59,473:INFO:Declaring metric variables
2023-07-03 15:32:59,480:INFO:Importing untrained model
2023-07-03 15:32:59,487:INFO:Elastic Net Imported successfully
2023-07-03 15:32:59,498:INFO:Starting cross validation
2023-07-03 15:32:59,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:00,727:INFO:Calculating mean and std
2023-07-03 15:33:00,730:INFO:Creating metrics dataframe
2023-07-03 15:33:00,775:INFO:Uploading results into container
2023-07-03 15:33:00,775:INFO:Uploading model into container now
2023-07-03 15:33:00,776:INFO:_master_model_container: 4
2023-07-03 15:33:00,776:INFO:_display_container: 2
2023-07-03 15:33:00,777:INFO:ElasticNet(random_state=123)
2023-07-03 15:33:00,777:INFO:create_model() successfully completed......................................
2023-07-03 15:33:00,871:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:00,871:INFO:Creating metrics dataframe
2023-07-03 15:33:00,886:INFO:Initializing Least Angle Regression
2023-07-03 15:33:00,886:INFO:Total runtime is 0.357854700088501 minutes
2023-07-03 15:33:00,890:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:00,892:INFO:Initializing create_model()
2023-07-03 15:33:00,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:00,892:INFO:Checking exceptions
2023-07-03 15:33:00,892:INFO:Importing libraries
2023-07-03 15:33:00,893:INFO:Copying training dataset
2023-07-03 15:33:00,903:INFO:Defining folds
2023-07-03 15:33:00,903:INFO:Declaring metric variables
2023-07-03 15:33:00,920:INFO:Importing untrained model
2023-07-03 15:33:00,929:INFO:Least Angle Regression Imported successfully
2023-07-03 15:33:00,944:INFO:Starting cross validation
2023-07-03 15:33:00,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:01,087:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,123:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,151:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,160:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,255:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,283:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,340:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,395:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,488:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,501:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:01,560:INFO:Calculating mean and std
2023-07-03 15:33:01,563:INFO:Creating metrics dataframe
2023-07-03 15:33:01,615:INFO:Uploading results into container
2023-07-03 15:33:01,616:INFO:Uploading model into container now
2023-07-03 15:33:01,616:INFO:_master_model_container: 5
2023-07-03 15:33:01,616:INFO:_display_container: 2
2023-07-03 15:33:01,617:INFO:Lars(random_state=123)
2023-07-03 15:33:01,617:INFO:create_model() successfully completed......................................
2023-07-03 15:33:01,714:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:01,715:INFO:Creating metrics dataframe
2023-07-03 15:33:01,731:INFO:Initializing Lasso Least Angle Regression
2023-07-03 15:33:01,731:INFO:Total runtime is 0.37193848292032883 minutes
2023-07-03 15:33:01,739:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:01,739:INFO:Initializing create_model()
2023-07-03 15:33:01,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:01,742:INFO:Checking exceptions
2023-07-03 15:33:01,742:INFO:Importing libraries
2023-07-03 15:33:01,742:INFO:Copying training dataset
2023-07-03 15:33:01,751:INFO:Defining folds
2023-07-03 15:33:01,752:INFO:Declaring metric variables
2023-07-03 15:33:01,761:INFO:Importing untrained model
2023-07-03 15:33:01,769:INFO:Lasso Least Angle Regression Imported successfully
2023-07-03 15:33:01,782:INFO:Starting cross validation
2023-07-03 15:33:01,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:01,941:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:01,973:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,008:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,020:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,146:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,195:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,238:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,279:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,352:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,360:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-03 15:33:02,480:INFO:Calculating mean and std
2023-07-03 15:33:02,483:INFO:Creating metrics dataframe
2023-07-03 15:33:02,536:INFO:Uploading results into container
2023-07-03 15:33:02,537:INFO:Uploading model into container now
2023-07-03 15:33:02,538:INFO:_master_model_container: 6
2023-07-03 15:33:02,538:INFO:_display_container: 2
2023-07-03 15:33:02,538:INFO:LassoLars(random_state=123)
2023-07-03 15:33:02,538:INFO:create_model() successfully completed......................................
2023-07-03 15:33:02,635:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:02,635:INFO:Creating metrics dataframe
2023-07-03 15:33:02,652:INFO:Initializing Orthogonal Matching Pursuit
2023-07-03 15:33:02,652:INFO:Total runtime is 0.38728316624959314 minutes
2023-07-03 15:33:02,657:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:02,657:INFO:Initializing create_model()
2023-07-03 15:33:02,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:02,657:INFO:Checking exceptions
2023-07-03 15:33:02,658:INFO:Importing libraries
2023-07-03 15:33:02,658:INFO:Copying training dataset
2023-07-03 15:33:02,670:INFO:Defining folds
2023-07-03 15:33:02,670:INFO:Declaring metric variables
2023-07-03 15:33:02,679:INFO:Importing untrained model
2023-07-03 15:33:02,685:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-03 15:33:02,706:INFO:Starting cross validation
2023-07-03 15:33:02,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:02,828:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:02,873:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:02,885:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:02,906:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,019:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,061:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,085:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,145:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,194:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,213:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-03 15:33:03,304:INFO:Calculating mean and std
2023-07-03 15:33:03,305:INFO:Creating metrics dataframe
2023-07-03 15:33:03,346:INFO:Uploading results into container
2023-07-03 15:33:03,347:INFO:Uploading model into container now
2023-07-03 15:33:03,348:INFO:_master_model_container: 7
2023-07-03 15:33:03,348:INFO:_display_container: 2
2023-07-03 15:33:03,348:INFO:OrthogonalMatchingPursuit()
2023-07-03 15:33:03,348:INFO:create_model() successfully completed......................................
2023-07-03 15:33:03,443:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:03,443:INFO:Creating metrics dataframe
2023-07-03 15:33:03,460:INFO:Initializing Bayesian Ridge
2023-07-03 15:33:03,460:INFO:Total runtime is 0.40075229803721113 minutes
2023-07-03 15:33:03,468:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:03,469:INFO:Initializing create_model()
2023-07-03 15:33:03,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:03,469:INFO:Checking exceptions
2023-07-03 15:33:03,469:INFO:Importing libraries
2023-07-03 15:33:03,469:INFO:Copying training dataset
2023-07-03 15:33:03,483:INFO:Defining folds
2023-07-03 15:33:03,483:INFO:Declaring metric variables
2023-07-03 15:33:03,501:INFO:Importing untrained model
2023-07-03 15:33:03,507:INFO:Bayesian Ridge Imported successfully
2023-07-03 15:33:03,520:INFO:Starting cross validation
2023-07-03 15:33:03,521:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:04,093:INFO:Calculating mean and std
2023-07-03 15:33:04,095:INFO:Creating metrics dataframe
2023-07-03 15:33:04,142:INFO:Uploading results into container
2023-07-03 15:33:04,143:INFO:Uploading model into container now
2023-07-03 15:33:04,143:INFO:_master_model_container: 8
2023-07-03 15:33:04,143:INFO:_display_container: 2
2023-07-03 15:33:04,143:INFO:BayesianRidge()
2023-07-03 15:33:04,143:INFO:create_model() successfully completed......................................
2023-07-03 15:33:04,235:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:04,235:INFO:Creating metrics dataframe
2023-07-03 15:33:04,251:INFO:Initializing Passive Aggressive Regressor
2023-07-03 15:33:04,251:INFO:Total runtime is 0.41393156846364343 minutes
2023-07-03 15:33:04,255:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:04,256:INFO:Initializing create_model()
2023-07-03 15:33:04,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:04,256:INFO:Checking exceptions
2023-07-03 15:33:04,256:INFO:Importing libraries
2023-07-03 15:33:04,257:INFO:Copying training dataset
2023-07-03 15:33:04,271:INFO:Defining folds
2023-07-03 15:33:04,271:INFO:Declaring metric variables
2023-07-03 15:33:04,286:INFO:Importing untrained model
2023-07-03 15:33:04,299:INFO:Passive Aggressive Regressor Imported successfully
2023-07-03 15:33:04,311:INFO:Starting cross validation
2023-07-03 15:33:04,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:04,982:INFO:Calculating mean and std
2023-07-03 15:33:04,984:INFO:Creating metrics dataframe
2023-07-03 15:33:05,034:INFO:Uploading results into container
2023-07-03 15:33:05,035:INFO:Uploading model into container now
2023-07-03 15:33:05,035:INFO:_master_model_container: 9
2023-07-03 15:33:05,036:INFO:_display_container: 2
2023-07-03 15:33:05,036:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-03 15:33:05,036:INFO:create_model() successfully completed......................................
2023-07-03 15:33:05,161:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:05,161:INFO:Creating metrics dataframe
2023-07-03 15:33:05,181:INFO:Initializing Huber Regressor
2023-07-03 15:33:05,181:INFO:Total runtime is 0.4294271151224773 minutes
2023-07-03 15:33:05,186:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:05,186:INFO:Initializing create_model()
2023-07-03 15:33:05,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:05,187:INFO:Checking exceptions
2023-07-03 15:33:05,187:INFO:Importing libraries
2023-07-03 15:33:05,188:INFO:Copying training dataset
2023-07-03 15:33:05,195:INFO:Defining folds
2023-07-03 15:33:05,195:INFO:Declaring metric variables
2023-07-03 15:33:05,201:INFO:Importing untrained model
2023-07-03 15:33:05,208:INFO:Huber Regressor Imported successfully
2023-07-03 15:33:05,220:INFO:Starting cross validation
2023-07-03 15:33:05,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:05,438:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:05,475:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:05,503:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:05,528:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:05,869:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:05,881:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:06,050:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:06,128:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-03 15:33:06,189:INFO:Calculating mean and std
2023-07-03 15:33:06,191:INFO:Creating metrics dataframe
2023-07-03 15:33:06,238:INFO:Uploading results into container
2023-07-03 15:33:06,239:INFO:Uploading model into container now
2023-07-03 15:33:06,239:INFO:_master_model_container: 10
2023-07-03 15:33:06,240:INFO:_display_container: 2
2023-07-03 15:33:06,240:INFO:HuberRegressor()
2023-07-03 15:33:06,240:INFO:create_model() successfully completed......................................
2023-07-03 15:33:06,332:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:06,333:INFO:Creating metrics dataframe
2023-07-03 15:33:06,349:INFO:Initializing K Neighbors Regressor
2023-07-03 15:33:06,349:INFO:Total runtime is 0.4488934477170309 minutes
2023-07-03 15:33:06,353:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:06,354:INFO:Initializing create_model()
2023-07-03 15:33:06,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:06,354:INFO:Checking exceptions
2023-07-03 15:33:06,354:INFO:Importing libraries
2023-07-03 15:33:06,354:INFO:Copying training dataset
2023-07-03 15:33:06,368:INFO:Defining folds
2023-07-03 15:33:06,368:INFO:Declaring metric variables
2023-07-03 15:33:06,376:INFO:Importing untrained model
2023-07-03 15:33:06,392:INFO:K Neighbors Regressor Imported successfully
2023-07-03 15:33:06,416:INFO:Starting cross validation
2023-07-03 15:33:06,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:07,049:INFO:Calculating mean and std
2023-07-03 15:33:07,051:INFO:Creating metrics dataframe
2023-07-03 15:33:07,102:INFO:Uploading results into container
2023-07-03 15:33:07,102:INFO:Uploading model into container now
2023-07-03 15:33:07,103:INFO:_master_model_container: 11
2023-07-03 15:33:07,103:INFO:_display_container: 2
2023-07-03 15:33:07,103:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-03 15:33:07,103:INFO:create_model() successfully completed......................................
2023-07-03 15:33:07,190:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:07,190:INFO:Creating metrics dataframe
2023-07-03 15:33:07,208:INFO:Initializing Decision Tree Regressor
2023-07-03 15:33:07,208:INFO:Total runtime is 0.46321386496225997 minutes
2023-07-03 15:33:07,216:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:07,216:INFO:Initializing create_model()
2023-07-03 15:33:07,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:07,216:INFO:Checking exceptions
2023-07-03 15:33:07,217:INFO:Importing libraries
2023-07-03 15:33:07,217:INFO:Copying training dataset
2023-07-03 15:33:07,226:INFO:Defining folds
2023-07-03 15:33:07,226:INFO:Declaring metric variables
2023-07-03 15:33:07,232:INFO:Importing untrained model
2023-07-03 15:33:07,239:INFO:Decision Tree Regressor Imported successfully
2023-07-03 15:33:07,249:INFO:Starting cross validation
2023-07-03 15:33:07,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:07,849:INFO:Calculating mean and std
2023-07-03 15:33:07,851:INFO:Creating metrics dataframe
2023-07-03 15:33:07,900:INFO:Uploading results into container
2023-07-03 15:33:07,901:INFO:Uploading model into container now
2023-07-03 15:33:07,901:INFO:_master_model_container: 12
2023-07-03 15:33:07,901:INFO:_display_container: 2
2023-07-03 15:33:07,902:INFO:DecisionTreeRegressor(random_state=123)
2023-07-03 15:33:07,902:INFO:create_model() successfully completed......................................
2023-07-03 15:33:08,000:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:08,000:INFO:Creating metrics dataframe
2023-07-03 15:33:08,029:INFO:Initializing Random Forest Regressor
2023-07-03 15:33:08,029:INFO:Total runtime is 0.4769001483917237 minutes
2023-07-03 15:33:08,035:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:08,035:INFO:Initializing create_model()
2023-07-03 15:33:08,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:08,036:INFO:Checking exceptions
2023-07-03 15:33:08,036:INFO:Importing libraries
2023-07-03 15:33:08,036:INFO:Copying training dataset
2023-07-03 15:33:08,051:INFO:Defining folds
2023-07-03 15:33:08,051:INFO:Declaring metric variables
2023-07-03 15:33:08,065:INFO:Importing untrained model
2023-07-03 15:33:08,073:INFO:Random Forest Regressor Imported successfully
2023-07-03 15:33:08,085:INFO:Starting cross validation
2023-07-03 15:33:08,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:09,386:INFO:Calculating mean and std
2023-07-03 15:33:09,388:INFO:Creating metrics dataframe
2023-07-03 15:33:09,442:INFO:Uploading results into container
2023-07-03 15:33:09,442:INFO:Uploading model into container now
2023-07-03 15:33:09,443:INFO:_master_model_container: 13
2023-07-03 15:33:09,443:INFO:_display_container: 2
2023-07-03 15:33:09,443:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-03 15:33:09,443:INFO:create_model() successfully completed......................................
2023-07-03 15:33:09,540:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:09,540:INFO:Creating metrics dataframe
2023-07-03 15:33:09,559:INFO:Initializing Extra Trees Regressor
2023-07-03 15:33:09,559:INFO:Total runtime is 0.5023969133694967 minutes
2023-07-03 15:33:09,564:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:09,565:INFO:Initializing create_model()
2023-07-03 15:33:09,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:09,565:INFO:Checking exceptions
2023-07-03 15:33:09,566:INFO:Importing libraries
2023-07-03 15:33:09,566:INFO:Copying training dataset
2023-07-03 15:33:09,578:INFO:Defining folds
2023-07-03 15:33:09,579:INFO:Declaring metric variables
2023-07-03 15:33:09,593:INFO:Importing untrained model
2023-07-03 15:33:09,602:INFO:Extra Trees Regressor Imported successfully
2023-07-03 15:33:09,611:INFO:Starting cross validation
2023-07-03 15:33:09,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:10,762:INFO:Calculating mean and std
2023-07-03 15:33:10,764:INFO:Creating metrics dataframe
2023-07-03 15:33:10,818:INFO:Uploading results into container
2023-07-03 15:33:10,818:INFO:Uploading model into container now
2023-07-03 15:33:10,819:INFO:_master_model_container: 14
2023-07-03 15:33:10,819:INFO:_display_container: 2
2023-07-03 15:33:10,819:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 15:33:10,819:INFO:create_model() successfully completed......................................
2023-07-03 15:33:10,908:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:10,908:INFO:Creating metrics dataframe
2023-07-03 15:33:10,929:INFO:Initializing AdaBoost Regressor
2023-07-03 15:33:10,929:INFO:Total runtime is 0.5252270619074504 minutes
2023-07-03 15:33:10,933:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:10,933:INFO:Initializing create_model()
2023-07-03 15:33:10,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:10,934:INFO:Checking exceptions
2023-07-03 15:33:10,934:INFO:Importing libraries
2023-07-03 15:33:10,934:INFO:Copying training dataset
2023-07-03 15:33:10,943:INFO:Defining folds
2023-07-03 15:33:10,944:INFO:Declaring metric variables
2023-07-03 15:33:10,955:INFO:Importing untrained model
2023-07-03 15:33:10,961:INFO:AdaBoost Regressor Imported successfully
2023-07-03 15:33:10,972:INFO:Starting cross validation
2023-07-03 15:33:10,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:11,825:INFO:Calculating mean and std
2023-07-03 15:33:11,828:INFO:Creating metrics dataframe
2023-07-03 15:33:11,890:INFO:Uploading results into container
2023-07-03 15:33:11,891:INFO:Uploading model into container now
2023-07-03 15:33:11,891:INFO:_master_model_container: 15
2023-07-03 15:33:11,891:INFO:_display_container: 2
2023-07-03 15:33:11,892:INFO:AdaBoostRegressor(random_state=123)
2023-07-03 15:33:11,892:INFO:create_model() successfully completed......................................
2023-07-03 15:33:11,988:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:11,988:INFO:Creating metrics dataframe
2023-07-03 15:33:12,007:INFO:Initializing Gradient Boosting Regressor
2023-07-03 15:33:12,007:INFO:Total runtime is 0.5432064175605774 minutes
2023-07-03 15:33:12,015:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:12,015:INFO:Initializing create_model()
2023-07-03 15:33:12,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:12,015:INFO:Checking exceptions
2023-07-03 15:33:12,016:INFO:Importing libraries
2023-07-03 15:33:12,016:INFO:Copying training dataset
2023-07-03 15:33:12,026:INFO:Defining folds
2023-07-03 15:33:12,027:INFO:Declaring metric variables
2023-07-03 15:33:12,034:INFO:Importing untrained model
2023-07-03 15:33:12,042:INFO:Gradient Boosting Regressor Imported successfully
2023-07-03 15:33:12,054:INFO:Starting cross validation
2023-07-03 15:33:12,056:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:13,127:INFO:Calculating mean and std
2023-07-03 15:33:13,129:INFO:Creating metrics dataframe
2023-07-03 15:33:13,184:INFO:Uploading results into container
2023-07-03 15:33:13,185:INFO:Uploading model into container now
2023-07-03 15:33:13,185:INFO:_master_model_container: 16
2023-07-03 15:33:13,185:INFO:_display_container: 2
2023-07-03 15:33:13,185:INFO:GradientBoostingRegressor(random_state=123)
2023-07-03 15:33:13,185:INFO:create_model() successfully completed......................................
2023-07-03 15:33:13,275:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:13,276:INFO:Creating metrics dataframe
2023-07-03 15:33:13,294:INFO:Initializing Extreme Gradient Boosting
2023-07-03 15:33:13,295:INFO:Total runtime is 0.5646596829096476 minutes
2023-07-03 15:33:13,299:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:13,299:INFO:Initializing create_model()
2023-07-03 15:33:13,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:13,299:INFO:Checking exceptions
2023-07-03 15:33:13,300:INFO:Importing libraries
2023-07-03 15:33:13,300:INFO:Copying training dataset
2023-07-03 15:33:13,310:INFO:Defining folds
2023-07-03 15:33:13,311:INFO:Declaring metric variables
2023-07-03 15:33:13,323:INFO:Importing untrained model
2023-07-03 15:33:13,331:INFO:Extreme Gradient Boosting Imported successfully
2023-07-03 15:33:13,341:INFO:Starting cross validation
2023-07-03 15:33:13,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:14,158:INFO:Calculating mean and std
2023-07-03 15:33:14,160:INFO:Creating metrics dataframe
2023-07-03 15:33:14,212:INFO:Uploading results into container
2023-07-03 15:33:14,213:INFO:Uploading model into container now
2023-07-03 15:33:14,214:INFO:_master_model_container: 17
2023-07-03 15:33:14,214:INFO:_display_container: 2
2023-07-03 15:33:14,215:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2023-07-03 15:33:14,216:INFO:create_model() successfully completed......................................
2023-07-03 15:33:14,305:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:14,305:INFO:Creating metrics dataframe
2023-07-03 15:33:14,331:INFO:Initializing Light Gradient Boosting Machine
2023-07-03 15:33:14,331:INFO:Total runtime is 0.5819306174914042 minutes
2023-07-03 15:33:14,335:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:14,336:INFO:Initializing create_model()
2023-07-03 15:33:14,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:14,336:INFO:Checking exceptions
2023-07-03 15:33:14,336:INFO:Importing libraries
2023-07-03 15:33:14,337:INFO:Copying training dataset
2023-07-03 15:33:14,344:INFO:Defining folds
2023-07-03 15:33:14,344:INFO:Declaring metric variables
2023-07-03 15:33:14,350:INFO:Importing untrained model
2023-07-03 15:33:14,356:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 15:33:14,366:INFO:Starting cross validation
2023-07-03 15:33:14,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:16,719:INFO:Calculating mean and std
2023-07-03 15:33:16,721:INFO:Creating metrics dataframe
2023-07-03 15:33:16,768:INFO:Uploading results into container
2023-07-03 15:33:16,769:INFO:Uploading model into container now
2023-07-03 15:33:16,769:INFO:_master_model_container: 18
2023-07-03 15:33:16,769:INFO:_display_container: 2
2023-07-03 15:33:16,770:INFO:LGBMRegressor(random_state=123)
2023-07-03 15:33:16,770:INFO:create_model() successfully completed......................................
2023-07-03 15:33:16,863:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:16,863:INFO:Creating metrics dataframe
2023-07-03 15:33:16,884:INFO:Initializing CatBoost Regressor
2023-07-03 15:33:16,884:INFO:Total runtime is 0.6244771679242451 minutes
2023-07-03 15:33:16,888:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:16,889:INFO:Initializing create_model()
2023-07-03 15:33:16,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:16,889:INFO:Checking exceptions
2023-07-03 15:33:16,889:INFO:Importing libraries
2023-07-03 15:33:16,889:INFO:Copying training dataset
2023-07-03 15:33:16,897:INFO:Defining folds
2023-07-03 15:33:16,898:INFO:Declaring metric variables
2023-07-03 15:33:16,904:INFO:Importing untrained model
2023-07-03 15:33:16,911:INFO:CatBoost Regressor Imported successfully
2023-07-03 15:33:16,925:INFO:Starting cross validation
2023-07-03 15:33:16,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:17,510:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,510:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,510:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,526:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,677:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,684:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,695:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,716:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,808:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,828:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 15:33:17,918:INFO:Calculating mean and std
2023-07-03 15:33:17,920:INFO:Creating metrics dataframe
2023-07-03 15:33:17,970:INFO:Uploading results into container
2023-07-03 15:33:17,970:INFO:Uploading model into container now
2023-07-03 15:33:17,971:INFO:_master_model_container: 19
2023-07-03 15:33:17,971:INFO:_display_container: 2
2023-07-03 15:33:17,971:INFO:<catboost.core.CatBoostRegressor object at 0x7f8c94a2bc40>
2023-07-03 15:33:17,971:INFO:create_model() successfully completed......................................
2023-07-03 15:33:18,060:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:18,060:INFO:Creating metrics dataframe
2023-07-03 15:33:18,082:INFO:Initializing Dummy Regressor
2023-07-03 15:33:18,082:INFO:Total runtime is 0.6444564461708068 minutes
2023-07-03 15:33:18,087:INFO:SubProcess create_model() called ==================================
2023-07-03 15:33:18,087:INFO:Initializing create_model()
2023-07-03 15:33:18,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f8c8c2edd30>, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:18,088:INFO:Checking exceptions
2023-07-03 15:33:18,088:INFO:Importing libraries
2023-07-03 15:33:18,088:INFO:Copying training dataset
2023-07-03 15:33:18,097:INFO:Defining folds
2023-07-03 15:33:18,097:INFO:Declaring metric variables
2023-07-03 15:33:18,103:INFO:Importing untrained model
2023-07-03 15:33:18,109:INFO:Dummy Regressor Imported successfully
2023-07-03 15:33:18,121:INFO:Starting cross validation
2023-07-03 15:33:18,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-03 15:33:18,780:INFO:Calculating mean and std
2023-07-03 15:33:18,782:INFO:Creating metrics dataframe
2023-07-03 15:33:18,830:INFO:Uploading results into container
2023-07-03 15:33:18,831:INFO:Uploading model into container now
2023-07-03 15:33:18,831:INFO:_master_model_container: 20
2023-07-03 15:33:18,831:INFO:_display_container: 2
2023-07-03 15:33:18,832:INFO:DummyRegressor()
2023-07-03 15:33:18,832:INFO:create_model() successfully completed......................................
2023-07-03 15:33:18,922:INFO:SubProcess create_model() end ==================================
2023-07-03 15:33:18,922:INFO:Creating metrics dataframe
2023-07-03 15:33:18,959:INFO:Initializing create_model()
2023-07-03 15:33:18,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c94a2bc40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:18,960:INFO:Checking exceptions
2023-07-03 15:33:18,963:INFO:Importing libraries
2023-07-03 15:33:18,964:INFO:Copying training dataset
2023-07-03 15:33:18,970:INFO:Defining folds
2023-07-03 15:33:18,970:INFO:Declaring metric variables
2023-07-03 15:33:18,971:INFO:Importing untrained model
2023-07-03 15:33:18,971:INFO:Declaring custom model
2023-07-03 15:33:18,972:INFO:CatBoost Regressor Imported successfully
2023-07-03 15:33:18,973:INFO:Cross validation set to False
2023-07-03 15:33:18,973:INFO:Fitting Model
2023-07-03 15:33:19,083:INFO:<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>
2023-07-03 15:33:19,083:INFO:create_model() successfully completed......................................
2023-07-03 15:33:19,209:INFO:Initializing create_model()
2023-07-03 15:33:19,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:19,210:INFO:Checking exceptions
2023-07-03 15:33:19,214:INFO:Importing libraries
2023-07-03 15:33:19,214:INFO:Copying training dataset
2023-07-03 15:33:19,224:INFO:Defining folds
2023-07-03 15:33:19,224:INFO:Declaring metric variables
2023-07-03 15:33:19,226:INFO:Importing untrained model
2023-07-03 15:33:19,228:INFO:Declaring custom model
2023-07-03 15:33:19,231:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-03 15:33:19,233:INFO:Cross validation set to False
2023-07-03 15:33:19,233:INFO:Fitting Model
2023-07-03 15:33:19,393:INFO:LGBMRegressor(random_state=123)
2023-07-03 15:33:19,393:INFO:create_model() successfully completed......................................
2023-07-03 15:33:19,519:INFO:Initializing create_model()
2023-07-03 15:33:19,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-03 15:33:19,520:INFO:Checking exceptions
2023-07-03 15:33:19,522:INFO:Importing libraries
2023-07-03 15:33:19,523:INFO:Copying training dataset
2023-07-03 15:33:19,529:INFO:Defining folds
2023-07-03 15:33:19,529:INFO:Declaring metric variables
2023-07-03 15:33:19,529:INFO:Importing untrained model
2023-07-03 15:33:19,529:INFO:Declaring custom model
2023-07-03 15:33:19,530:INFO:Extra Trees Regressor Imported successfully
2023-07-03 15:33:19,531:INFO:Cross validation set to False
2023-07-03 15:33:19,531:INFO:Fitting Model
2023-07-03 15:33:19,708:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-03 15:33:19,708:INFO:create_model() successfully completed......................................
2023-07-03 15:33:19,863:INFO:_master_model_container: 20
2023-07-03 15:33:19,863:INFO:_display_container: 2
2023-07-03 15:33:19,864:INFO:[<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-07-03 15:33:19,864:INFO:compare_models() successfully completed......................................
2023-07-03 16:38:39,038:INFO:Initializing evaluate_model()
2023-07-03 16:38:39,039:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-03 16:38:39,170:INFO:Initializing plot_model()
2023-07-03 16:38:39,173:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:38:39,173:INFO:Checking exceptions
2023-07-03 16:38:39,183:INFO:Preloading libraries
2023-07-03 16:38:39,206:INFO:Copying training dataset
2023-07-03 16:38:39,206:INFO:Plot type: pipeline
2023-07-03 16:38:39,477:INFO:Visual Rendered Successfully
2023-07-03 16:38:39,614:INFO:plot_model() successfully completed......................................
2023-07-03 16:38:44,328:INFO:Initializing plot_model()
2023-07-03 16:38:44,328:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:38:44,329:INFO:Checking exceptions
2023-07-03 16:38:44,332:INFO:Preloading libraries
2023-07-03 16:38:44,333:INFO:Copying training dataset
2023-07-03 16:38:44,334:INFO:Plot type: parameter
2023-07-03 16:38:44,367:INFO:Visual Rendered Successfully
2023-07-03 16:38:44,557:INFO:plot_model() successfully completed......................................
2023-07-03 16:38:45,866:INFO:Initializing plot_model()
2023-07-03 16:38:45,867:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:38:45,867:INFO:Checking exceptions
2023-07-03 16:38:45,874:INFO:Preloading libraries
2023-07-03 16:38:45,875:INFO:Copying training dataset
2023-07-03 16:38:45,876:INFO:Plot type: residuals
2023-07-03 16:38:46,107:INFO:Fitting Model
2023-07-03 16:38:46,121:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 16:38:46,160:INFO:Scoring test/hold-out set
2023-07-03 16:38:47,281:INFO:Visual Rendered Successfully
2023-07-03 16:38:47,476:INFO:plot_model() successfully completed......................................
2023-07-03 16:38:49,116:INFO:Initializing plot_model()
2023-07-03 16:38:49,117:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:38:49,117:INFO:Checking exceptions
2023-07-03 16:38:49,121:INFO:Preloading libraries
2023-07-03 16:38:49,124:INFO:Copying training dataset
2023-07-03 16:38:49,124:INFO:Plot type: error
2023-07-03 16:38:49,243:INFO:Fitting Model
2023-07-03 16:38:49,244:INFO:Scoring test/hold-out set
2023-07-03 16:38:49,245:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-03 16:38:55,655:INFO:Visual Rendered Successfully
2023-07-03 16:38:55,760:INFO:plot_model() successfully completed......................................
2023-07-03 16:38:57,272:INFO:Initializing plot_model()
2023-07-03 16:38:57,273:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:38:57,273:INFO:Checking exceptions
2023-07-03 16:38:57,277:INFO:Preloading libraries
2023-07-03 16:38:57,278:INFO:Copying training dataset
2023-07-03 16:38:57,279:INFO:Plot type: feature
2023-07-03 16:38:57,280:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:38:57,475:INFO:Visual Rendered Successfully
2023-07-03 16:38:57,591:INFO:plot_model() successfully completed......................................
2023-07-03 16:39:00,349:INFO:Initializing evaluate_model()
2023-07-03 16:39:00,349:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=LGBMRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-03 16:39:00,398:INFO:Initializing plot_model()
2023-07-03 16:39:00,398:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:39:00,398:INFO:Checking exceptions
2023-07-03 16:39:00,402:INFO:Preloading libraries
2023-07-03 16:39:00,428:INFO:Copying training dataset
2023-07-03 16:39:00,428:INFO:Plot type: pipeline
2023-07-03 16:39:00,616:INFO:Visual Rendered Successfully
2023-07-03 16:39:00,732:INFO:plot_model() successfully completed......................................
2023-07-03 16:39:02,856:INFO:Initializing plot_model()
2023-07-03 16:39:02,856:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:39:02,856:INFO:Checking exceptions
2023-07-03 16:39:02,860:INFO:Preloading libraries
2023-07-03 16:39:02,872:INFO:Copying training dataset
2023-07-03 16:39:02,872:INFO:Plot type: feature
2023-07-03 16:39:02,873:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:39:03,077:INFO:Visual Rendered Successfully
2023-07-03 16:39:03,245:INFO:plot_model() successfully completed......................................
2023-07-03 16:39:05,422:INFO:Initializing evaluate_model()
2023-07-03 16:39:05,422:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-03 16:39:05,464:INFO:Initializing plot_model()
2023-07-03 16:39:05,464:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:39:05,464:INFO:Checking exceptions
2023-07-03 16:39:05,519:INFO:Preloading libraries
2023-07-03 16:39:05,569:INFO:Copying training dataset
2023-07-03 16:39:05,569:INFO:Plot type: pipeline
2023-07-03 16:39:05,710:INFO:Visual Rendered Successfully
2023-07-03 16:39:05,856:INFO:plot_model() successfully completed......................................
2023-07-03 16:39:07,341:INFO:Initializing plot_model()
2023-07-03 16:39:07,342:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:39:07,342:INFO:Checking exceptions
2023-07-03 16:39:07,384:INFO:Preloading libraries
2023-07-03 16:39:07,414:INFO:Copying training dataset
2023-07-03 16:39:07,415:INFO:Plot type: feature
2023-07-03 16:39:07,416:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:39:07,574:INFO:Visual Rendered Successfully
2023-07-03 16:39:07,691:INFO:plot_model() successfully completed......................................
2023-07-03 16:47:34,806:INFO:Initializing interpret_model()
2023-07-03 16:47:34,806:INFO:interpret_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>)
2023-07-03 16:47:34,806:INFO:Checking exceptions
2023-07-03 16:47:34,807:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-03 16:48:12,273:INFO:Initializing interpret_model()
2023-07-03 16:48:12,274:INFO:interpret_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>)
2023-07-03 16:48:12,274:INFO:Checking exceptions
2023-07-03 16:48:12,275:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-07-03 16:50:08,299:INFO:Initializing evaluate_model()
2023-07-03 16:50:08,300:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-03 16:50:08,376:INFO:Initializing plot_model()
2023-07-03 16:50:08,378:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:08,385:INFO:Checking exceptions
2023-07-03 16:50:08,395:INFO:Preloading libraries
2023-07-03 16:50:08,464:INFO:Copying training dataset
2023-07-03 16:50:08,464:INFO:Plot type: pipeline
2023-07-03 16:50:08,679:INFO:Visual Rendered Successfully
2023-07-03 16:50:09,131:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:11,133:INFO:Initializing plot_model()
2023-07-03 16:50:11,134:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:11,134:INFO:Checking exceptions
2023-07-03 16:50:11,139:INFO:Preloading libraries
2023-07-03 16:50:11,142:INFO:Copying training dataset
2023-07-03 16:50:11,142:INFO:Plot type: feature
2023-07-03 16:50:11,143:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:11,499:INFO:Visual Rendered Successfully
2023-07-03 16:50:11,705:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:20,564:INFO:Initializing evaluate_model()
2023-07-03 16:50:20,565:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=LGBMRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-03 16:50:20,657:INFO:Initializing plot_model()
2023-07-03 16:50:20,658:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:20,658:INFO:Checking exceptions
2023-07-03 16:50:20,664:INFO:Preloading libraries
2023-07-03 16:50:20,695:INFO:Copying training dataset
2023-07-03 16:50:20,695:INFO:Plot type: pipeline
2023-07-03 16:50:20,869:INFO:Visual Rendered Successfully
2023-07-03 16:50:21,068:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:23,348:INFO:Initializing plot_model()
2023-07-03 16:50:23,348:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:23,348:INFO:Checking exceptions
2023-07-03 16:50:23,353:INFO:Preloading libraries
2023-07-03 16:50:23,369:INFO:Copying training dataset
2023-07-03 16:50:23,369:INFO:Plot type: feature
2023-07-03 16:50:23,370:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:23,598:INFO:Visual Rendered Successfully
2023-07-03 16:50:23,884:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:31,742:INFO:Initializing evaluate_model()
2023-07-03 16:50:31,743:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-03 16:50:31,787:INFO:Initializing plot_model()
2023-07-03 16:50:31,787:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:31,788:INFO:Checking exceptions
2023-07-03 16:50:31,827:INFO:Preloading libraries
2023-07-03 16:50:31,906:INFO:Copying training dataset
2023-07-03 16:50:31,906:INFO:Plot type: pipeline
2023-07-03 16:50:32,011:INFO:Visual Rendered Successfully
2023-07-03 16:50:32,176:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:35,022:INFO:Initializing plot_model()
2023-07-03 16:50:35,022:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:35,022:INFO:Checking exceptions
2023-07-03 16:50:35,055:INFO:Preloading libraries
2023-07-03 16:50:35,081:INFO:Copying training dataset
2023-07-03 16:50:35,081:INFO:Plot type: feature
2023-07-03 16:50:35,082:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:35,237:INFO:Visual Rendered Successfully
2023-07-03 16:50:35,395:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:36,439:INFO:Initializing plot_model()
2023-07-03 16:50:36,439:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:36,439:INFO:Checking exceptions
2023-07-03 16:50:36,470:INFO:Preloading libraries
2023-07-03 16:50:36,508:INFO:Copying training dataset
2023-07-03 16:50:36,508:INFO:Plot type: feature_all
2023-07-03 16:50:36,543:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:36,709:INFO:Visual Rendered Successfully
2023-07-03 16:50:36,857:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:38,273:INFO:Initializing plot_model()
2023-07-03 16:50:38,274:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:38,274:INFO:Checking exceptions
2023-07-03 16:50:38,306:INFO:Preloading libraries
2023-07-03 16:50:38,333:INFO:Copying training dataset
2023-07-03 16:50:38,333:INFO:Plot type: feature
2023-07-03 16:50:38,334:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:38,490:INFO:Visual Rendered Successfully
2023-07-03 16:50:38,693:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:41,745:INFO:Initializing plot_model()
2023-07-03 16:50:41,745:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:41,746:INFO:Checking exceptions
2023-07-03 16:50:41,751:INFO:Preloading libraries
2023-07-03 16:50:41,763:INFO:Copying training dataset
2023-07-03 16:50:41,763:INFO:Plot type: feature_all
2023-07-03 16:50:41,813:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:42,004:INFO:Visual Rendered Successfully
2023-07-03 16:50:42,149:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:44,109:INFO:Initializing plot_model()
2023-07-03 16:50:44,109:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:44,109:INFO:Checking exceptions
2023-07-03 16:50:44,115:INFO:Preloading libraries
2023-07-03 16:50:44,149:INFO:Copying training dataset
2023-07-03 16:50:44,150:INFO:Plot type: feature
2023-07-03 16:50:44,151:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:44,351:INFO:Visual Rendered Successfully
2023-07-03 16:50:44,500:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:45,733:INFO:Initializing plot_model()
2023-07-03 16:50:45,733:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:45,733:INFO:Checking exceptions
2023-07-03 16:50:45,738:INFO:Preloading libraries
2023-07-03 16:50:45,749:INFO:Copying training dataset
2023-07-03 16:50:45,749:INFO:Plot type: feature_all
2023-07-03 16:50:45,808:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:45,998:INFO:Visual Rendered Successfully
2023-07-03 16:50:46,144:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:48,059:INFO:Initializing plot_model()
2023-07-03 16:50:48,059:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:48,059:INFO:Checking exceptions
2023-07-03 16:50:48,063:INFO:Preloading libraries
2023-07-03 16:50:48,075:INFO:Copying training dataset
2023-07-03 16:50:48,075:INFO:Plot type: feature
2023-07-03 16:50:48,076:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:48,276:INFO:Visual Rendered Successfully
2023-07-03 16:50:48,423:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:49,649:INFO:Initializing plot_model()
2023-07-03 16:50:49,649:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:49,650:INFO:Checking exceptions
2023-07-03 16:50:49,653:INFO:Preloading libraries
2023-07-03 16:50:49,671:INFO:Copying training dataset
2023-07-03 16:50:49,671:INFO:Plot type: feature_all
2023-07-03 16:50:49,720:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:49,904:INFO:Visual Rendered Successfully
2023-07-03 16:50:50,186:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:51,644:INFO:Initializing plot_model()
2023-07-03 16:50:51,644:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:51,645:INFO:Checking exceptions
2023-07-03 16:50:51,679:INFO:Preloading libraries
2023-07-03 16:50:51,713:INFO:Copying training dataset
2023-07-03 16:50:51,713:INFO:Plot type: feature_all
2023-07-03 16:50:51,736:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:52,007:INFO:Visual Rendered Successfully
2023-07-03 16:50:52,182:INFO:plot_model() successfully completed......................................
2023-07-03 16:50:55,764:INFO:Initializing plot_model()
2023-07-03 16:50:55,764:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:50:55,765:INFO:Checking exceptions
2023-07-03 16:50:55,768:INFO:Preloading libraries
2023-07-03 16:50:55,771:INFO:Copying training dataset
2023-07-03 16:50:55,771:INFO:Plot type: feature_all
2023-07-03 16:50:55,846:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:50:56,098:INFO:Visual Rendered Successfully
2023-07-03 16:50:56,247:INFO:plot_model() successfully completed......................................
2023-07-03 16:54:50,387:INFO:Initializing plot_model()
2023-07-03 16:54:50,387:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7f8c93c47460>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:54:50,388:INFO:Checking exceptions
2023-07-03 16:54:50,419:INFO:Preloading libraries
2023-07-03 16:54:50,429:INFO:Copying training dataset
2023-07-03 16:54:50,429:INFO:Plot type: feature_all
2023-07-03 16:54:50,470:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:54:50,645:INFO:Visual Rendered Successfully
2023-07-03 16:54:50,801:INFO:plot_model() successfully completed......................................
2023-07-03 16:55:24,438:INFO:Initializing plot_model()
2023-07-03 16:55:24,438:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:55:24,438:INFO:Checking exceptions
2023-07-03 16:55:24,447:INFO:Preloading libraries
2023-07-03 16:55:24,463:INFO:Copying training dataset
2023-07-03 16:55:24,464:INFO:Plot type: feature_all
2023-07-03 16:55:24,499:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:55:24,747:INFO:Visual Rendered Successfully
2023-07-03 16:55:25,048:INFO:plot_model() successfully completed......................................
2023-07-03 16:55:35,407:INFO:Initializing plot_model()
2023-07-03 16:55:35,407:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:55:35,408:INFO:Checking exceptions
2023-07-03 16:55:35,443:INFO:Preloading libraries
2023-07-03 16:55:35,528:INFO:Copying training dataset
2023-07-03 16:55:35,528:INFO:Plot type: residuals
2023-07-03 16:55:35,754:INFO:Fitting Model
2023-07-03 16:55:35,771:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2023-07-03 16:55:36,031:INFO:Scoring test/hold-out set
2023-07-03 16:55:36,603:INFO:Visual Rendered Successfully
2023-07-03 16:55:36,835:INFO:plot_model() successfully completed......................................
2023-07-03 16:55:44,774:INFO:Initializing plot_model()
2023-07-03 16:55:44,774:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f8c93431e80>, system=True)
2023-07-03 16:55:44,774:INFO:Checking exceptions
2023-07-03 16:55:44,811:INFO:Preloading libraries
2023-07-03 16:55:44,840:INFO:Copying training dataset
2023-07-03 16:55:44,840:INFO:Plot type: feature_all
2023-07-03 16:55:44,913:WARNING:No coef_ found. Trying feature_importances_
2023-07-03 16:55:45,146:INFO:Visual Rendered Successfully
2023-07-03 16:55:45,404:INFO:plot_model() successfully completed......................................
2023-07-07 17:54:38,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:54:38,826:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:54:38,826:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:54:38,826:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:59:53,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:59:53,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:59:53,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 17:59:53,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 19:14:33,090:WARNING:<>:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:14:33,098:WARNING:<>:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:14:33,099:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/816350709.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:33,111:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/816350709.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:33,112:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/816350709.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:40,440:WARNING:<>:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:14:40,443:WARNING:<>:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:14:40,445:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1131443872.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:40,459:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1131443872.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:40,459:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1131443872.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:47,742:WARNING:<>:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:14:47,743:WARNING:<>:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:14:47,745:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/2874015781.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:47,760:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/2874015781.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:14:47,760:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/2874015781.py:10: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [14, 15, 16]

2023-07-07 19:19:34,647:WARNING:<>:9: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:19:34,649:WARNING:<>:9: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?

2023-07-07 19:19:34,650:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1555628929.py:9: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [1, 2, 3]

2023-07-07 19:19:34,667:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1555628929.py:9: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [1, 2, 3]

2023-07-07 19:19:34,668:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1555628929.py:9: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?
  [1, 2, 3]

2023-07-07 19:27:32,277:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/712089138.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  row_exists = np.any(np.all(row == X_train, axis=1))

2023-07-07 19:31:59,463:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1635283910.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  X_sub[:5] == X_train[:,5]

2023-07-07 19:32:04,962:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1228554896.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  X_sub[:,5] == X_train[:,5]

2023-07-07 19:32:28,170:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/896239792.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  X_sub[:,4] == X_train[:,4]

2023-07-07 20:15:00,130:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/4074306625.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  indices = np.where(np.all(X_train == X_sub, axis=(2, )))

2023-07-07 20:15:09,118:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/2579431020.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  indices = np.where(np.all(X_train == X_sub))

2023-07-07 20:15:13,084:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1699653960.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  indices = np.where(np.all(X_train == X))

2023-07-07 20:15:16,207:WARNING:/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/ipykernel_80841/1556591045.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  indices = np.where(np.all(X_train == X_mask))

2023-07-09 12:32:33,725:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:42,248:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:42,994:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:43,558:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:44,104:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:44,631:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:45,104:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:45,569:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:46,036:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:46,558:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:47,040:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:47,605:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:48,081:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:48,548:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:32:49,014:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:21,889:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:22,433:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:23,480:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:24,376:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:25,004:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:26,096:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:26,854:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:28,296:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:29,131:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:29,824:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:30,501:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:31,101:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:31,798:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:32,378:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 12:33:32,964:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-07-09 14:14:38,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 14:14:38,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 14:14:38,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 14:14:38,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 21:48:55,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 21:48:55,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 21:48:55,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 21:48:55,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-09 21:49:44,767:INFO:PyCaret RegressionExperiment
2023-07-09 21:49:44,767:INFO:Logging name: reg-default-name
2023-07-09 21:49:44,767:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-09 21:49:44,768:INFO:version 3.0.4
2023-07-09 21:49:44,768:INFO:Initializing setup()
2023-07-09 21:49:44,768:INFO:self.USI: 9ac7
2023-07-09 21:49:44,768:INFO:self._variable_keys: {'log_plots_param', 'target_param', 'data', 'gpu_param', 'fold_shuffle_param', 'seed', 'X_train', 'USI', 'logging_param', '_available_plots', 'exp_name_log', 'n_jobs_param', 'exp_id', 'memory', 'fold_generator', 'pipeline', 'y', 'gpu_n_jobs_param', '_ml_usecase', 'y_test', 'fold_groups_param', 'html_param', 'transform_target_param', 'y_train', 'idx', 'X', 'X_test'}
2023-07-09 21:49:44,768:INFO:Checking environment
2023-07-09 21:49:44,768:INFO:python_version: 3.9.12
2023-07-09 21:49:44,768:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-07-09 21:49:44,768:INFO:machine: x86_64
2023-07-09 21:49:44,768:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-09 21:49:44,768:INFO:Memory: svmem(total=17179869184, available=6578274304, percent=61.7, used=9792782336, free=160006144, active=6385954816, inactive=6379864064, wired=3406827520)
2023-07-09 21:49:44,768:INFO:Physical Core: 2
2023-07-09 21:49:44,768:INFO:Logical Core: 4
2023-07-09 21:49:44,768:INFO:Checking libraries
2023-07-09 21:49:44,768:INFO:System:
2023-07-09 21:49:44,768:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-07-09 21:49:44,768:INFO:executable: /Users/chinmayasukumar/opt/anaconda3/bin/python
2023-07-09 21:49:44,768:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-09 21:49:44,768:INFO:PyCaret required dependencies:
2023-07-09 21:49:44,770:INFO:                 pip: 21.2.4
2023-07-09 21:49:44,770:INFO:          setuptools: 60.10.0
2023-07-09 21:49:44,770:INFO:             pycaret: 3.0.4
2023-07-09 21:49:44,771:INFO:             IPython: 8.2.0
2023-07-09 21:49:44,771:INFO:          ipywidgets: 7.6.5
2023-07-09 21:49:44,771:INFO:                tqdm: 4.64.0
2023-07-09 21:49:44,771:INFO:               numpy: 1.22.4
2023-07-09 21:49:44,771:INFO:              pandas: 1.5.2
2023-07-09 21:49:44,771:INFO:              jinja2: 3.0.0
2023-07-09 21:49:44,771:INFO:               scipy: 1.7.3
2023-07-09 21:49:44,771:INFO:              joblib: 1.2.0
2023-07-09 21:49:44,771:INFO:             sklearn: 1.0.2
2023-07-09 21:49:44,771:INFO:                pyod: 1.0.9
2023-07-09 21:49:44,771:INFO:            imblearn: 0.9.1
2023-07-09 21:49:44,771:INFO:   category_encoders: 2.5.1.post0
2023-07-09 21:49:44,771:INFO:            lightgbm: 3.3.2
2023-07-09 21:49:44,771:INFO:               numba: 0.55.1
2023-07-09 21:49:44,771:INFO:            requests: 2.27.1
2023-07-09 21:49:44,771:INFO:          matplotlib: 3.5.1
2023-07-09 21:49:44,771:INFO:          scikitplot: 0.3.7
2023-07-09 21:49:44,771:INFO:         yellowbrick: 1.4
2023-07-09 21:49:44,771:INFO:              plotly: 5.6.0
2023-07-09 21:49:44,771:INFO:    plotly-resampler: Not installed
2023-07-09 21:49:44,771:INFO:             kaleido: 0.2.1
2023-07-09 21:49:44,771:INFO:           schemdraw: 0.15
2023-07-09 21:49:44,771:INFO:         statsmodels: 0.13.2
2023-07-09 21:49:44,771:INFO:              sktime: 0.17.0
2023-07-09 21:49:44,771:INFO:               tbats: 1.1.3
2023-07-09 21:49:44,771:INFO:            pmdarima: 2.0.1
2023-07-09 21:49:44,772:INFO:              psutil: 5.9.5
2023-07-09 21:49:44,772:INFO:          markupsafe: 2.0.1
2023-07-09 21:49:44,772:INFO:             pickle5: Not installed
2023-07-09 21:49:44,772:INFO:         cloudpickle: 2.0.0
2023-07-09 21:49:44,772:INFO:         deprecation: 2.1.0
2023-07-09 21:49:44,772:INFO:              xxhash: 3.2.0
2023-07-09 21:49:44,772:INFO:           wurlitzer: 3.0.2
2023-07-09 21:49:44,772:INFO:PyCaret optional dependencies:
2023-07-09 21:49:44,783:INFO:                shap: 0.41.0
2023-07-09 21:49:44,783:INFO:           interpret: Not installed
2023-07-09 21:49:44,783:INFO:                umap: 0.5.3
2023-07-09 21:49:44,784:INFO:    pandas_profiling: 3.2.0
2023-07-09 21:49:44,784:INFO:  explainerdashboard: Not installed
2023-07-09 21:49:44,784:INFO:             autoviz: 0.1.58
2023-07-09 21:49:44,784:INFO:           fairlearn: Not installed
2023-07-09 21:49:44,784:INFO:          deepchecks: Not installed
2023-07-09 21:49:44,784:INFO:             xgboost: 1.6.1
2023-07-09 21:49:44,784:INFO:            catboost: 1.0.6
2023-07-09 21:49:44,784:INFO:              kmodes: 0.12.1
2023-07-09 21:49:44,784:INFO:             mlxtend: 0.20.0
2023-07-09 21:49:44,784:INFO:       statsforecast: Not installed
2023-07-09 21:49:44,784:INFO:        tune_sklearn: Not installed
2023-07-09 21:49:44,784:INFO:                 ray: Not installed
2023-07-09 21:49:44,784:INFO:            hyperopt: Not installed
2023-07-09 21:49:44,784:INFO:              optuna: 3.2.0
2023-07-09 21:49:44,784:INFO:               skopt: Not installed
2023-07-09 21:49:44,784:INFO:              mlflow: 1.26.1
2023-07-09 21:49:44,784:INFO:              gradio: Not installed
2023-07-09 21:49:44,784:INFO:             fastapi: Not installed
2023-07-09 21:49:44,784:INFO:             uvicorn: Not installed
2023-07-09 21:49:44,784:INFO:              m2cgen: Not installed
2023-07-09 21:49:44,784:INFO:           evidently: Not installed
2023-07-09 21:49:44,784:INFO:               fugue: Not installed
2023-07-09 21:49:44,784:INFO:           streamlit: Not installed
2023-07-09 21:49:44,784:INFO:             prophet: Not installed
2023-07-09 21:49:44,784:INFO:None
2023-07-09 21:49:44,784:INFO:Set up data.
2023-07-09 21:49:44,792:INFO:Set up train/test split.
2023-07-09 21:49:44,795:INFO:Set up index.
2023-07-09 21:49:44,795:INFO:Set up folding strategy.
2023-07-09 21:49:44,796:INFO:Assigning column types.
2023-07-09 21:49:44,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-09 21:49:44,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-09 21:49:44,804:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-09 21:49:44,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-09 21:49:44,878:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:44,927:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:44,928:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:45,520:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:45,611:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,627:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,637:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,782:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:45,786:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:45,786:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-09 21:49:45,791:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-09 21:49:45,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,049:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:46,052:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:46,057:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,062:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,196:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:46,204:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:46,206:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-09 21:49:46,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,453:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:46,458:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:46,474:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,641:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:46,645:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:46,645:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-09 21:49:46,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,775:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:46,779:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:46,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-09 21:49:46,921:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:46,927:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:46,928:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-09 21:49:47,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:47,078:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:47,081:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:47,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-09 21:49:47,210:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:47,213:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:47,214:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-09 21:49:47,355:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:47,360:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:47,491:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:47,494:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:47,499:INFO:Preparing preprocessing pipeline...
2023-07-09 21:49:47,499:INFO:Set up simple imputation.
2023-07-09 21:49:47,500:INFO:Set up column name cleaning.
2023-07-09 21:49:47,530:INFO:Finished creating preprocessing pipeline.
2023-07-09 21:49:47,539:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['c', 'si', 'mn', 'p', 's', 'ni',
                                             'cr', 'mo', 'cu', 'v', 'al', 'n',
                                             'nb+ta', 'temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-09 21:49:47,539:INFO:Creating final display dataframe.
2023-07-09 21:49:47,674:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (618, 15)
4        Transformed data shape         (618, 15)
5   Transformed train set shape         (432, 15)
6    Transformed test set shape         (186, 15)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9ac7
2023-07-09 21:49:47,969:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:47,973:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:48,100:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-09 21:49:48,103:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-09 21:49:48,105:INFO:setup() successfully completed in 3.52s...............
2023-07-09 21:49:53,222:INFO:Initializing compare_models()
2023-07-09 21:49:53,222:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-09 21:49:53,222:INFO:Checking exceptions
2023-07-09 21:49:53,226:INFO:Preparing display monitor
2023-07-09 21:49:53,390:INFO:Initializing Linear Regression
2023-07-09 21:49:53,394:INFO:Total runtime is 7.248719533284506e-05 minutes
2023-07-09 21:49:53,404:INFO:SubProcess create_model() called ==================================
2023-07-09 21:49:53,405:INFO:Initializing create_model()
2023-07-09 21:49:53,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:49:53,406:INFO:Checking exceptions
2023-07-09 21:49:53,406:INFO:Importing libraries
2023-07-09 21:49:53,406:INFO:Copying training dataset
2023-07-09 21:49:53,423:INFO:Defining folds
2023-07-09 21:49:53,423:INFO:Declaring metric variables
2023-07-09 21:49:53,432:INFO:Importing untrained model
2023-07-09 21:49:53,443:INFO:Linear Regression Imported successfully
2023-07-09 21:49:53,462:INFO:Starting cross validation
2023-07-09 21:49:53,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:15,237:INFO:Calculating mean and std
2023-07-09 21:50:15,241:INFO:Creating metrics dataframe
2023-07-09 21:50:15,376:INFO:Uploading results into container
2023-07-09 21:50:15,377:INFO:Uploading model into container now
2023-07-09 21:50:15,378:INFO:_master_model_container: 1
2023-07-09 21:50:15,378:INFO:_display_container: 2
2023-07-09 21:50:15,378:INFO:LinearRegression(n_jobs=-1)
2023-07-09 21:50:15,379:INFO:create_model() successfully completed......................................
2023-07-09 21:50:15,521:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:15,521:INFO:Creating metrics dataframe
2023-07-09 21:50:15,542:INFO:Initializing Lasso Regression
2023-07-09 21:50:15,543:INFO:Total runtime is 0.36921948591868087 minutes
2023-07-09 21:50:15,551:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:15,551:INFO:Initializing create_model()
2023-07-09 21:50:15,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:15,552:INFO:Checking exceptions
2023-07-09 21:50:15,552:INFO:Importing libraries
2023-07-09 21:50:15,552:INFO:Copying training dataset
2023-07-09 21:50:15,561:INFO:Defining folds
2023-07-09 21:50:15,561:INFO:Declaring metric variables
2023-07-09 21:50:15,572:INFO:Importing untrained model
2023-07-09 21:50:15,580:INFO:Lasso Regression Imported successfully
2023-07-09 21:50:15,591:INFO:Starting cross validation
2023-07-09 21:50:15,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:16,953:INFO:Calculating mean and std
2023-07-09 21:50:16,955:INFO:Creating metrics dataframe
2023-07-09 21:50:17,099:INFO:Uploading results into container
2023-07-09 21:50:17,100:INFO:Uploading model into container now
2023-07-09 21:50:17,100:INFO:_master_model_container: 2
2023-07-09 21:50:17,101:INFO:_display_container: 2
2023-07-09 21:50:17,101:INFO:Lasso(random_state=123)
2023-07-09 21:50:17,101:INFO:create_model() successfully completed......................................
2023-07-09 21:50:17,223:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:17,223:INFO:Creating metrics dataframe
2023-07-09 21:50:17,237:INFO:Initializing Ridge Regression
2023-07-09 21:50:17,237:INFO:Total runtime is 0.3974594871203105 minutes
2023-07-09 21:50:17,244:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:17,244:INFO:Initializing create_model()
2023-07-09 21:50:17,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:17,245:INFO:Checking exceptions
2023-07-09 21:50:17,245:INFO:Importing libraries
2023-07-09 21:50:17,245:INFO:Copying training dataset
2023-07-09 21:50:17,255:INFO:Defining folds
2023-07-09 21:50:17,255:INFO:Declaring metric variables
2023-07-09 21:50:17,262:INFO:Importing untrained model
2023-07-09 21:50:17,269:INFO:Ridge Regression Imported successfully
2023-07-09 21:50:17,283:INFO:Starting cross validation
2023-07-09 21:50:17,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:18,489:INFO:Calculating mean and std
2023-07-09 21:50:18,491:INFO:Creating metrics dataframe
2023-07-09 21:50:18,660:INFO:Uploading results into container
2023-07-09 21:50:18,661:INFO:Uploading model into container now
2023-07-09 21:50:18,662:INFO:_master_model_container: 3
2023-07-09 21:50:18,662:INFO:_display_container: 2
2023-07-09 21:50:18,662:INFO:Ridge(random_state=123)
2023-07-09 21:50:18,662:INFO:create_model() successfully completed......................................
2023-07-09 21:50:18,791:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:18,791:INFO:Creating metrics dataframe
2023-07-09 21:50:18,815:INFO:Initializing Elastic Net
2023-07-09 21:50:18,815:INFO:Total runtime is 0.4237590829531352 minutes
2023-07-09 21:50:18,821:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:18,821:INFO:Initializing create_model()
2023-07-09 21:50:18,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:18,822:INFO:Checking exceptions
2023-07-09 21:50:18,822:INFO:Importing libraries
2023-07-09 21:50:18,822:INFO:Copying training dataset
2023-07-09 21:50:18,842:INFO:Defining folds
2023-07-09 21:50:18,843:INFO:Declaring metric variables
2023-07-09 21:50:18,849:INFO:Importing untrained model
2023-07-09 21:50:18,856:INFO:Elastic Net Imported successfully
2023-07-09 21:50:18,869:INFO:Starting cross validation
2023-07-09 21:50:18,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:20,086:INFO:Calculating mean and std
2023-07-09 21:50:20,088:INFO:Creating metrics dataframe
2023-07-09 21:50:20,244:INFO:Uploading results into container
2023-07-09 21:50:20,245:INFO:Uploading model into container now
2023-07-09 21:50:20,247:INFO:_master_model_container: 4
2023-07-09 21:50:20,247:INFO:_display_container: 2
2023-07-09 21:50:20,247:INFO:ElasticNet(random_state=123)
2023-07-09 21:50:20,247:INFO:create_model() successfully completed......................................
2023-07-09 21:50:20,477:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:20,478:INFO:Creating metrics dataframe
2023-07-09 21:50:20,495:INFO:Initializing Least Angle Regression
2023-07-09 21:50:20,495:INFO:Total runtime is 0.4517654975255331 minutes
2023-07-09 21:50:20,502:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:20,503:INFO:Initializing create_model()
2023-07-09 21:50:20,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:20,503:INFO:Checking exceptions
2023-07-09 21:50:20,503:INFO:Importing libraries
2023-07-09 21:50:20,503:INFO:Copying training dataset
2023-07-09 21:50:20,513:INFO:Defining folds
2023-07-09 21:50:20,513:INFO:Declaring metric variables
2023-07-09 21:50:20,519:INFO:Importing untrained model
2023-07-09 21:50:20,527:INFO:Least Angle Regression Imported successfully
2023-07-09 21:50:20,537:INFO:Starting cross validation
2023-07-09 21:50:20,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:20,671:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:20,675:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:20,675:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:20,711:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:21,067:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:21,078:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:21,138:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:21,148:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:21,570:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:21,692:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:22,677:INFO:Calculating mean and std
2023-07-09 21:50:22,679:INFO:Creating metrics dataframe
2023-07-09 21:50:22,804:INFO:Uploading results into container
2023-07-09 21:50:22,805:INFO:Uploading model into container now
2023-07-09 21:50:22,805:INFO:_master_model_container: 5
2023-07-09 21:50:22,806:INFO:_display_container: 2
2023-07-09 21:50:22,806:INFO:Lars(random_state=123)
2023-07-09 21:50:22,806:INFO:create_model() successfully completed......................................
2023-07-09 21:50:22,927:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:22,927:INFO:Creating metrics dataframe
2023-07-09 21:50:22,961:INFO:Initializing Lasso Least Angle Regression
2023-07-09 21:50:22,961:INFO:Total runtime is 0.49286141792933147 minutes
2023-07-09 21:50:22,977:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:22,979:INFO:Initializing create_model()
2023-07-09 21:50:22,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:22,979:INFO:Checking exceptions
2023-07-09 21:50:22,979:INFO:Importing libraries
2023-07-09 21:50:22,980:INFO:Copying training dataset
2023-07-09 21:50:23,005:INFO:Defining folds
2023-07-09 21:50:23,005:INFO:Declaring metric variables
2023-07-09 21:50:23,026:INFO:Importing untrained model
2023-07-09 21:50:23,035:INFO:Lasso Least Angle Regression Imported successfully
2023-07-09 21:50:23,069:INFO:Starting cross validation
2023-07-09 21:50:23,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:23,193:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,204:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,218:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,240:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,644:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,647:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,655:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,658:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,942:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:23,970:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-09 21:50:24,639:INFO:Calculating mean and std
2023-07-09 21:50:24,641:INFO:Creating metrics dataframe
2023-07-09 21:50:24,827:INFO:Uploading results into container
2023-07-09 21:50:24,828:INFO:Uploading model into container now
2023-07-09 21:50:24,829:INFO:_master_model_container: 6
2023-07-09 21:50:24,829:INFO:_display_container: 2
2023-07-09 21:50:24,829:INFO:LassoLars(random_state=123)
2023-07-09 21:50:24,829:INFO:create_model() successfully completed......................................
2023-07-09 21:50:24,941:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:24,942:INFO:Creating metrics dataframe
2023-07-09 21:50:24,959:INFO:Initializing Orthogonal Matching Pursuit
2023-07-09 21:50:24,960:INFO:Total runtime is 0.5261700868606567 minutes
2023-07-09 21:50:24,968:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:24,968:INFO:Initializing create_model()
2023-07-09 21:50:24,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:24,969:INFO:Checking exceptions
2023-07-09 21:50:24,969:INFO:Importing libraries
2023-07-09 21:50:24,969:INFO:Copying training dataset
2023-07-09 21:50:24,979:INFO:Defining folds
2023-07-09 21:50:24,979:INFO:Declaring metric variables
2023-07-09 21:50:24,985:INFO:Importing untrained model
2023-07-09 21:50:24,992:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-09 21:50:25,004:INFO:Starting cross validation
2023-07-09 21:50:25,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:25,118:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,137:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,160:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,160:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,558:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,563:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,589:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,643:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,969:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:25,980:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-09 21:50:26,626:INFO:Calculating mean and std
2023-07-09 21:50:26,629:INFO:Creating metrics dataframe
2023-07-09 21:50:26,902:INFO:Uploading results into container
2023-07-09 21:50:26,903:INFO:Uploading model into container now
2023-07-09 21:50:26,904:INFO:_master_model_container: 7
2023-07-09 21:50:26,904:INFO:_display_container: 2
2023-07-09 21:50:26,905:INFO:OrthogonalMatchingPursuit()
2023-07-09 21:50:26,905:INFO:create_model() successfully completed......................................
2023-07-09 21:50:27,043:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:27,043:INFO:Creating metrics dataframe
2023-07-09 21:50:27,063:INFO:Initializing Bayesian Ridge
2023-07-09 21:50:27,063:INFO:Total runtime is 0.5612214684486388 minutes
2023-07-09 21:50:27,071:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:27,071:INFO:Initializing create_model()
2023-07-09 21:50:27,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:27,071:INFO:Checking exceptions
2023-07-09 21:50:27,071:INFO:Importing libraries
2023-07-09 21:50:27,071:INFO:Copying training dataset
2023-07-09 21:50:27,083:INFO:Defining folds
2023-07-09 21:50:27,083:INFO:Declaring metric variables
2023-07-09 21:50:27,091:INFO:Importing untrained model
2023-07-09 21:50:27,101:INFO:Bayesian Ridge Imported successfully
2023-07-09 21:50:27,117:INFO:Starting cross validation
2023-07-09 21:50:27,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:29,423:INFO:Calculating mean and std
2023-07-09 21:50:29,425:INFO:Creating metrics dataframe
2023-07-09 21:50:29,737:INFO:Uploading results into container
2023-07-09 21:50:29,738:INFO:Uploading model into container now
2023-07-09 21:50:29,739:INFO:_master_model_container: 8
2023-07-09 21:50:29,740:INFO:_display_container: 2
2023-07-09 21:50:29,740:INFO:BayesianRidge()
2023-07-09 21:50:29,740:INFO:create_model() successfully completed......................................
2023-07-09 21:50:29,888:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:29,888:INFO:Creating metrics dataframe
2023-07-09 21:50:29,926:INFO:Initializing Passive Aggressive Regressor
2023-07-09 21:50:29,926:INFO:Total runtime is 0.6089420477549234 minutes
2023-07-09 21:50:29,932:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:29,933:INFO:Initializing create_model()
2023-07-09 21:50:29,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:29,933:INFO:Checking exceptions
2023-07-09 21:50:29,933:INFO:Importing libraries
2023-07-09 21:50:29,934:INFO:Copying training dataset
2023-07-09 21:50:29,945:INFO:Defining folds
2023-07-09 21:50:29,945:INFO:Declaring metric variables
2023-07-09 21:50:29,951:INFO:Importing untrained model
2023-07-09 21:50:29,963:INFO:Passive Aggressive Regressor Imported successfully
2023-07-09 21:50:29,992:INFO:Starting cross validation
2023-07-09 21:50:29,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:31,723:INFO:Calculating mean and std
2023-07-09 21:50:31,725:INFO:Creating metrics dataframe
2023-07-09 21:50:31,943:INFO:Uploading results into container
2023-07-09 21:50:31,944:INFO:Uploading model into container now
2023-07-09 21:50:31,945:INFO:_master_model_container: 9
2023-07-09 21:50:31,945:INFO:_display_container: 2
2023-07-09 21:50:31,946:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-09 21:50:31,946:INFO:create_model() successfully completed......................................
2023-07-09 21:50:32,178:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:32,179:INFO:Creating metrics dataframe
2023-07-09 21:50:32,209:INFO:Initializing Huber Regressor
2023-07-09 21:50:32,209:INFO:Total runtime is 0.6469944357872008 minutes
2023-07-09 21:50:32,218:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:32,219:INFO:Initializing create_model()
2023-07-09 21:50:32,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:32,220:INFO:Checking exceptions
2023-07-09 21:50:32,220:INFO:Importing libraries
2023-07-09 21:50:32,221:INFO:Copying training dataset
2023-07-09 21:50:32,232:INFO:Defining folds
2023-07-09 21:50:32,233:INFO:Declaring metric variables
2023-07-09 21:50:32,242:INFO:Importing untrained model
2023-07-09 21:50:32,258:INFO:Huber Regressor Imported successfully
2023-07-09 21:50:32,269:INFO:Starting cross validation
2023-07-09 21:50:32,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:32,487:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:32,537:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:32,542:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:32,567:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,102:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,218:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,243:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,246:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,483:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,576:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-09 21:50:33,936:INFO:Calculating mean and std
2023-07-09 21:50:33,938:INFO:Creating metrics dataframe
2023-07-09 21:50:34,065:INFO:Uploading results into container
2023-07-09 21:50:34,066:INFO:Uploading model into container now
2023-07-09 21:50:34,067:INFO:_master_model_container: 10
2023-07-09 21:50:34,067:INFO:_display_container: 2
2023-07-09 21:50:34,067:INFO:HuberRegressor()
2023-07-09 21:50:34,067:INFO:create_model() successfully completed......................................
2023-07-09 21:50:34,178:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:34,179:INFO:Creating metrics dataframe
2023-07-09 21:50:34,199:INFO:Initializing K Neighbors Regressor
2023-07-09 21:50:34,199:INFO:Total runtime is 0.6801574190457661 minutes
2023-07-09 21:50:34,208:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:34,209:INFO:Initializing create_model()
2023-07-09 21:50:34,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:34,210:INFO:Checking exceptions
2023-07-09 21:50:34,210:INFO:Importing libraries
2023-07-09 21:50:34,210:INFO:Copying training dataset
2023-07-09 21:50:34,218:INFO:Defining folds
2023-07-09 21:50:34,219:INFO:Declaring metric variables
2023-07-09 21:50:34,225:INFO:Importing untrained model
2023-07-09 21:50:34,233:INFO:K Neighbors Regressor Imported successfully
2023-07-09 21:50:34,244:INFO:Starting cross validation
2023-07-09 21:50:34,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:35,611:INFO:Calculating mean and std
2023-07-09 21:50:35,613:INFO:Creating metrics dataframe
2023-07-09 21:50:35,748:INFO:Uploading results into container
2023-07-09 21:50:35,749:INFO:Uploading model into container now
2023-07-09 21:50:35,750:INFO:_master_model_container: 11
2023-07-09 21:50:35,752:INFO:_display_container: 2
2023-07-09 21:50:35,753:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-09 21:50:35,753:INFO:create_model() successfully completed......................................
2023-07-09 21:50:35,921:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:35,921:INFO:Creating metrics dataframe
2023-07-09 21:50:35,940:INFO:Initializing Decision Tree Regressor
2023-07-09 21:50:35,940:INFO:Total runtime is 0.709183919429779 minutes
2023-07-09 21:50:35,948:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:35,948:INFO:Initializing create_model()
2023-07-09 21:50:35,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:35,948:INFO:Checking exceptions
2023-07-09 21:50:35,949:INFO:Importing libraries
2023-07-09 21:50:35,949:INFO:Copying training dataset
2023-07-09 21:50:35,957:INFO:Defining folds
2023-07-09 21:50:35,958:INFO:Declaring metric variables
2023-07-09 21:50:35,964:INFO:Importing untrained model
2023-07-09 21:50:35,970:INFO:Decision Tree Regressor Imported successfully
2023-07-09 21:50:35,980:INFO:Starting cross validation
2023-07-09 21:50:35,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:37,334:INFO:Calculating mean and std
2023-07-09 21:50:37,336:INFO:Creating metrics dataframe
2023-07-09 21:50:37,460:INFO:Uploading results into container
2023-07-09 21:50:37,461:INFO:Uploading model into container now
2023-07-09 21:50:37,461:INFO:_master_model_container: 12
2023-07-09 21:50:37,461:INFO:_display_container: 2
2023-07-09 21:50:37,462:INFO:DecisionTreeRegressor(random_state=123)
2023-07-09 21:50:37,462:INFO:create_model() successfully completed......................................
2023-07-09 21:50:37,581:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:37,582:INFO:Creating metrics dataframe
2023-07-09 21:50:37,602:INFO:Initializing Random Forest Regressor
2023-07-09 21:50:37,602:INFO:Total runtime is 0.7368836164474487 minutes
2023-07-09 21:50:37,607:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:37,608:INFO:Initializing create_model()
2023-07-09 21:50:37,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:37,608:INFO:Checking exceptions
2023-07-09 21:50:37,608:INFO:Importing libraries
2023-07-09 21:50:37,609:INFO:Copying training dataset
2023-07-09 21:50:37,619:INFO:Defining folds
2023-07-09 21:50:37,620:INFO:Declaring metric variables
2023-07-09 21:50:37,625:INFO:Importing untrained model
2023-07-09 21:50:37,634:INFO:Random Forest Regressor Imported successfully
2023-07-09 21:50:37,644:INFO:Starting cross validation
2023-07-09 21:50:37,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:40,642:INFO:Calculating mean and std
2023-07-09 21:50:40,644:INFO:Creating metrics dataframe
2023-07-09 21:50:40,767:INFO:Uploading results into container
2023-07-09 21:50:40,768:INFO:Uploading model into container now
2023-07-09 21:50:40,768:INFO:_master_model_container: 13
2023-07-09 21:50:40,768:INFO:_display_container: 2
2023-07-09 21:50:40,769:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-09 21:50:40,769:INFO:create_model() successfully completed......................................
2023-07-09 21:50:40,880:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:40,880:INFO:Creating metrics dataframe
2023-07-09 21:50:40,902:INFO:Initializing Extra Trees Regressor
2023-07-09 21:50:40,902:INFO:Total runtime is 0.7918754339218139 minutes
2023-07-09 21:50:40,910:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:40,911:INFO:Initializing create_model()
2023-07-09 21:50:40,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:40,912:INFO:Checking exceptions
2023-07-09 21:50:40,912:INFO:Importing libraries
2023-07-09 21:50:40,912:INFO:Copying training dataset
2023-07-09 21:50:40,921:INFO:Defining folds
2023-07-09 21:50:40,922:INFO:Declaring metric variables
2023-07-09 21:50:40,929:INFO:Importing untrained model
2023-07-09 21:50:40,936:INFO:Extra Trees Regressor Imported successfully
2023-07-09 21:50:40,947:INFO:Starting cross validation
2023-07-09 21:50:40,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:43,781:INFO:Calculating mean and std
2023-07-09 21:50:43,784:INFO:Creating metrics dataframe
2023-07-09 21:50:43,925:INFO:Uploading results into container
2023-07-09 21:50:43,926:INFO:Uploading model into container now
2023-07-09 21:50:43,926:INFO:_master_model_container: 14
2023-07-09 21:50:43,927:INFO:_display_container: 2
2023-07-09 21:50:43,927:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-09 21:50:43,927:INFO:create_model() successfully completed......................................
2023-07-09 21:50:44,050:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:44,050:INFO:Creating metrics dataframe
2023-07-09 21:50:44,068:INFO:Initializing AdaBoost Regressor
2023-07-09 21:50:44,068:INFO:Total runtime is 0.8446407834688822 minutes
2023-07-09 21:50:44,075:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:44,076:INFO:Initializing create_model()
2023-07-09 21:50:44,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:44,076:INFO:Checking exceptions
2023-07-09 21:50:44,076:INFO:Importing libraries
2023-07-09 21:50:44,076:INFO:Copying training dataset
2023-07-09 21:50:44,087:INFO:Defining folds
2023-07-09 21:50:44,087:INFO:Declaring metric variables
2023-07-09 21:50:44,102:INFO:Importing untrained model
2023-07-09 21:50:44,112:INFO:AdaBoost Regressor Imported successfully
2023-07-09 21:50:44,130:INFO:Starting cross validation
2023-07-09 21:50:44,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:45,618:INFO:Calculating mean and std
2023-07-09 21:50:45,620:INFO:Creating metrics dataframe
2023-07-09 21:50:45,747:INFO:Uploading results into container
2023-07-09 21:50:45,748:INFO:Uploading model into container now
2023-07-09 21:50:45,748:INFO:_master_model_container: 15
2023-07-09 21:50:45,748:INFO:_display_container: 2
2023-07-09 21:50:45,748:INFO:AdaBoostRegressor(random_state=123)
2023-07-09 21:50:45,749:INFO:create_model() successfully completed......................................
2023-07-09 21:50:45,859:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:45,859:INFO:Creating metrics dataframe
2023-07-09 21:50:45,879:INFO:Initializing Gradient Boosting Regressor
2023-07-09 21:50:45,879:INFO:Total runtime is 0.8748293995857238 minutes
2023-07-09 21:50:45,886:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:45,887:INFO:Initializing create_model()
2023-07-09 21:50:45,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:45,887:INFO:Checking exceptions
2023-07-09 21:50:45,887:INFO:Importing libraries
2023-07-09 21:50:45,887:INFO:Copying training dataset
2023-07-09 21:50:45,898:INFO:Defining folds
2023-07-09 21:50:45,898:INFO:Declaring metric variables
2023-07-09 21:50:45,903:INFO:Importing untrained model
2023-07-09 21:50:45,912:INFO:Gradient Boosting Regressor Imported successfully
2023-07-09 21:50:45,923:INFO:Starting cross validation
2023-07-09 21:50:45,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:47,856:INFO:Calculating mean and std
2023-07-09 21:50:47,858:INFO:Creating metrics dataframe
2023-07-09 21:50:48,001:INFO:Uploading results into container
2023-07-09 21:50:48,002:INFO:Uploading model into container now
2023-07-09 21:50:48,004:INFO:_master_model_container: 16
2023-07-09 21:50:48,004:INFO:_display_container: 2
2023-07-09 21:50:48,004:INFO:GradientBoostingRegressor(random_state=123)
2023-07-09 21:50:48,004:INFO:create_model() successfully completed......................................
2023-07-09 21:50:48,136:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:48,136:INFO:Creating metrics dataframe
2023-07-09 21:50:48,164:INFO:Initializing Extreme Gradient Boosting
2023-07-09 21:50:48,165:INFO:Total runtime is 0.9129217187563577 minutes
2023-07-09 21:50:48,170:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:48,170:INFO:Initializing create_model()
2023-07-09 21:50:48,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:48,171:INFO:Checking exceptions
2023-07-09 21:50:48,171:INFO:Importing libraries
2023-07-09 21:50:48,171:INFO:Copying training dataset
2023-07-09 21:50:48,184:INFO:Defining folds
2023-07-09 21:50:48,185:INFO:Declaring metric variables
2023-07-09 21:50:48,203:INFO:Importing untrained model
2023-07-09 21:50:48,232:INFO:Extreme Gradient Boosting Imported successfully
2023-07-09 21:50:48,256:INFO:Starting cross validation
2023-07-09 21:50:48,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:50,051:INFO:Calculating mean and std
2023-07-09 21:50:50,057:INFO:Creating metrics dataframe
2023-07-09 21:50:50,367:INFO:Uploading results into container
2023-07-09 21:50:50,368:INFO:Uploading model into container now
2023-07-09 21:50:50,369:INFO:_master_model_container: 17
2023-07-09 21:50:50,369:INFO:_display_container: 2
2023-07-09 21:50:50,374:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2023-07-09 21:50:50,374:INFO:create_model() successfully completed......................................
2023-07-09 21:50:50,537:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:50,537:INFO:Creating metrics dataframe
2023-07-09 21:50:50,559:INFO:Initializing Light Gradient Boosting Machine
2023-07-09 21:50:50,559:INFO:Total runtime is 0.9528311491012572 minutes
2023-07-09 21:50:50,564:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:50,565:INFO:Initializing create_model()
2023-07-09 21:50:50,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:50,566:INFO:Checking exceptions
2023-07-09 21:50:50,566:INFO:Importing libraries
2023-07-09 21:50:50,566:INFO:Copying training dataset
2023-07-09 21:50:50,575:INFO:Defining folds
2023-07-09 21:50:50,575:INFO:Declaring metric variables
2023-07-09 21:50:50,581:INFO:Importing untrained model
2023-07-09 21:50:50,590:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-09 21:50:50,601:INFO:Starting cross validation
2023-07-09 21:50:50,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:54,466:INFO:Calculating mean and std
2023-07-09 21:50:54,470:INFO:Creating metrics dataframe
2023-07-09 21:50:54,725:INFO:Uploading results into container
2023-07-09 21:50:54,726:INFO:Uploading model into container now
2023-07-09 21:50:54,727:INFO:_master_model_container: 18
2023-07-09 21:50:54,727:INFO:_display_container: 2
2023-07-09 21:50:54,728:INFO:LGBMRegressor(random_state=123)
2023-07-09 21:50:54,728:INFO:create_model() successfully completed......................................
2023-07-09 21:50:55,061:INFO:SubProcess create_model() end ==================================
2023-07-09 21:50:55,061:INFO:Creating metrics dataframe
2023-07-09 21:50:55,110:INFO:Initializing CatBoost Regressor
2023-07-09 21:50:55,111:INFO:Total runtime is 1.028697117169698 minutes
2023-07-09 21:50:55,126:INFO:SubProcess create_model() called ==================================
2023-07-09 21:50:55,128:INFO:Initializing create_model()
2023-07-09 21:50:55,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:50:55,129:INFO:Checking exceptions
2023-07-09 21:50:55,129:INFO:Importing libraries
2023-07-09 21:50:55,129:INFO:Copying training dataset
2023-07-09 21:50:55,141:INFO:Defining folds
2023-07-09 21:50:55,142:INFO:Declaring metric variables
2023-07-09 21:50:55,167:INFO:Importing untrained model
2023-07-09 21:50:55,196:INFO:CatBoost Regressor Imported successfully
2023-07-09 21:50:55,221:INFO:Starting cross validation
2023-07-09 21:50:55,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:50:56,024:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:50:56,027:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:50:56,036:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:50:56,042:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:00,965:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,014:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,060:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,063:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,380:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,411:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,464:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:01,481:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:03,837:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:03,845:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:03,871:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:03,927:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:04,037:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:04,216:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:05,458:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:05,461:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:05,589:INFO:Calculating mean and std
2023-07-09 21:51:05,592:INFO:Creating metrics dataframe
2023-07-09 21:51:05,780:INFO:Uploading results into container
2023-07-09 21:51:05,781:INFO:Uploading model into container now
2023-07-09 21:51:05,782:INFO:_master_model_container: 19
2023-07-09 21:51:05,782:INFO:_display_container: 2
2023-07-09 21:51:05,783:INFO:<catboost.core.CatBoostRegressor object at 0x7fc9b115fdc0>
2023-07-09 21:51:05,783:INFO:create_model() successfully completed......................................
2023-07-09 21:51:05,931:INFO:SubProcess create_model() end ==================================
2023-07-09 21:51:05,931:INFO:Creating metrics dataframe
2023-07-09 21:51:05,953:INFO:Initializing Dummy Regressor
2023-07-09 21:51:05,954:INFO:Total runtime is 1.2094032684961953 minutes
2023-07-09 21:51:05,960:INFO:SubProcess create_model() called ==================================
2023-07-09 21:51:05,960:INFO:Initializing create_model()
2023-07-09 21:51:05,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b06a4e20>, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:51:05,961:INFO:Checking exceptions
2023-07-09 21:51:05,961:INFO:Importing libraries
2023-07-09 21:51:05,961:INFO:Copying training dataset
2023-07-09 21:51:05,969:INFO:Defining folds
2023-07-09 21:51:05,969:INFO:Declaring metric variables
2023-07-09 21:51:05,998:INFO:Importing untrained model
2023-07-09 21:51:06,006:INFO:Dummy Regressor Imported successfully
2023-07-09 21:51:06,018:INFO:Starting cross validation
2023-07-09 21:51:06,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-09 21:51:08,740:INFO:Calculating mean and std
2023-07-09 21:51:08,742:INFO:Creating metrics dataframe
2023-07-09 21:51:08,946:INFO:Uploading results into container
2023-07-09 21:51:08,947:INFO:Uploading model into container now
2023-07-09 21:51:08,949:INFO:_master_model_container: 20
2023-07-09 21:51:08,949:INFO:_display_container: 2
2023-07-09 21:51:08,950:INFO:DummyRegressor()
2023-07-09 21:51:08,951:INFO:create_model() successfully completed......................................
2023-07-09 21:51:09,168:INFO:SubProcess create_model() end ==================================
2023-07-09 21:51:09,168:INFO:Creating metrics dataframe
2023-07-09 21:51:09,490:INFO:Initializing create_model()
2023-07-09 21:51:09,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fc9b115fdc0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:51:09,490:INFO:Checking exceptions
2023-07-09 21:51:09,494:INFO:Importing libraries
2023-07-09 21:51:09,495:INFO:Copying training dataset
2023-07-09 21:51:09,502:INFO:Defining folds
2023-07-09 21:51:09,502:INFO:Declaring metric variables
2023-07-09 21:51:09,502:INFO:Importing untrained model
2023-07-09 21:51:09,503:INFO:Declaring custom model
2023-07-09 21:51:09,503:INFO:CatBoost Regressor Imported successfully
2023-07-09 21:51:09,505:INFO:Cross validation set to False
2023-07-09 21:51:09,506:INFO:Fitting Model
2023-07-09 21:51:09,733:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-09 21:51:12,061:INFO:<catboost.core.CatBoostRegressor object at 0x7fc9b2558460>
2023-07-09 21:51:12,061:INFO:create_model() successfully completed......................................
2023-07-09 21:51:12,397:INFO:Initializing create_model()
2023-07-09 21:51:12,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:51:12,398:INFO:Checking exceptions
2023-07-09 21:51:12,409:INFO:Importing libraries
2023-07-09 21:51:12,409:INFO:Copying training dataset
2023-07-09 21:51:12,422:INFO:Defining folds
2023-07-09 21:51:12,422:INFO:Declaring metric variables
2023-07-09 21:51:12,423:INFO:Importing untrained model
2023-07-09 21:51:12,423:INFO:Declaring custom model
2023-07-09 21:51:12,424:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-09 21:51:12,425:INFO:Cross validation set to False
2023-07-09 21:51:12,425:INFO:Fitting Model
2023-07-09 21:51:14,921:INFO:LGBMRegressor(random_state=123)
2023-07-09 21:51:14,921:INFO:create_model() successfully completed......................................
2023-07-09 21:51:15,153:INFO:Initializing create_model()
2023-07-09 21:51:15,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-09 21:51:15,154:INFO:Checking exceptions
2023-07-09 21:51:15,157:INFO:Importing libraries
2023-07-09 21:51:15,158:INFO:Copying training dataset
2023-07-09 21:51:15,180:INFO:Defining folds
2023-07-09 21:51:15,181:INFO:Declaring metric variables
2023-07-09 21:51:15,182:INFO:Importing untrained model
2023-07-09 21:51:15,188:INFO:Declaring custom model
2023-07-09 21:51:15,190:INFO:Extra Trees Regressor Imported successfully
2023-07-09 21:51:15,192:INFO:Cross validation set to False
2023-07-09 21:51:15,193:INFO:Fitting Model
2023-07-09 21:51:16,016:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-09 21:51:16,017:INFO:create_model() successfully completed......................................
2023-07-09 21:51:16,704:INFO:_master_model_container: 20
2023-07-09 21:51:16,704:INFO:_display_container: 2
2023-07-09 21:51:16,705:INFO:[<catboost.core.CatBoostRegressor object at 0x7fc9b2558460>, LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-07-09 21:51:16,705:INFO:compare_models() successfully completed......................................
2023-07-09 21:51:42,733:INFO:Initializing plot_model()
2023-07-09 21:51:42,734:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7fc9b2558460>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, system=True)
2023-07-09 21:51:42,735:INFO:Checking exceptions
2023-07-09 21:51:42,744:INFO:Preloading libraries
2023-07-09 21:51:42,749:INFO:Copying training dataset
2023-07-09 21:51:42,749:INFO:Plot type: feature_all
2023-07-09 21:51:42,787:WARNING:No coef_ found. Trying feature_importances_
2023-07-09 21:51:43,366:INFO:Visual Rendered Successfully
2023-07-09 21:51:43,539:INFO:plot_model() successfully completed......................................
2023-07-09 22:03:37,614:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 187, in _parallel_build_trees
    tree.fit(X, y, sample_weight=sample_weight, check_input=False)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1315, in fit
    super().fit(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 250, in fit
    raise ValueError(
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 450, in fit
    trees = Parallel(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 446, in result
    return self.__get_result()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-09 22:03:37,625:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.93658598 0.92685497 0.91285547 0.93578109 0.92663491 0.9072913
        nan 0.90203139 0.91285543        nan]
  warnings.warn(

2023-07-10 09:31:52,390:INFO:Initializing compare_models()
2023-07-10 09:31:52,398:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-10 09:31:52,398:INFO:Checking exceptions
2023-07-10 09:31:52,581:INFO:Preparing display monitor
2023-07-10 09:31:52,732:INFO:Initializing Linear Regression
2023-07-10 09:31:52,733:INFO:Total runtime is 6.302197774251302e-06 minutes
2023-07-10 09:31:52,738:INFO:SubProcess create_model() called ==================================
2023-07-10 09:31:52,738:INFO:Initializing create_model()
2023-07-10 09:31:52,738:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:31:52,738:INFO:Checking exceptions
2023-07-10 09:31:52,738:INFO:Importing libraries
2023-07-10 09:31:52,739:INFO:Copying training dataset
2023-07-10 09:31:52,746:INFO:Defining folds
2023-07-10 09:31:52,746:INFO:Declaring metric variables
2023-07-10 09:31:52,752:INFO:Importing untrained model
2023-07-10 09:31:52,757:INFO:Linear Regression Imported successfully
2023-07-10 09:31:52,767:INFO:Starting cross validation
2023-07-10 09:31:52,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:19,868:INFO:Calculating mean and std
2023-07-10 09:32:19,871:INFO:Creating metrics dataframe
2023-07-10 09:32:20,025:INFO:Uploading results into container
2023-07-10 09:32:20,026:INFO:Uploading model into container now
2023-07-10 09:32:20,027:INFO:_master_model_container: 21
2023-07-10 09:32:20,027:INFO:_display_container: 3
2023-07-10 09:32:20,027:INFO:LinearRegression(n_jobs=-1)
2023-07-10 09:32:20,027:INFO:create_model() successfully completed......................................
2023-07-10 09:32:20,231:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:20,231:INFO:Creating metrics dataframe
2023-07-10 09:32:20,250:INFO:Initializing Lasso Regression
2023-07-10 09:32:20,250:INFO:Total runtime is 0.45863078435262045 minutes
2023-07-10 09:32:20,262:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:20,263:INFO:Initializing create_model()
2023-07-10 09:32:20,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:20,263:INFO:Checking exceptions
2023-07-10 09:32:20,263:INFO:Importing libraries
2023-07-10 09:32:20,264:INFO:Copying training dataset
2023-07-10 09:32:20,274:INFO:Defining folds
2023-07-10 09:32:20,274:INFO:Declaring metric variables
2023-07-10 09:32:20,281:INFO:Importing untrained model
2023-07-10 09:32:20,289:INFO:Lasso Regression Imported successfully
2023-07-10 09:32:20,301:INFO:Starting cross validation
2023-07-10 09:32:20,304:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:21,482:INFO:Calculating mean and std
2023-07-10 09:32:21,484:INFO:Creating metrics dataframe
2023-07-10 09:32:21,609:INFO:Uploading results into container
2023-07-10 09:32:21,609:INFO:Uploading model into container now
2023-07-10 09:32:21,610:INFO:_master_model_container: 22
2023-07-10 09:32:21,610:INFO:_display_container: 3
2023-07-10 09:32:21,610:INFO:Lasso(random_state=123)
2023-07-10 09:32:21,611:INFO:create_model() successfully completed......................................
2023-07-10 09:32:21,791:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:21,791:INFO:Creating metrics dataframe
2023-07-10 09:32:21,808:INFO:Initializing Ridge Regression
2023-07-10 09:32:21,808:INFO:Total runtime is 0.48459810415903726 minutes
2023-07-10 09:32:21,813:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:21,814:INFO:Initializing create_model()
2023-07-10 09:32:21,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:21,814:INFO:Checking exceptions
2023-07-10 09:32:21,814:INFO:Importing libraries
2023-07-10 09:32:21,815:INFO:Copying training dataset
2023-07-10 09:32:21,826:INFO:Defining folds
2023-07-10 09:32:21,826:INFO:Declaring metric variables
2023-07-10 09:32:21,834:INFO:Importing untrained model
2023-07-10 09:32:21,844:INFO:Ridge Regression Imported successfully
2023-07-10 09:32:21,858:INFO:Starting cross validation
2023-07-10 09:32:21,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:23,112:INFO:Calculating mean and std
2023-07-10 09:32:23,117:INFO:Creating metrics dataframe
2023-07-10 09:32:23,251:INFO:Uploading results into container
2023-07-10 09:32:23,252:INFO:Uploading model into container now
2023-07-10 09:32:23,253:INFO:_master_model_container: 23
2023-07-10 09:32:23,253:INFO:_display_container: 3
2023-07-10 09:32:23,254:INFO:Ridge(random_state=123)
2023-07-10 09:32:23,254:INFO:create_model() successfully completed......................................
2023-07-10 09:32:23,439:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:23,440:INFO:Creating metrics dataframe
2023-07-10 09:32:23,456:INFO:Initializing Elastic Net
2023-07-10 09:32:23,457:INFO:Total runtime is 0.5120731194814047 minutes
2023-07-10 09:32:23,464:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:23,464:INFO:Initializing create_model()
2023-07-10 09:32:23,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:23,465:INFO:Checking exceptions
2023-07-10 09:32:23,465:INFO:Importing libraries
2023-07-10 09:32:23,465:INFO:Copying training dataset
2023-07-10 09:32:23,476:INFO:Defining folds
2023-07-10 09:32:23,477:INFO:Declaring metric variables
2023-07-10 09:32:23,485:INFO:Importing untrained model
2023-07-10 09:32:23,493:INFO:Elastic Net Imported successfully
2023-07-10 09:32:23,505:INFO:Starting cross validation
2023-07-10 09:32:23,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:24,940:INFO:Calculating mean and std
2023-07-10 09:32:24,942:INFO:Creating metrics dataframe
2023-07-10 09:32:25,069:INFO:Uploading results into container
2023-07-10 09:32:25,070:INFO:Uploading model into container now
2023-07-10 09:32:25,070:INFO:_master_model_container: 24
2023-07-10 09:32:25,070:INFO:_display_container: 3
2023-07-10 09:32:25,070:INFO:ElasticNet(random_state=123)
2023-07-10 09:32:25,070:INFO:create_model() successfully completed......................................
2023-07-10 09:32:25,253:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:25,253:INFO:Creating metrics dataframe
2023-07-10 09:32:25,276:INFO:Initializing Least Angle Regression
2023-07-10 09:32:25,276:INFO:Total runtime is 0.542396334807078 minutes
2023-07-10 09:32:25,281:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:25,282:INFO:Initializing create_model()
2023-07-10 09:32:25,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:25,282:INFO:Checking exceptions
2023-07-10 09:32:25,282:INFO:Importing libraries
2023-07-10 09:32:25,283:INFO:Copying training dataset
2023-07-10 09:32:25,295:INFO:Defining folds
2023-07-10 09:32:25,296:INFO:Declaring metric variables
2023-07-10 09:32:25,302:INFO:Importing untrained model
2023-07-10 09:32:25,311:INFO:Least Angle Regression Imported successfully
2023-07-10 09:32:25,322:INFO:Starting cross validation
2023-07-10 09:32:25,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:25,469:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,472:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,479:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,498:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,843:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,843:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,856:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:25,869:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:26,127:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:26,134:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:26,612:INFO:Calculating mean and std
2023-07-10 09:32:26,614:INFO:Creating metrics dataframe
2023-07-10 09:32:26,736:INFO:Uploading results into container
2023-07-10 09:32:26,737:INFO:Uploading model into container now
2023-07-10 09:32:26,737:INFO:_master_model_container: 25
2023-07-10 09:32:26,737:INFO:_display_container: 3
2023-07-10 09:32:26,739:INFO:Lars(random_state=123)
2023-07-10 09:32:26,739:INFO:create_model() successfully completed......................................
2023-07-10 09:32:26,917:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:26,917:INFO:Creating metrics dataframe
2023-07-10 09:32:26,933:INFO:Initializing Lasso Least Angle Regression
2023-07-10 09:32:26,933:INFO:Total runtime is 0.5700167179107666 minutes
2023-07-10 09:32:26,938:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:26,939:INFO:Initializing create_model()
2023-07-10 09:32:26,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:26,939:INFO:Checking exceptions
2023-07-10 09:32:26,939:INFO:Importing libraries
2023-07-10 09:32:26,940:INFO:Copying training dataset
2023-07-10 09:32:26,952:INFO:Defining folds
2023-07-10 09:32:26,952:INFO:Declaring metric variables
2023-07-10 09:32:26,959:INFO:Importing untrained model
2023-07-10 09:32:26,966:INFO:Lasso Least Angle Regression Imported successfully
2023-07-10 09:32:26,976:INFO:Starting cross validation
2023-07-10 09:32:26,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:27,082:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,106:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,155:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,184:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,478:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,500:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,509:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,512:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,687:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:27,737:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:32:28,168:INFO:Calculating mean and std
2023-07-10 09:32:28,170:INFO:Creating metrics dataframe
2023-07-10 09:32:28,304:INFO:Uploading results into container
2023-07-10 09:32:28,304:INFO:Uploading model into container now
2023-07-10 09:32:28,305:INFO:_master_model_container: 26
2023-07-10 09:32:28,305:INFO:_display_container: 3
2023-07-10 09:32:28,306:INFO:LassoLars(random_state=123)
2023-07-10 09:32:28,306:INFO:create_model() successfully completed......................................
2023-07-10 09:32:28,488:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:28,488:INFO:Creating metrics dataframe
2023-07-10 09:32:28,505:INFO:Initializing Orthogonal Matching Pursuit
2023-07-10 09:32:28,506:INFO:Total runtime is 0.5962236046791076 minutes
2023-07-10 09:32:28,510:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:28,511:INFO:Initializing create_model()
2023-07-10 09:32:28,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:28,511:INFO:Checking exceptions
2023-07-10 09:32:28,511:INFO:Importing libraries
2023-07-10 09:32:28,511:INFO:Copying training dataset
2023-07-10 09:32:28,520:INFO:Defining folds
2023-07-10 09:32:28,521:INFO:Declaring metric variables
2023-07-10 09:32:28,527:INFO:Importing untrained model
2023-07-10 09:32:28,535:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-10 09:32:28,547:INFO:Starting cross validation
2023-07-10 09:32:28,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:28,652:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:28,690:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:28,702:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:28,743:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:28,994:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:29,019:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:29,023:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:29,091:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:29,356:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:29,367:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:32:30,019:INFO:Calculating mean and std
2023-07-10 09:32:30,021:INFO:Creating metrics dataframe
2023-07-10 09:32:30,173:INFO:Uploading results into container
2023-07-10 09:32:30,175:INFO:Uploading model into container now
2023-07-10 09:32:30,175:INFO:_master_model_container: 27
2023-07-10 09:32:30,175:INFO:_display_container: 3
2023-07-10 09:32:30,176:INFO:OrthogonalMatchingPursuit()
2023-07-10 09:32:30,176:INFO:create_model() successfully completed......................................
2023-07-10 09:32:30,364:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:30,364:INFO:Creating metrics dataframe
2023-07-10 09:32:30,379:INFO:Initializing Bayesian Ridge
2023-07-10 09:32:30,379:INFO:Total runtime is 0.62745015223821 minutes
2023-07-10 09:32:30,389:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:30,390:INFO:Initializing create_model()
2023-07-10 09:32:30,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:30,390:INFO:Checking exceptions
2023-07-10 09:32:30,390:INFO:Importing libraries
2023-07-10 09:32:30,390:INFO:Copying training dataset
2023-07-10 09:32:30,400:INFO:Defining folds
2023-07-10 09:32:30,400:INFO:Declaring metric variables
2023-07-10 09:32:30,408:INFO:Importing untrained model
2023-07-10 09:32:30,416:INFO:Bayesian Ridge Imported successfully
2023-07-10 09:32:30,431:INFO:Starting cross validation
2023-07-10 09:32:30,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:31,746:INFO:Calculating mean and std
2023-07-10 09:32:31,749:INFO:Creating metrics dataframe
2023-07-10 09:32:31,922:INFO:Uploading results into container
2023-07-10 09:32:31,923:INFO:Uploading model into container now
2023-07-10 09:32:31,923:INFO:_master_model_container: 28
2023-07-10 09:32:31,924:INFO:_display_container: 3
2023-07-10 09:32:31,924:INFO:BayesianRidge()
2023-07-10 09:32:31,924:INFO:create_model() successfully completed......................................
2023-07-10 09:32:32,099:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:32,100:INFO:Creating metrics dataframe
2023-07-10 09:32:32,119:INFO:Initializing Passive Aggressive Regressor
2023-07-10 09:32:32,119:INFO:Total runtime is 0.6564481854438782 minutes
2023-07-10 09:32:32,129:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:32,131:INFO:Initializing create_model()
2023-07-10 09:32:32,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:32,131:INFO:Checking exceptions
2023-07-10 09:32:32,131:INFO:Importing libraries
2023-07-10 09:32:32,132:INFO:Copying training dataset
2023-07-10 09:32:32,143:INFO:Defining folds
2023-07-10 09:32:32,143:INFO:Declaring metric variables
2023-07-10 09:32:32,152:INFO:Importing untrained model
2023-07-10 09:32:32,164:INFO:Passive Aggressive Regressor Imported successfully
2023-07-10 09:32:32,175:INFO:Starting cross validation
2023-07-10 09:32:32,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:33,418:INFO:Calculating mean and std
2023-07-10 09:32:33,420:INFO:Creating metrics dataframe
2023-07-10 09:32:33,551:INFO:Uploading results into container
2023-07-10 09:32:33,552:INFO:Uploading model into container now
2023-07-10 09:32:33,553:INFO:_master_model_container: 29
2023-07-10 09:32:33,553:INFO:_display_container: 3
2023-07-10 09:32:33,553:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-10 09:32:33,553:INFO:create_model() successfully completed......................................
2023-07-10 09:32:33,733:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:33,733:INFO:Creating metrics dataframe
2023-07-10 09:32:33,754:INFO:Initializing Huber Regressor
2023-07-10 09:32:33,754:INFO:Total runtime is 0.6836916009585062 minutes
2023-07-10 09:32:33,762:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:33,762:INFO:Initializing create_model()
2023-07-10 09:32:33,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:33,763:INFO:Checking exceptions
2023-07-10 09:32:33,763:INFO:Importing libraries
2023-07-10 09:32:33,763:INFO:Copying training dataset
2023-07-10 09:32:33,773:INFO:Defining folds
2023-07-10 09:32:33,774:INFO:Declaring metric variables
2023-07-10 09:32:33,780:INFO:Importing untrained model
2023-07-10 09:32:33,789:INFO:Huber Regressor Imported successfully
2023-07-10 09:32:33,802:INFO:Starting cross validation
2023-07-10 09:32:33,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:34,113:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-10 09:32:34,829:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-10 09:32:34,829:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-10 09:32:35,306:INFO:Calculating mean and std
2023-07-10 09:32:35,309:INFO:Creating metrics dataframe
2023-07-10 09:32:35,458:INFO:Uploading results into container
2023-07-10 09:32:35,459:INFO:Uploading model into container now
2023-07-10 09:32:35,459:INFO:_master_model_container: 30
2023-07-10 09:32:35,459:INFO:_display_container: 3
2023-07-10 09:32:35,459:INFO:HuberRegressor()
2023-07-10 09:32:35,459:INFO:create_model() successfully completed......................................
2023-07-10 09:32:35,635:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:35,635:INFO:Creating metrics dataframe
2023-07-10 09:32:35,657:INFO:Initializing K Neighbors Regressor
2023-07-10 09:32:35,657:INFO:Total runtime is 0.7154071529706318 minutes
2023-07-10 09:32:35,665:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:35,666:INFO:Initializing create_model()
2023-07-10 09:32:35,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:35,667:INFO:Checking exceptions
2023-07-10 09:32:35,667:INFO:Importing libraries
2023-07-10 09:32:35,667:INFO:Copying training dataset
2023-07-10 09:32:35,675:INFO:Defining folds
2023-07-10 09:32:35,675:INFO:Declaring metric variables
2023-07-10 09:32:35,682:INFO:Importing untrained model
2023-07-10 09:32:35,698:INFO:K Neighbors Regressor Imported successfully
2023-07-10 09:32:35,710:INFO:Starting cross validation
2023-07-10 09:32:35,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:36,939:INFO:Calculating mean and std
2023-07-10 09:32:36,940:INFO:Creating metrics dataframe
2023-07-10 09:32:37,066:INFO:Uploading results into container
2023-07-10 09:32:37,067:INFO:Uploading model into container now
2023-07-10 09:32:37,067:INFO:_master_model_container: 31
2023-07-10 09:32:37,068:INFO:_display_container: 3
2023-07-10 09:32:37,068:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-10 09:32:37,068:INFO:create_model() successfully completed......................................
2023-07-10 09:32:37,247:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:37,247:INFO:Creating metrics dataframe
2023-07-10 09:32:37,265:INFO:Initializing Decision Tree Regressor
2023-07-10 09:32:37,265:INFO:Total runtime is 0.7422160704930623 minutes
2023-07-10 09:32:37,270:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:37,270:INFO:Initializing create_model()
2023-07-10 09:32:37,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:37,271:INFO:Checking exceptions
2023-07-10 09:32:37,271:INFO:Importing libraries
2023-07-10 09:32:37,271:INFO:Copying training dataset
2023-07-10 09:32:37,279:INFO:Defining folds
2023-07-10 09:32:37,280:INFO:Declaring metric variables
2023-07-10 09:32:37,287:INFO:Importing untrained model
2023-07-10 09:32:37,296:INFO:Decision Tree Regressor Imported successfully
2023-07-10 09:32:37,311:INFO:Starting cross validation
2023-07-10 09:32:37,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:38,625:INFO:Calculating mean and std
2023-07-10 09:32:38,628:INFO:Creating metrics dataframe
2023-07-10 09:32:38,796:INFO:Uploading results into container
2023-07-10 09:32:38,797:INFO:Uploading model into container now
2023-07-10 09:32:38,798:INFO:_master_model_container: 32
2023-07-10 09:32:38,798:INFO:_display_container: 3
2023-07-10 09:32:38,799:INFO:DecisionTreeRegressor(random_state=123)
2023-07-10 09:32:38,799:INFO:create_model() successfully completed......................................
2023-07-10 09:32:38,996:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:38,996:INFO:Creating metrics dataframe
2023-07-10 09:32:39,016:INFO:Initializing Random Forest Regressor
2023-07-10 09:32:39,016:INFO:Total runtime is 0.771389071146647 minutes
2023-07-10 09:32:39,023:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:39,024:INFO:Initializing create_model()
2023-07-10 09:32:39,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:39,024:INFO:Checking exceptions
2023-07-10 09:32:39,024:INFO:Importing libraries
2023-07-10 09:32:39,024:INFO:Copying training dataset
2023-07-10 09:32:39,036:INFO:Defining folds
2023-07-10 09:32:39,036:INFO:Declaring metric variables
2023-07-10 09:32:39,042:INFO:Importing untrained model
2023-07-10 09:32:39,051:INFO:Random Forest Regressor Imported successfully
2023-07-10 09:32:39,062:INFO:Starting cross validation
2023-07-10 09:32:39,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:40,731:INFO:Calculating mean and std
2023-07-10 09:32:40,733:INFO:Creating metrics dataframe
2023-07-10 09:32:40,898:INFO:Uploading results into container
2023-07-10 09:32:40,899:INFO:Uploading model into container now
2023-07-10 09:32:40,900:INFO:_master_model_container: 33
2023-07-10 09:32:40,900:INFO:_display_container: 3
2023-07-10 09:32:40,900:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:32:40,901:INFO:create_model() successfully completed......................................
2023-07-10 09:32:41,086:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:41,086:INFO:Creating metrics dataframe
2023-07-10 09:32:41,107:INFO:Initializing Extra Trees Regressor
2023-07-10 09:32:41,107:INFO:Total runtime is 0.806240435441335 minutes
2023-07-10 09:32:41,111:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:41,112:INFO:Initializing create_model()
2023-07-10 09:32:41,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:41,112:INFO:Checking exceptions
2023-07-10 09:32:41,113:INFO:Importing libraries
2023-07-10 09:32:41,113:INFO:Copying training dataset
2023-07-10 09:32:41,121:INFO:Defining folds
2023-07-10 09:32:41,122:INFO:Declaring metric variables
2023-07-10 09:32:41,129:INFO:Importing untrained model
2023-07-10 09:32:41,140:INFO:Extra Trees Regressor Imported successfully
2023-07-10 09:32:41,156:INFO:Starting cross validation
2023-07-10 09:32:41,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:43,415:INFO:Calculating mean and std
2023-07-10 09:32:43,417:INFO:Creating metrics dataframe
2023-07-10 09:32:43,553:INFO:Uploading results into container
2023-07-10 09:32:43,553:INFO:Uploading model into container now
2023-07-10 09:32:43,554:INFO:_master_model_container: 34
2023-07-10 09:32:43,554:INFO:_display_container: 3
2023-07-10 09:32:43,554:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:32:43,554:INFO:create_model() successfully completed......................................
2023-07-10 09:32:43,738:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:43,738:INFO:Creating metrics dataframe
2023-07-10 09:32:43,757:INFO:Initializing AdaBoost Regressor
2023-07-10 09:32:43,757:INFO:Total runtime is 0.8504125515619912 minutes
2023-07-10 09:32:43,766:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:43,766:INFO:Initializing create_model()
2023-07-10 09:32:43,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:43,767:INFO:Checking exceptions
2023-07-10 09:32:43,767:INFO:Importing libraries
2023-07-10 09:32:43,767:INFO:Copying training dataset
2023-07-10 09:32:43,777:INFO:Defining folds
2023-07-10 09:32:43,777:INFO:Declaring metric variables
2023-07-10 09:32:43,783:INFO:Importing untrained model
2023-07-10 09:32:43,794:INFO:AdaBoost Regressor Imported successfully
2023-07-10 09:32:43,805:INFO:Starting cross validation
2023-07-10 09:32:43,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:45,462:INFO:Calculating mean and std
2023-07-10 09:32:45,464:INFO:Creating metrics dataframe
2023-07-10 09:32:45,588:INFO:Uploading results into container
2023-07-10 09:32:45,588:INFO:Uploading model into container now
2023-07-10 09:32:45,589:INFO:_master_model_container: 35
2023-07-10 09:32:45,589:INFO:_display_container: 3
2023-07-10 09:32:45,589:INFO:AdaBoostRegressor(random_state=123)
2023-07-10 09:32:45,589:INFO:create_model() successfully completed......................................
2023-07-10 09:32:45,760:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:45,760:INFO:Creating metrics dataframe
2023-07-10 09:32:45,789:INFO:Initializing Gradient Boosting Regressor
2023-07-10 09:32:45,790:INFO:Total runtime is 0.8842861692110696 minutes
2023-07-10 09:32:45,798:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:45,799:INFO:Initializing create_model()
2023-07-10 09:32:45,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:45,799:INFO:Checking exceptions
2023-07-10 09:32:45,800:INFO:Importing libraries
2023-07-10 09:32:45,800:INFO:Copying training dataset
2023-07-10 09:32:45,828:INFO:Defining folds
2023-07-10 09:32:45,829:INFO:Declaring metric variables
2023-07-10 09:32:45,842:INFO:Importing untrained model
2023-07-10 09:32:45,854:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 09:32:45,866:INFO:Starting cross validation
2023-07-10 09:32:45,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:47,751:INFO:Calculating mean and std
2023-07-10 09:32:47,753:INFO:Creating metrics dataframe
2023-07-10 09:32:47,881:INFO:Uploading results into container
2023-07-10 09:32:47,882:INFO:Uploading model into container now
2023-07-10 09:32:47,883:INFO:_master_model_container: 36
2023-07-10 09:32:47,883:INFO:_display_container: 3
2023-07-10 09:32:47,883:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 09:32:47,884:INFO:create_model() successfully completed......................................
2023-07-10 09:32:48,070:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:48,070:INFO:Creating metrics dataframe
2023-07-10 09:32:48,090:INFO:Initializing Extreme Gradient Boosting
2023-07-10 09:32:48,090:INFO:Total runtime is 0.922632865111033 minutes
2023-07-10 09:32:48,095:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:48,095:INFO:Initializing create_model()
2023-07-10 09:32:48,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:48,096:INFO:Checking exceptions
2023-07-10 09:32:48,096:INFO:Importing libraries
2023-07-10 09:32:48,096:INFO:Copying training dataset
2023-07-10 09:32:48,107:INFO:Defining folds
2023-07-10 09:32:48,108:INFO:Declaring metric variables
2023-07-10 09:32:48,113:INFO:Importing untrained model
2023-07-10 09:32:48,122:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 09:32:48,136:INFO:Starting cross validation
2023-07-10 09:32:48,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:49,504:INFO:Calculating mean and std
2023-07-10 09:32:49,506:INFO:Creating metrics dataframe
2023-07-10 09:32:49,639:INFO:Uploading results into container
2023-07-10 09:32:49,639:INFO:Uploading model into container now
2023-07-10 09:32:49,640:INFO:_master_model_container: 37
2023-07-10 09:32:49,640:INFO:_display_container: 3
2023-07-10 09:32:49,641:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2023-07-10 09:32:49,641:INFO:create_model() successfully completed......................................
2023-07-10 09:32:49,817:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:49,817:INFO:Creating metrics dataframe
2023-07-10 09:32:49,854:INFO:Initializing Light Gradient Boosting Machine
2023-07-10 09:32:49,854:INFO:Total runtime is 0.9520257552464803 minutes
2023-07-10 09:32:49,859:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:49,860:INFO:Initializing create_model()
2023-07-10 09:32:49,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:49,860:INFO:Checking exceptions
2023-07-10 09:32:49,860:INFO:Importing libraries
2023-07-10 09:32:49,860:INFO:Copying training dataset
2023-07-10 09:32:49,875:INFO:Defining folds
2023-07-10 09:32:49,876:INFO:Declaring metric variables
2023-07-10 09:32:49,883:INFO:Importing untrained model
2023-07-10 09:32:49,892:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 09:32:49,903:INFO:Starting cross validation
2023-07-10 09:32:49,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:53,412:INFO:Calculating mean and std
2023-07-10 09:32:53,414:INFO:Creating metrics dataframe
2023-07-10 09:32:53,544:INFO:Uploading results into container
2023-07-10 09:32:53,545:INFO:Uploading model into container now
2023-07-10 09:32:53,545:INFO:_master_model_container: 38
2023-07-10 09:32:53,546:INFO:_display_container: 3
2023-07-10 09:32:53,546:INFO:LGBMRegressor(random_state=123)
2023-07-10 09:32:53,546:INFO:create_model() successfully completed......................................
2023-07-10 09:32:53,727:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:53,727:INFO:Creating metrics dataframe
2023-07-10 09:32:53,748:INFO:Initializing CatBoost Regressor
2023-07-10 09:32:53,748:INFO:Total runtime is 1.0169336199760437 minutes
2023-07-10 09:32:53,753:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:53,754:INFO:Initializing create_model()
2023-07-10 09:32:53,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:53,754:INFO:Checking exceptions
2023-07-10 09:32:53,754:INFO:Importing libraries
2023-07-10 09:32:53,755:INFO:Copying training dataset
2023-07-10 09:32:53,766:INFO:Defining folds
2023-07-10 09:32:53,767:INFO:Declaring metric variables
2023-07-10 09:32:53,775:INFO:Importing untrained model
2023-07-10 09:32:53,789:INFO:CatBoost Regressor Imported successfully
2023-07-10 09:32:53,801:INFO:Starting cross validation
2023-07-10 09:32:53,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:55,084:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,084:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,085:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,113:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,414:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,421:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,481:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,484:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,713:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:55,722:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:32:56,246:INFO:Calculating mean and std
2023-07-10 09:32:56,248:INFO:Creating metrics dataframe
2023-07-10 09:32:56,407:INFO:Uploading results into container
2023-07-10 09:32:56,408:INFO:Uploading model into container now
2023-07-10 09:32:56,409:INFO:_master_model_container: 39
2023-07-10 09:32:56,410:INFO:_display_container: 3
2023-07-10 09:32:56,410:INFO:<catboost.core.CatBoostRegressor object at 0x7fc99abdea60>
2023-07-10 09:32:56,410:INFO:create_model() successfully completed......................................
2023-07-10 09:32:56,596:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:56,597:INFO:Creating metrics dataframe
2023-07-10 09:32:56,619:INFO:Initializing Dummy Regressor
2023-07-10 09:32:56,620:INFO:Total runtime is 1.0647884527842204 minutes
2023-07-10 09:32:56,627:INFO:SubProcess create_model() called ==================================
2023-07-10 09:32:56,627:INFO:Initializing create_model()
2023-07-10 09:32:56,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9b2e0de20>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:56,627:INFO:Checking exceptions
2023-07-10 09:32:56,627:INFO:Importing libraries
2023-07-10 09:32:56,628:INFO:Copying training dataset
2023-07-10 09:32:56,638:INFO:Defining folds
2023-07-10 09:32:56,638:INFO:Declaring metric variables
2023-07-10 09:32:56,656:INFO:Importing untrained model
2023-07-10 09:32:56,662:INFO:Dummy Regressor Imported successfully
2023-07-10 09:32:56,672:INFO:Starting cross validation
2023-07-10 09:32:56,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:32:57,894:INFO:Calculating mean and std
2023-07-10 09:32:57,896:INFO:Creating metrics dataframe
2023-07-10 09:32:58,031:INFO:Uploading results into container
2023-07-10 09:32:58,032:INFO:Uploading model into container now
2023-07-10 09:32:58,032:INFO:_master_model_container: 40
2023-07-10 09:32:58,032:INFO:_display_container: 3
2023-07-10 09:32:58,033:INFO:DummyRegressor()
2023-07-10 09:32:58,033:INFO:create_model() successfully completed......................................
2023-07-10 09:32:58,214:INFO:SubProcess create_model() end ==================================
2023-07-10 09:32:58,215:INFO:Creating metrics dataframe
2023-07-10 09:32:58,261:INFO:Initializing create_model()
2023-07-10 09:32:58,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fc99abdea60>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:58,261:INFO:Checking exceptions
2023-07-10 09:32:58,266:INFO:Importing libraries
2023-07-10 09:32:58,267:INFO:Copying training dataset
2023-07-10 09:32:58,274:INFO:Defining folds
2023-07-10 09:32:58,274:INFO:Declaring metric variables
2023-07-10 09:32:58,275:INFO:Importing untrained model
2023-07-10 09:32:58,275:INFO:Declaring custom model
2023-07-10 09:32:58,276:INFO:CatBoost Regressor Imported successfully
2023-07-10 09:32:58,277:INFO:Cross validation set to False
2023-07-10 09:32:58,278:INFO:Fitting Model
2023-07-10 09:32:58,493:INFO:<catboost.core.CatBoostRegressor object at 0x7fc997d39460>
2023-07-10 09:32:58,493:INFO:create_model() successfully completed......................................
2023-07-10 09:32:58,714:INFO:Initializing create_model()
2023-07-10 09:32:58,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:58,715:INFO:Checking exceptions
2023-07-10 09:32:58,718:INFO:Importing libraries
2023-07-10 09:32:58,718:INFO:Copying training dataset
2023-07-10 09:32:58,724:INFO:Defining folds
2023-07-10 09:32:58,724:INFO:Declaring metric variables
2023-07-10 09:32:58,725:INFO:Importing untrained model
2023-07-10 09:32:58,725:INFO:Declaring custom model
2023-07-10 09:32:58,727:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 09:32:58,728:INFO:Cross validation set to False
2023-07-10 09:32:58,729:INFO:Fitting Model
2023-07-10 09:32:58,880:INFO:LGBMRegressor(random_state=123)
2023-07-10 09:32:58,880:INFO:create_model() successfully completed......................................
2023-07-10 09:32:59,093:INFO:Initializing create_model()
2023-07-10 09:32:59,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:59,094:INFO:Checking exceptions
2023-07-10 09:32:59,098:INFO:Importing libraries
2023-07-10 09:32:59,098:INFO:Copying training dataset
2023-07-10 09:32:59,108:INFO:Defining folds
2023-07-10 09:32:59,108:INFO:Declaring metric variables
2023-07-10 09:32:59,109:INFO:Importing untrained model
2023-07-10 09:32:59,109:INFO:Declaring custom model
2023-07-10 09:32:59,110:INFO:Extra Trees Regressor Imported successfully
2023-07-10 09:32:59,111:INFO:Cross validation set to False
2023-07-10 09:32:59,111:INFO:Fitting Model
2023-07-10 09:32:59,343:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:32:59,343:INFO:create_model() successfully completed......................................
2023-07-10 09:32:59,533:INFO:Initializing create_model()
2023-07-10 09:32:59,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:32:59,534:INFO:Checking exceptions
2023-07-10 09:32:59,538:INFO:Importing libraries
2023-07-10 09:32:59,538:INFO:Copying training dataset
2023-07-10 09:32:59,550:INFO:Defining folds
2023-07-10 09:32:59,550:INFO:Declaring metric variables
2023-07-10 09:32:59,551:INFO:Importing untrained model
2023-07-10 09:32:59,551:INFO:Declaring custom model
2023-07-10 09:32:59,552:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 09:32:59,553:INFO:Cross validation set to False
2023-07-10 09:32:59,553:INFO:Fitting Model
2023-07-10 09:32:59,782:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 09:32:59,782:INFO:create_model() successfully completed......................................
2023-07-10 09:33:00,057:INFO:_master_model_container: 40
2023-07-10 09:33:00,058:INFO:_display_container: 3
2023-07-10 09:33:00,061:INFO:[<catboost.core.CatBoostRegressor object at 0x7fc997d39460>, LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123)]
2023-07-10 09:33:00,061:INFO:compare_models() successfully completed......................................
2023-07-10 09:33:32,093:INFO:Initializing plot_model()
2023-07-10 09:33:32,093:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, system=True)
2023-07-10 09:33:32,093:INFO:Checking exceptions
2023-07-10 09:33:32,105:INFO:Preloading libraries
2023-07-10 09:33:32,120:INFO:Copying training dataset
2023-07-10 09:33:32,120:INFO:Plot type: feature_all
2023-07-10 09:33:32,148:WARNING:No coef_ found. Trying feature_importances_
2023-07-10 09:33:32,370:INFO:Visual Rendered Successfully
2023-07-10 09:33:32,624:INFO:plot_model() successfully completed......................................
2023-07-10 09:41:49,243:INFO:Initializing compare_models()
2023-07-10 09:41:49,243:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-10 09:41:49,244:INFO:Checking exceptions
2023-07-10 09:41:49,248:INFO:Preparing display monitor
2023-07-10 09:41:49,334:INFO:Initializing Linear Regression
2023-07-10 09:41:49,335:INFO:Total runtime is 6.33398691813151e-06 minutes
2023-07-10 09:41:49,341:INFO:SubProcess create_model() called ==================================
2023-07-10 09:41:49,343:INFO:Initializing create_model()
2023-07-10 09:41:49,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:41:49,344:INFO:Checking exceptions
2023-07-10 09:41:49,344:INFO:Importing libraries
2023-07-10 09:41:49,344:INFO:Copying training dataset
2023-07-10 09:41:49,351:INFO:Defining folds
2023-07-10 09:41:49,352:INFO:Declaring metric variables
2023-07-10 09:41:49,358:INFO:Importing untrained model
2023-07-10 09:41:49,363:INFO:Linear Regression Imported successfully
2023-07-10 09:41:49,374:INFO:Starting cross validation
2023-07-10 09:41:49,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:00,135:INFO:Calculating mean and std
2023-07-10 09:42:00,139:INFO:Creating metrics dataframe
2023-07-10 09:42:00,270:INFO:Uploading results into container
2023-07-10 09:42:00,271:INFO:Uploading model into container now
2023-07-10 09:42:00,272:INFO:_master_model_container: 41
2023-07-10 09:42:00,272:INFO:_display_container: 4
2023-07-10 09:42:00,272:INFO:LinearRegression(n_jobs=-1)
2023-07-10 09:42:00,272:INFO:create_model() successfully completed......................................
2023-07-10 09:42:00,477:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:00,478:INFO:Creating metrics dataframe
2023-07-10 09:42:00,502:INFO:Initializing Lasso Regression
2023-07-10 09:42:00,502:INFO:Total runtime is 0.1861262838045756 minutes
2023-07-10 09:42:00,509:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:00,509:INFO:Initializing create_model()
2023-07-10 09:42:00,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:00,510:INFO:Checking exceptions
2023-07-10 09:42:00,510:INFO:Importing libraries
2023-07-10 09:42:00,510:INFO:Copying training dataset
2023-07-10 09:42:00,526:INFO:Defining folds
2023-07-10 09:42:00,527:INFO:Declaring metric variables
2023-07-10 09:42:00,534:INFO:Importing untrained model
2023-07-10 09:42:00,542:INFO:Lasso Regression Imported successfully
2023-07-10 09:42:00,552:INFO:Starting cross validation
2023-07-10 09:42:00,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:03,768:INFO:Calculating mean and std
2023-07-10 09:42:03,770:INFO:Creating metrics dataframe
2023-07-10 09:42:03,909:INFO:Uploading results into container
2023-07-10 09:42:03,910:INFO:Uploading model into container now
2023-07-10 09:42:03,911:INFO:_master_model_container: 42
2023-07-10 09:42:03,911:INFO:_display_container: 4
2023-07-10 09:42:03,911:INFO:Lasso(random_state=123)
2023-07-10 09:42:03,912:INFO:create_model() successfully completed......................................
2023-07-10 09:42:04,089:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:04,089:INFO:Creating metrics dataframe
2023-07-10 09:42:04,105:INFO:Initializing Ridge Regression
2023-07-10 09:42:04,105:INFO:Total runtime is 0.24617860317230225 minutes
2023-07-10 09:42:04,111:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:04,112:INFO:Initializing create_model()
2023-07-10 09:42:04,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:04,112:INFO:Checking exceptions
2023-07-10 09:42:04,112:INFO:Importing libraries
2023-07-10 09:42:04,113:INFO:Copying training dataset
2023-07-10 09:42:04,122:INFO:Defining folds
2023-07-10 09:42:04,122:INFO:Declaring metric variables
2023-07-10 09:42:04,129:INFO:Importing untrained model
2023-07-10 09:42:04,137:INFO:Ridge Regression Imported successfully
2023-07-10 09:42:04,147:INFO:Starting cross validation
2023-07-10 09:42:04,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:05,581:INFO:Calculating mean and std
2023-07-10 09:42:05,582:INFO:Creating metrics dataframe
2023-07-10 09:42:05,707:INFO:Uploading results into container
2023-07-10 09:42:05,707:INFO:Uploading model into container now
2023-07-10 09:42:05,708:INFO:_master_model_container: 43
2023-07-10 09:42:05,708:INFO:_display_container: 4
2023-07-10 09:42:05,708:INFO:Ridge(random_state=123)
2023-07-10 09:42:05,708:INFO:create_model() successfully completed......................................
2023-07-10 09:42:05,890:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:05,890:INFO:Creating metrics dataframe
2023-07-10 09:42:05,907:INFO:Initializing Elastic Net
2023-07-10 09:42:05,907:INFO:Total runtime is 0.2762175997098287 minutes
2023-07-10 09:42:05,912:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:05,913:INFO:Initializing create_model()
2023-07-10 09:42:05,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:05,913:INFO:Checking exceptions
2023-07-10 09:42:05,914:INFO:Importing libraries
2023-07-10 09:42:05,915:INFO:Copying training dataset
2023-07-10 09:42:05,925:INFO:Defining folds
2023-07-10 09:42:05,925:INFO:Declaring metric variables
2023-07-10 09:42:05,933:INFO:Importing untrained model
2023-07-10 09:42:05,939:INFO:Elastic Net Imported successfully
2023-07-10 09:42:05,950:INFO:Starting cross validation
2023-07-10 09:42:05,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:07,263:INFO:Calculating mean and std
2023-07-10 09:42:07,266:INFO:Creating metrics dataframe
2023-07-10 09:42:07,401:INFO:Uploading results into container
2023-07-10 09:42:07,402:INFO:Uploading model into container now
2023-07-10 09:42:07,403:INFO:_master_model_container: 44
2023-07-10 09:42:07,403:INFO:_display_container: 4
2023-07-10 09:42:07,404:INFO:ElasticNet(random_state=123)
2023-07-10 09:42:07,404:INFO:create_model() successfully completed......................................
2023-07-10 09:42:07,584:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:07,584:INFO:Creating metrics dataframe
2023-07-10 09:42:07,602:INFO:Initializing Least Angle Regression
2023-07-10 09:42:07,603:INFO:Total runtime is 0.3044704516728719 minutes
2023-07-10 09:42:07,607:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:07,608:INFO:Initializing create_model()
2023-07-10 09:42:07,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:07,608:INFO:Checking exceptions
2023-07-10 09:42:07,608:INFO:Importing libraries
2023-07-10 09:42:07,608:INFO:Copying training dataset
2023-07-10 09:42:07,617:INFO:Defining folds
2023-07-10 09:42:07,618:INFO:Declaring metric variables
2023-07-10 09:42:07,624:INFO:Importing untrained model
2023-07-10 09:42:07,632:INFO:Least Angle Regression Imported successfully
2023-07-10 09:42:07,643:INFO:Starting cross validation
2023-07-10 09:42:07,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:07,754:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:07,778:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:07,831:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:07,836:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,075:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,132:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,178:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,206:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,439:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,457:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:08,899:INFO:Calculating mean and std
2023-07-10 09:42:08,901:INFO:Creating metrics dataframe
2023-07-10 09:42:09,032:INFO:Uploading results into container
2023-07-10 09:42:09,032:INFO:Uploading model into container now
2023-07-10 09:42:09,033:INFO:_master_model_container: 45
2023-07-10 09:42:09,034:INFO:_display_container: 4
2023-07-10 09:42:09,034:INFO:Lars(random_state=123)
2023-07-10 09:42:09,034:INFO:create_model() successfully completed......................................
2023-07-10 09:42:09,215:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:09,215:INFO:Creating metrics dataframe
2023-07-10 09:42:09,235:INFO:Initializing Lasso Least Angle Regression
2023-07-10 09:42:09,236:INFO:Total runtime is 0.331685201327006 minutes
2023-07-10 09:42:09,245:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:09,246:INFO:Initializing create_model()
2023-07-10 09:42:09,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:09,246:INFO:Checking exceptions
2023-07-10 09:42:09,247:INFO:Importing libraries
2023-07-10 09:42:09,247:INFO:Copying training dataset
2023-07-10 09:42:09,260:INFO:Defining folds
2023-07-10 09:42:09,260:INFO:Declaring metric variables
2023-07-10 09:42:09,268:INFO:Importing untrained model
2023-07-10 09:42:09,277:INFO:Lasso Least Angle Regression Imported successfully
2023-07-10 09:42:09,290:INFO:Starting cross validation
2023-07-10 09:42:09,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:09,399:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,416:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,452:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,489:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,775:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,819:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,836:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:09,839:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:10,094:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:10,144:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:42:10,699:INFO:Calculating mean and std
2023-07-10 09:42:10,701:INFO:Creating metrics dataframe
2023-07-10 09:42:10,860:INFO:Uploading results into container
2023-07-10 09:42:10,861:INFO:Uploading model into container now
2023-07-10 09:42:10,862:INFO:_master_model_container: 46
2023-07-10 09:42:10,862:INFO:_display_container: 4
2023-07-10 09:42:10,863:INFO:LassoLars(random_state=123)
2023-07-10 09:42:10,863:INFO:create_model() successfully completed......................................
2023-07-10 09:42:11,055:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:11,055:INFO:Creating metrics dataframe
2023-07-10 09:42:11,074:INFO:Initializing Orthogonal Matching Pursuit
2023-07-10 09:42:11,074:INFO:Total runtime is 0.3623266657193502 minutes
2023-07-10 09:42:11,083:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:11,084:INFO:Initializing create_model()
2023-07-10 09:42:11,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:11,084:INFO:Checking exceptions
2023-07-10 09:42:11,084:INFO:Importing libraries
2023-07-10 09:42:11,084:INFO:Copying training dataset
2023-07-10 09:42:11,093:INFO:Defining folds
2023-07-10 09:42:11,094:INFO:Declaring metric variables
2023-07-10 09:42:11,106:INFO:Importing untrained model
2023-07-10 09:42:11,117:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-10 09:42:11,130:INFO:Starting cross validation
2023-07-10 09:42:11,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:11,201:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,228:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,255:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,285:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,671:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,712:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,744:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:11,745:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:12,217:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:12,307:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:42:12,744:INFO:Calculating mean and std
2023-07-10 09:42:12,746:INFO:Creating metrics dataframe
2023-07-10 09:42:12,876:INFO:Uploading results into container
2023-07-10 09:42:12,877:INFO:Uploading model into container now
2023-07-10 09:42:12,877:INFO:_master_model_container: 47
2023-07-10 09:42:12,877:INFO:_display_container: 4
2023-07-10 09:42:12,878:INFO:OrthogonalMatchingPursuit()
2023-07-10 09:42:12,878:INFO:create_model() successfully completed......................................
2023-07-10 09:42:13,062:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:13,063:INFO:Creating metrics dataframe
2023-07-10 09:42:13,096:INFO:Initializing Bayesian Ridge
2023-07-10 09:42:13,096:INFO:Total runtime is 0.39602956771850584 minutes
2023-07-10 09:42:13,125:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:13,126:INFO:Initializing create_model()
2023-07-10 09:42:13,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:13,126:INFO:Checking exceptions
2023-07-10 09:42:13,126:INFO:Importing libraries
2023-07-10 09:42:13,126:INFO:Copying training dataset
2023-07-10 09:42:13,175:INFO:Defining folds
2023-07-10 09:42:13,175:INFO:Declaring metric variables
2023-07-10 09:42:13,184:INFO:Importing untrained model
2023-07-10 09:42:13,190:INFO:Bayesian Ridge Imported successfully
2023-07-10 09:42:13,201:INFO:Starting cross validation
2023-07-10 09:42:13,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:14,396:INFO:Calculating mean and std
2023-07-10 09:42:14,398:INFO:Creating metrics dataframe
2023-07-10 09:42:14,534:INFO:Uploading results into container
2023-07-10 09:42:14,535:INFO:Uploading model into container now
2023-07-10 09:42:14,535:INFO:_master_model_container: 48
2023-07-10 09:42:14,536:INFO:_display_container: 4
2023-07-10 09:42:14,536:INFO:BayesianRidge()
2023-07-10 09:42:14,536:INFO:create_model() successfully completed......................................
2023-07-10 09:42:14,720:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:14,720:INFO:Creating metrics dataframe
2023-07-10 09:42:14,738:INFO:Initializing Passive Aggressive Regressor
2023-07-10 09:42:14,738:INFO:Total runtime is 0.42339193423589067 minutes
2023-07-10 09:42:14,742:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:14,743:INFO:Initializing create_model()
2023-07-10 09:42:14,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:14,743:INFO:Checking exceptions
2023-07-10 09:42:14,744:INFO:Importing libraries
2023-07-10 09:42:14,744:INFO:Copying training dataset
2023-07-10 09:42:14,752:INFO:Defining folds
2023-07-10 09:42:14,753:INFO:Declaring metric variables
2023-07-10 09:42:14,760:INFO:Importing untrained model
2023-07-10 09:42:14,770:INFO:Passive Aggressive Regressor Imported successfully
2023-07-10 09:42:14,785:INFO:Starting cross validation
2023-07-10 09:42:14,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:16,099:INFO:Calculating mean and std
2023-07-10 09:42:16,101:INFO:Creating metrics dataframe
2023-07-10 09:42:16,228:INFO:Uploading results into container
2023-07-10 09:42:16,229:INFO:Uploading model into container now
2023-07-10 09:42:16,229:INFO:_master_model_container: 49
2023-07-10 09:42:16,230:INFO:_display_container: 4
2023-07-10 09:42:16,230:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-10 09:42:16,230:INFO:create_model() successfully completed......................................
2023-07-10 09:42:16,414:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:16,414:INFO:Creating metrics dataframe
2023-07-10 09:42:16,432:INFO:Initializing Huber Regressor
2023-07-10 09:42:16,432:INFO:Total runtime is 0.45163390239079787 minutes
2023-07-10 09:42:16,437:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:16,438:INFO:Initializing create_model()
2023-07-10 09:42:16,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:16,438:INFO:Checking exceptions
2023-07-10 09:42:16,438:INFO:Importing libraries
2023-07-10 09:42:16,439:INFO:Copying training dataset
2023-07-10 09:42:16,447:INFO:Defining folds
2023-07-10 09:42:16,448:INFO:Declaring metric variables
2023-07-10 09:42:16,454:INFO:Importing untrained model
2023-07-10 09:42:16,463:INFO:Huber Regressor Imported successfully
2023-07-10 09:42:16,475:INFO:Starting cross validation
2023-07-10 09:42:16,476:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:17,396:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-10 09:42:17,839:INFO:Calculating mean and std
2023-07-10 09:42:17,841:INFO:Creating metrics dataframe
2023-07-10 09:42:17,975:INFO:Uploading results into container
2023-07-10 09:42:17,975:INFO:Uploading model into container now
2023-07-10 09:42:17,976:INFO:_master_model_container: 50
2023-07-10 09:42:17,976:INFO:_display_container: 4
2023-07-10 09:42:17,976:INFO:HuberRegressor()
2023-07-10 09:42:17,977:INFO:create_model() successfully completed......................................
2023-07-10 09:42:18,162:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:18,163:INFO:Creating metrics dataframe
2023-07-10 09:42:18,181:INFO:Initializing K Neighbors Regressor
2023-07-10 09:42:18,181:INFO:Total runtime is 0.4807786663373311 minutes
2023-07-10 09:42:18,189:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:18,190:INFO:Initializing create_model()
2023-07-10 09:42:18,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:18,190:INFO:Checking exceptions
2023-07-10 09:42:18,190:INFO:Importing libraries
2023-07-10 09:42:18,190:INFO:Copying training dataset
2023-07-10 09:42:18,200:INFO:Defining folds
2023-07-10 09:42:18,201:INFO:Declaring metric variables
2023-07-10 09:42:18,208:INFO:Importing untrained model
2023-07-10 09:42:18,216:INFO:K Neighbors Regressor Imported successfully
2023-07-10 09:42:18,229:INFO:Starting cross validation
2023-07-10 09:42:18,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:19,515:INFO:Calculating mean and std
2023-07-10 09:42:19,516:INFO:Creating metrics dataframe
2023-07-10 09:42:19,639:INFO:Uploading results into container
2023-07-10 09:42:19,640:INFO:Uploading model into container now
2023-07-10 09:42:19,640:INFO:_master_model_container: 51
2023-07-10 09:42:19,640:INFO:_display_container: 4
2023-07-10 09:42:19,641:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-10 09:42:19,641:INFO:create_model() successfully completed......................................
2023-07-10 09:42:19,817:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:19,817:INFO:Creating metrics dataframe
2023-07-10 09:42:19,839:INFO:Initializing Decision Tree Regressor
2023-07-10 09:42:19,839:INFO:Total runtime is 0.5084155321121215 minutes
2023-07-10 09:42:19,847:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:19,848:INFO:Initializing create_model()
2023-07-10 09:42:19,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:19,848:INFO:Checking exceptions
2023-07-10 09:42:19,848:INFO:Importing libraries
2023-07-10 09:42:19,848:INFO:Copying training dataset
2023-07-10 09:42:19,857:INFO:Defining folds
2023-07-10 09:42:19,857:INFO:Declaring metric variables
2023-07-10 09:42:19,873:INFO:Importing untrained model
2023-07-10 09:42:19,889:INFO:Decision Tree Regressor Imported successfully
2023-07-10 09:42:19,901:INFO:Starting cross validation
2023-07-10 09:42:19,903:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:21,155:INFO:Calculating mean and std
2023-07-10 09:42:21,157:INFO:Creating metrics dataframe
2023-07-10 09:42:21,295:INFO:Uploading results into container
2023-07-10 09:42:21,296:INFO:Uploading model into container now
2023-07-10 09:42:21,296:INFO:_master_model_container: 52
2023-07-10 09:42:21,296:INFO:_display_container: 4
2023-07-10 09:42:21,296:INFO:DecisionTreeRegressor(random_state=123)
2023-07-10 09:42:21,296:INFO:create_model() successfully completed......................................
2023-07-10 09:42:21,477:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:21,478:INFO:Creating metrics dataframe
2023-07-10 09:42:21,500:INFO:Initializing Random Forest Regressor
2023-07-10 09:42:21,500:INFO:Total runtime is 0.5360931833585103 minutes
2023-07-10 09:42:21,511:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:21,512:INFO:Initializing create_model()
2023-07-10 09:42:21,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:21,512:INFO:Checking exceptions
2023-07-10 09:42:21,512:INFO:Importing libraries
2023-07-10 09:42:21,512:INFO:Copying training dataset
2023-07-10 09:42:21,523:INFO:Defining folds
2023-07-10 09:42:21,523:INFO:Declaring metric variables
2023-07-10 09:42:21,546:INFO:Importing untrained model
2023-07-10 09:42:21,558:INFO:Random Forest Regressor Imported successfully
2023-07-10 09:42:21,576:INFO:Starting cross validation
2023-07-10 09:42:21,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:23,224:INFO:Calculating mean and std
2023-07-10 09:42:23,226:INFO:Creating metrics dataframe
2023-07-10 09:42:23,369:INFO:Uploading results into container
2023-07-10 09:42:23,370:INFO:Uploading model into container now
2023-07-10 09:42:23,371:INFO:_master_model_container: 53
2023-07-10 09:42:23,371:INFO:_display_container: 4
2023-07-10 09:42:23,371:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:42:23,371:INFO:create_model() successfully completed......................................
2023-07-10 09:42:23,556:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:23,556:INFO:Creating metrics dataframe
2023-07-10 09:42:23,588:INFO:Initializing Extra Trees Regressor
2023-07-10 09:42:23,588:INFO:Total runtime is 0.5708978494008382 minutes
2023-07-10 09:42:23,595:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:23,595:INFO:Initializing create_model()
2023-07-10 09:42:23,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:23,596:INFO:Checking exceptions
2023-07-10 09:42:23,596:INFO:Importing libraries
2023-07-10 09:42:23,596:INFO:Copying training dataset
2023-07-10 09:42:23,608:INFO:Defining folds
2023-07-10 09:42:23,609:INFO:Declaring metric variables
2023-07-10 09:42:23,617:INFO:Importing untrained model
2023-07-10 09:42:23,628:INFO:Extra Trees Regressor Imported successfully
2023-07-10 09:42:23,642:INFO:Starting cross validation
2023-07-10 09:42:23,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:25,934:INFO:Calculating mean and std
2023-07-10 09:42:25,936:INFO:Creating metrics dataframe
2023-07-10 09:42:26,084:INFO:Uploading results into container
2023-07-10 09:42:26,085:INFO:Uploading model into container now
2023-07-10 09:42:26,085:INFO:_master_model_container: 54
2023-07-10 09:42:26,085:INFO:_display_container: 4
2023-07-10 09:42:26,086:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:42:26,086:INFO:create_model() successfully completed......................................
2023-07-10 09:42:26,273:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:26,273:INFO:Creating metrics dataframe
2023-07-10 09:42:26,305:INFO:Initializing AdaBoost Regressor
2023-07-10 09:42:26,305:INFO:Total runtime is 0.6161749323209127 minutes
2023-07-10 09:42:26,312:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:26,315:INFO:Initializing create_model()
2023-07-10 09:42:26,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:26,315:INFO:Checking exceptions
2023-07-10 09:42:26,315:INFO:Importing libraries
2023-07-10 09:42:26,315:INFO:Copying training dataset
2023-07-10 09:42:26,325:INFO:Defining folds
2023-07-10 09:42:26,326:INFO:Declaring metric variables
2023-07-10 09:42:26,334:INFO:Importing untrained model
2023-07-10 09:42:26,343:INFO:AdaBoost Regressor Imported successfully
2023-07-10 09:42:26,358:INFO:Starting cross validation
2023-07-10 09:42:26,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:27,934:INFO:Calculating mean and std
2023-07-10 09:42:27,936:INFO:Creating metrics dataframe
2023-07-10 09:42:28,067:INFO:Uploading results into container
2023-07-10 09:42:28,068:INFO:Uploading model into container now
2023-07-10 09:42:28,068:INFO:_master_model_container: 55
2023-07-10 09:42:28,068:INFO:_display_container: 4
2023-07-10 09:42:28,069:INFO:AdaBoostRegressor(random_state=123)
2023-07-10 09:42:28,069:INFO:create_model() successfully completed......................................
2023-07-10 09:42:28,259:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:28,259:INFO:Creating metrics dataframe
2023-07-10 09:42:28,282:INFO:Initializing Gradient Boosting Regressor
2023-07-10 09:42:28,282:INFO:Total runtime is 0.6491289496421814 minutes
2023-07-10 09:42:28,291:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:28,291:INFO:Initializing create_model()
2023-07-10 09:42:28,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:28,292:INFO:Checking exceptions
2023-07-10 09:42:28,292:INFO:Importing libraries
2023-07-10 09:42:28,292:INFO:Copying training dataset
2023-07-10 09:42:28,304:INFO:Defining folds
2023-07-10 09:42:28,304:INFO:Declaring metric variables
2023-07-10 09:42:28,319:INFO:Importing untrained model
2023-07-10 09:42:28,325:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 09:42:28,339:INFO:Starting cross validation
2023-07-10 09:42:28,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:29,789:INFO:Calculating mean and std
2023-07-10 09:42:29,791:INFO:Creating metrics dataframe
2023-07-10 09:42:29,914:INFO:Uploading results into container
2023-07-10 09:42:29,915:INFO:Uploading model into container now
2023-07-10 09:42:29,916:INFO:_master_model_container: 56
2023-07-10 09:42:29,916:INFO:_display_container: 4
2023-07-10 09:42:29,916:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 09:42:29,916:INFO:create_model() successfully completed......................................
2023-07-10 09:42:30,104:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:30,105:INFO:Creating metrics dataframe
2023-07-10 09:42:30,131:INFO:Initializing Extreme Gradient Boosting
2023-07-10 09:42:30,132:INFO:Total runtime is 0.679951798915863 minutes
2023-07-10 09:42:30,137:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:30,138:INFO:Initializing create_model()
2023-07-10 09:42:30,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:30,138:INFO:Checking exceptions
2023-07-10 09:42:30,138:INFO:Importing libraries
2023-07-10 09:42:30,138:INFO:Copying training dataset
2023-07-10 09:42:30,147:INFO:Defining folds
2023-07-10 09:42:30,148:INFO:Declaring metric variables
2023-07-10 09:42:30,166:INFO:Importing untrained model
2023-07-10 09:42:30,175:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 09:42:30,189:INFO:Starting cross validation
2023-07-10 09:42:30,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:32,281:INFO:Calculating mean and std
2023-07-10 09:42:32,286:INFO:Creating metrics dataframe
2023-07-10 09:42:32,498:INFO:Uploading results into container
2023-07-10 09:42:32,499:INFO:Uploading model into container now
2023-07-10 09:42:32,499:INFO:_master_model_container: 57
2023-07-10 09:42:32,500:INFO:_display_container: 4
2023-07-10 09:42:32,501:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2023-07-10 09:42:32,501:INFO:create_model() successfully completed......................................
2023-07-10 09:42:32,692:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:32,693:INFO:Creating metrics dataframe
2023-07-10 09:42:32,717:INFO:Initializing Light Gradient Boosting Machine
2023-07-10 09:42:32,717:INFO:Total runtime is 0.723039432366689 minutes
2023-07-10 09:42:32,721:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:32,722:INFO:Initializing create_model()
2023-07-10 09:42:32,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:32,722:INFO:Checking exceptions
2023-07-10 09:42:32,723:INFO:Importing libraries
2023-07-10 09:42:32,723:INFO:Copying training dataset
2023-07-10 09:42:32,732:INFO:Defining folds
2023-07-10 09:42:32,732:INFO:Declaring metric variables
2023-07-10 09:42:32,741:INFO:Importing untrained model
2023-07-10 09:42:32,750:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 09:42:32,762:INFO:Starting cross validation
2023-07-10 09:42:32,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:36,745:INFO:Calculating mean and std
2023-07-10 09:42:36,746:INFO:Creating metrics dataframe
2023-07-10 09:42:37,038:INFO:Uploading results into container
2023-07-10 09:42:37,039:INFO:Uploading model into container now
2023-07-10 09:42:37,040:INFO:_master_model_container: 58
2023-07-10 09:42:37,040:INFO:_display_container: 4
2023-07-10 09:42:37,041:INFO:LGBMRegressor(random_state=123)
2023-07-10 09:42:37,041:INFO:create_model() successfully completed......................................
2023-07-10 09:42:37,377:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:37,377:INFO:Creating metrics dataframe
2023-07-10 09:42:37,407:INFO:Initializing CatBoost Regressor
2023-07-10 09:42:37,407:INFO:Total runtime is 0.801208233833313 minutes
2023-07-10 09:42:37,413:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:37,413:INFO:Initializing create_model()
2023-07-10 09:42:37,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:37,413:INFO:Checking exceptions
2023-07-10 09:42:37,414:INFO:Importing libraries
2023-07-10 09:42:37,414:INFO:Copying training dataset
2023-07-10 09:42:37,424:INFO:Defining folds
2023-07-10 09:42:37,424:INFO:Declaring metric variables
2023-07-10 09:42:37,432:INFO:Importing untrained model
2023-07-10 09:42:37,439:INFO:CatBoost Regressor Imported successfully
2023-07-10 09:42:37,450:INFO:Starting cross validation
2023-07-10 09:42:37,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:37,884:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:37,975:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,049:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,054:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,448:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,495:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,506:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,508:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,745:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:38,784:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:42:39,324:INFO:Calculating mean and std
2023-07-10 09:42:39,327:INFO:Creating metrics dataframe
2023-07-10 09:42:39,496:INFO:Uploading results into container
2023-07-10 09:42:39,497:INFO:Uploading model into container now
2023-07-10 09:42:39,498:INFO:_master_model_container: 59
2023-07-10 09:42:39,498:INFO:_display_container: 4
2023-07-10 09:42:39,498:INFO:<catboost.core.CatBoostRegressor object at 0x7fc999ca28b0>
2023-07-10 09:42:39,498:INFO:create_model() successfully completed......................................
2023-07-10 09:42:39,689:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:39,689:INFO:Creating metrics dataframe
2023-07-10 09:42:39,712:INFO:Initializing Dummy Regressor
2023-07-10 09:42:39,712:INFO:Total runtime is 0.8396282990773518 minutes
2023-07-10 09:42:39,718:INFO:SubProcess create_model() called ==================================
2023-07-10 09:42:39,718:INFO:Initializing create_model()
2023-07-10 09:42:39,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc9986072e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:39,719:INFO:Checking exceptions
2023-07-10 09:42:39,719:INFO:Importing libraries
2023-07-10 09:42:39,719:INFO:Copying training dataset
2023-07-10 09:42:39,729:INFO:Defining folds
2023-07-10 09:42:39,731:INFO:Declaring metric variables
2023-07-10 09:42:39,741:INFO:Importing untrained model
2023-07-10 09:42:39,748:INFO:Dummy Regressor Imported successfully
2023-07-10 09:42:39,759:INFO:Starting cross validation
2023-07-10 09:42:39,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:42:41,633:INFO:Calculating mean and std
2023-07-10 09:42:41,635:INFO:Creating metrics dataframe
2023-07-10 09:42:41,796:INFO:Uploading results into container
2023-07-10 09:42:41,797:INFO:Uploading model into container now
2023-07-10 09:42:41,798:INFO:_master_model_container: 60
2023-07-10 09:42:41,798:INFO:_display_container: 4
2023-07-10 09:42:41,799:INFO:DummyRegressor()
2023-07-10 09:42:41,799:INFO:create_model() successfully completed......................................
2023-07-10 09:42:42,067:INFO:SubProcess create_model() end ==================================
2023-07-10 09:42:42,068:INFO:Creating metrics dataframe
2023-07-10 09:42:42,149:INFO:Initializing create_model()
2023-07-10 09:42:42,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fc999ca28b0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:42,150:INFO:Checking exceptions
2023-07-10 09:42:42,153:INFO:Importing libraries
2023-07-10 09:42:42,153:INFO:Copying training dataset
2023-07-10 09:42:42,160:INFO:Defining folds
2023-07-10 09:42:42,160:INFO:Declaring metric variables
2023-07-10 09:42:42,160:INFO:Importing untrained model
2023-07-10 09:42:42,172:INFO:Declaring custom model
2023-07-10 09:42:42,173:INFO:CatBoost Regressor Imported successfully
2023-07-10 09:42:42,175:INFO:Cross validation set to False
2023-07-10 09:42:42,175:INFO:Fitting Model
2023-07-10 09:42:42,410:INFO:<catboost.core.CatBoostRegressor object at 0x7fc9975f20d0>
2023-07-10 09:42:42,410:INFO:create_model() successfully completed......................................
2023-07-10 09:42:42,795:INFO:Initializing create_model()
2023-07-10 09:42:42,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:42,797:INFO:Checking exceptions
2023-07-10 09:42:42,802:INFO:Importing libraries
2023-07-10 09:42:42,802:INFO:Copying training dataset
2023-07-10 09:42:42,813:INFO:Defining folds
2023-07-10 09:42:42,813:INFO:Declaring metric variables
2023-07-10 09:42:42,813:INFO:Importing untrained model
2023-07-10 09:42:42,813:INFO:Declaring custom model
2023-07-10 09:42:42,816:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 09:42:42,817:INFO:Cross validation set to False
2023-07-10 09:42:42,818:INFO:Fitting Model
2023-07-10 09:42:43,147:INFO:LGBMRegressor(random_state=123)
2023-07-10 09:42:43,147:INFO:create_model() successfully completed......................................
2023-07-10 09:42:43,499:INFO:Initializing create_model()
2023-07-10 09:42:43,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:43,502:INFO:Checking exceptions
2023-07-10 09:42:43,506:INFO:Importing libraries
2023-07-10 09:42:43,506:INFO:Copying training dataset
2023-07-10 09:42:43,514:INFO:Defining folds
2023-07-10 09:42:43,514:INFO:Declaring metric variables
2023-07-10 09:42:43,514:INFO:Importing untrained model
2023-07-10 09:42:43,515:INFO:Declaring custom model
2023-07-10 09:42:43,515:INFO:Extra Trees Regressor Imported successfully
2023-07-10 09:42:43,516:INFO:Cross validation set to False
2023-07-10 09:42:43,517:INFO:Fitting Model
2023-07-10 09:42:43,719:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:42:43,719:INFO:create_model() successfully completed......................................
2023-07-10 09:42:44,071:INFO:Initializing create_model()
2023-07-10 09:42:44,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:44,076:INFO:Checking exceptions
2023-07-10 09:42:44,087:INFO:Importing libraries
2023-07-10 09:42:44,087:INFO:Copying training dataset
2023-07-10 09:42:44,120:INFO:Defining folds
2023-07-10 09:42:44,120:INFO:Declaring metric variables
2023-07-10 09:42:44,121:INFO:Importing untrained model
2023-07-10 09:42:44,121:INFO:Declaring custom model
2023-07-10 09:42:44,123:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 09:42:44,127:INFO:Cross validation set to False
2023-07-10 09:42:44,127:INFO:Fitting Model
2023-07-10 09:42:44,453:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 09:42:44,453:INFO:create_model() successfully completed......................................
2023-07-10 09:42:44,701:INFO:Initializing create_model()
2023-07-10 09:42:44,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:42:44,702:INFO:Checking exceptions
2023-07-10 09:42:44,707:INFO:Importing libraries
2023-07-10 09:42:44,707:INFO:Copying training dataset
2023-07-10 09:42:44,716:INFO:Defining folds
2023-07-10 09:42:44,717:INFO:Declaring metric variables
2023-07-10 09:42:44,717:INFO:Importing untrained model
2023-07-10 09:42:44,717:INFO:Declaring custom model
2023-07-10 09:42:44,720:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 09:42:44,721:INFO:Cross validation set to False
2023-07-10 09:42:44,721:INFO:Fitting Model
2023-07-10 09:42:45,276:INFO:XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...)
2023-07-10 09:42:45,277:INFO:create_model() successfully completed......................................
2023-07-10 09:42:45,564:INFO:_master_model_container: 60
2023-07-10 09:42:45,564:INFO:_display_container: 4
2023-07-10 09:42:45,574:INFO:[<catboost.core.CatBoostRegressor object at 0x7fc9975f20d0>, LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123), XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...)]
2023-07-10 09:42:45,574:INFO:compare_models() successfully completed......................................
2023-07-10 09:42:57,801:INFO:Initializing plot_model()
2023-07-10 09:42:57,802:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc9b25a88e0>, system=True)
2023-07-10 09:42:57,802:INFO:Checking exceptions
2023-07-10 09:42:57,810:INFO:Preloading libraries
2023-07-10 09:42:57,817:INFO:Copying training dataset
2023-07-10 09:42:57,817:INFO:Plot type: feature_all
2023-07-10 09:42:57,852:WARNING:No coef_ found. Trying feature_importances_
2023-07-10 09:42:58,083:INFO:Visual Rendered Successfully
2023-07-10 09:42:58,301:INFO:plot_model() successfully completed......................................
2023-07-10 09:47:17,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 09:47:17,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 09:47:17,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 09:47:17,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 09:47:20,080:INFO:PyCaret RegressionExperiment
2023-07-10 09:47:20,080:INFO:Logging name: reg-default-name
2023-07-10 09:47:20,080:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-10 09:47:20,080:INFO:version 3.0.4
2023-07-10 09:47:20,080:INFO:Initializing setup()
2023-07-10 09:47:20,080:INFO:self.USI: 4f6b
2023-07-10 09:47:20,080:INFO:self._variable_keys: {'logging_param', 'html_param', 'exp_id', 'pipeline', 'y', 'memory', 'gpu_param', '_ml_usecase', 'gpu_n_jobs_param', 'target_param', 'USI', 'fold_shuffle_param', 'fold_groups_param', 'exp_name_log', 'fold_generator', 'y_test', 'log_plots_param', '_available_plots', 'y_train', 'seed', 'n_jobs_param', 'X_train', 'transform_target_param', 'idx', 'X_test', 'data', 'X'}
2023-07-10 09:47:20,080:INFO:Checking environment
2023-07-10 09:47:20,080:INFO:python_version: 3.9.12
2023-07-10 09:47:20,080:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-07-10 09:47:20,080:INFO:machine: x86_64
2023-07-10 09:47:20,080:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-10 09:47:20,081:INFO:Memory: svmem(total=17179869184, available=6540476416, percent=61.9, used=9678598144, free=214712320, active=6327320576, inactive=6316077056, wired=3351277568)
2023-07-10 09:47:20,081:INFO:Physical Core: 2
2023-07-10 09:47:20,081:INFO:Logical Core: 4
2023-07-10 09:47:20,081:INFO:Checking libraries
2023-07-10 09:47:20,081:INFO:System:
2023-07-10 09:47:20,081:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-07-10 09:47:20,081:INFO:executable: /Users/chinmayasukumar/opt/anaconda3/bin/python
2023-07-10 09:47:20,081:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-10 09:47:20,081:INFO:PyCaret required dependencies:
2023-07-10 09:47:20,083:INFO:                 pip: 21.2.4
2023-07-10 09:47:20,083:INFO:          setuptools: 60.10.0
2023-07-10 09:47:20,083:INFO:             pycaret: 3.0.4
2023-07-10 09:47:20,083:INFO:             IPython: 8.2.0
2023-07-10 09:47:20,083:INFO:          ipywidgets: 7.6.5
2023-07-10 09:47:20,083:INFO:                tqdm: 4.64.0
2023-07-10 09:47:20,083:INFO:               numpy: 1.22.4
2023-07-10 09:47:20,083:INFO:              pandas: 1.5.2
2023-07-10 09:47:20,083:INFO:              jinja2: 3.0.0
2023-07-10 09:47:20,083:INFO:               scipy: 1.7.3
2023-07-10 09:47:20,083:INFO:              joblib: 1.2.0
2023-07-10 09:47:20,083:INFO:             sklearn: 1.0.2
2023-07-10 09:47:20,083:INFO:                pyod: 1.0.9
2023-07-10 09:47:20,083:INFO:            imblearn: 0.9.1
2023-07-10 09:47:20,083:INFO:   category_encoders: 2.5.1.post0
2023-07-10 09:47:20,083:INFO:            lightgbm: 3.3.2
2023-07-10 09:47:20,083:INFO:               numba: 0.55.1
2023-07-10 09:47:20,083:INFO:            requests: 2.27.1
2023-07-10 09:47:20,083:INFO:          matplotlib: 3.5.1
2023-07-10 09:47:20,083:INFO:          scikitplot: 0.3.7
2023-07-10 09:47:20,083:INFO:         yellowbrick: 1.4
2023-07-10 09:47:20,083:INFO:              plotly: 5.6.0
2023-07-10 09:47:20,083:INFO:    plotly-resampler: Not installed
2023-07-10 09:47:20,083:INFO:             kaleido: 0.2.1
2023-07-10 09:47:20,084:INFO:           schemdraw: 0.15
2023-07-10 09:47:20,084:INFO:         statsmodels: 0.13.2
2023-07-10 09:47:20,084:INFO:              sktime: 0.17.0
2023-07-10 09:47:20,084:INFO:               tbats: 1.1.3
2023-07-10 09:47:20,084:INFO:            pmdarima: 2.0.1
2023-07-10 09:47:20,084:INFO:              psutil: 5.9.5
2023-07-10 09:47:20,084:INFO:          markupsafe: 2.0.1
2023-07-10 09:47:20,084:INFO:             pickle5: Not installed
2023-07-10 09:47:20,084:INFO:         cloudpickle: 2.0.0
2023-07-10 09:47:20,084:INFO:         deprecation: 2.1.0
2023-07-10 09:47:20,084:INFO:              xxhash: 3.2.0
2023-07-10 09:47:20,084:INFO:           wurlitzer: 3.0.2
2023-07-10 09:47:20,084:INFO:PyCaret optional dependencies:
2023-07-10 09:47:20,095:INFO:                shap: 0.41.0
2023-07-10 09:47:20,095:INFO:           interpret: Not installed
2023-07-10 09:47:20,095:INFO:                umap: 0.5.3
2023-07-10 09:47:20,095:INFO:    pandas_profiling: 3.2.0
2023-07-10 09:47:20,095:INFO:  explainerdashboard: Not installed
2023-07-10 09:47:20,096:INFO:             autoviz: 0.1.58
2023-07-10 09:47:20,096:INFO:           fairlearn: Not installed
2023-07-10 09:47:20,096:INFO:          deepchecks: Not installed
2023-07-10 09:47:20,096:INFO:             xgboost: 1.6.1
2023-07-10 09:47:20,096:INFO:            catboost: 1.0.6
2023-07-10 09:47:20,096:INFO:              kmodes: 0.12.1
2023-07-10 09:47:20,096:INFO:             mlxtend: 0.20.0
2023-07-10 09:47:20,096:INFO:       statsforecast: Not installed
2023-07-10 09:47:20,096:INFO:        tune_sklearn: Not installed
2023-07-10 09:47:20,096:INFO:                 ray: Not installed
2023-07-10 09:47:20,096:INFO:            hyperopt: Not installed
2023-07-10 09:47:20,096:INFO:              optuna: 3.2.0
2023-07-10 09:47:20,096:INFO:               skopt: Not installed
2023-07-10 09:47:20,096:INFO:              mlflow: 1.26.1
2023-07-10 09:47:20,096:INFO:              gradio: Not installed
2023-07-10 09:47:20,096:INFO:             fastapi: Not installed
2023-07-10 09:47:20,096:INFO:             uvicorn: Not installed
2023-07-10 09:47:20,096:INFO:              m2cgen: Not installed
2023-07-10 09:47:20,096:INFO:           evidently: Not installed
2023-07-10 09:47:20,096:INFO:               fugue: Not installed
2023-07-10 09:47:20,096:INFO:           streamlit: Not installed
2023-07-10 09:47:20,096:INFO:             prophet: Not installed
2023-07-10 09:47:20,096:INFO:None
2023-07-10 09:47:20,096:INFO:Set up data.
2023-07-10 09:47:20,103:INFO:Set up train/test split.
2023-07-10 09:47:20,106:INFO:Set up index.
2023-07-10 09:47:20,107:INFO:Set up folding strategy.
2023-07-10 09:47:20,107:INFO:Assigning column types.
2023-07-10 09:47:20,110:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-10 09:47:20,110:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,115:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,120:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,240:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:20,597:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:20,634:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,647:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,775:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:20,778:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:20,779:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-10 09:47:20,784:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,905:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:20,908:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:20,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 09:47:20,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,040:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,042:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,043:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-10 09:47:21,054:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,172:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,175:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,186:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,308:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,311:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,311:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-10 09:47:21,389:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,440:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,442:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,569:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,570:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,573:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,573:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-10 09:47:21,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,699:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,702:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 09:47:21,826:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,829:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:21,829:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-10 09:47:21,960:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:21,963:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:22,092:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:22,095:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:22,106:INFO:Preparing preprocessing pipeline...
2023-07-10 09:47:22,106:INFO:Set up simple imputation.
2023-07-10 09:47:22,107:INFO:Set up column name cleaning.
2023-07-10 09:47:22,142:INFO:Finished creating preprocessing pipeline.
2023-07-10 09:47:22,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['c', 'si', 'mn', 'p', 's', 'ni',
                                             'cr', 'mo', 'cu', 'v', 'al', 'n',
                                             'nb+ta', 'temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-10 09:47:22,150:INFO:Creating final display dataframe.
2023-07-10 09:47:22,225:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (618, 15)
4        Transformed data shape         (618, 15)
5   Transformed train set shape         (432, 15)
6    Transformed test set shape         (186, 15)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4f6b
2023-07-10 09:47:22,383:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:22,386:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:22,511:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 09:47:22,514:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 09:47:22,515:INFO:setup() successfully completed in 2.56s...............
2023-07-10 09:47:22,520:INFO:Initializing compare_models()
2023-07-10 09:47:22,520:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-10 09:47:22,521:INFO:Checking exceptions
2023-07-10 09:47:22,522:INFO:Preparing display monitor
2023-07-10 09:47:22,622:INFO:Initializing Linear Regression
2023-07-10 09:47:22,622:INFO:Total runtime is 6.786982218424479e-06 minutes
2023-07-10 09:47:22,630:INFO:SubProcess create_model() called ==================================
2023-07-10 09:47:22,631:INFO:Initializing create_model()
2023-07-10 09:47:22,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa670163340>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:47:22,631:INFO:Checking exceptions
2023-07-10 09:47:22,631:INFO:Importing libraries
2023-07-10 09:47:22,631:INFO:Copying training dataset
2023-07-10 09:47:22,644:INFO:Defining folds
2023-07-10 09:47:22,644:INFO:Declaring metric variables
2023-07-10 09:47:22,650:INFO:Importing untrained model
2023-07-10 09:47:22,656:INFO:Linear Regression Imported successfully
2023-07-10 09:47:22,667:INFO:Starting cross validation
2023-07-10 09:47:22,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:47:33,284:INFO:Calculating mean and std
2023-07-10 09:47:33,287:INFO:Creating metrics dataframe
2023-07-10 09:47:33,425:INFO:Uploading results into container
2023-07-10 09:47:33,426:INFO:Uploading model into container now
2023-07-10 09:47:33,427:INFO:_master_model_container: 1
2023-07-10 09:47:33,427:INFO:_display_container: 2
2023-07-10 09:47:33,427:INFO:LinearRegression(n_jobs=-1)
2023-07-10 09:47:33,427:INFO:create_model() successfully completed......................................
2023-07-10 09:47:33,561:INFO:SubProcess create_model() end ==================================
2023-07-10 09:47:33,561:INFO:Creating metrics dataframe
2023-07-10 09:47:33,576:INFO:Initializing Lasso Regression
2023-07-10 09:47:33,577:INFO:Total runtime is 0.18257558743158978 minutes
2023-07-10 09:47:33,581:INFO:SubProcess create_model() called ==================================
2023-07-10 09:47:33,582:INFO:Initializing create_model()
2023-07-10 09:47:33,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa670163340>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:47:33,582:INFO:Checking exceptions
2023-07-10 09:47:33,583:INFO:Importing libraries
2023-07-10 09:47:33,583:INFO:Copying training dataset
2023-07-10 09:47:33,591:INFO:Defining folds
2023-07-10 09:47:33,591:INFO:Declaring metric variables
2023-07-10 09:47:33,597:INFO:Importing untrained model
2023-07-10 09:47:33,604:INFO:Lasso Regression Imported successfully
2023-07-10 09:47:33,614:INFO:Starting cross validation
2023-07-10 09:47:33,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:47:39,103:INFO:Calculating mean and std
2023-07-10 09:47:39,105:INFO:Creating metrics dataframe
2023-07-10 09:47:39,236:INFO:Uploading results into container
2023-07-10 09:47:39,236:INFO:Uploading model into container now
2023-07-10 09:47:39,237:INFO:_master_model_container: 2
2023-07-10 09:47:39,237:INFO:_display_container: 2
2023-07-10 09:47:39,238:INFO:Lasso(random_state=123)
2023-07-10 09:47:39,238:INFO:create_model() successfully completed......................................
2023-07-10 09:47:39,341:INFO:SubProcess create_model() end ==================================
2023-07-10 09:47:39,341:INFO:Creating metrics dataframe
2023-07-10 09:47:39,356:INFO:Initializing Ridge Regression
2023-07-10 09:47:39,356:INFO:Total runtime is 0.27890308698018396 minutes
2023-07-10 09:47:39,361:INFO:SubProcess create_model() called ==================================
2023-07-10 09:47:39,361:INFO:Initializing create_model()
2023-07-10 09:47:39,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa670163340>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:47:39,362:INFO:Checking exceptions
2023-07-10 09:47:39,362:INFO:Importing libraries
2023-07-10 09:47:39,362:INFO:Copying training dataset
2023-07-10 09:47:39,371:INFO:Defining folds
2023-07-10 09:47:39,371:INFO:Declaring metric variables
2023-07-10 09:47:39,378:INFO:Importing untrained model
2023-07-10 09:47:39,385:INFO:Ridge Regression Imported successfully
2023-07-10 09:47:39,396:INFO:Starting cross validation
2023-07-10 09:47:39,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:47:42,395:INFO:Calculating mean and std
2023-07-10 09:47:42,398:INFO:Creating metrics dataframe
2023-07-10 09:47:42,769:INFO:Uploading results into container
2023-07-10 09:47:42,783:INFO:Uploading model into container now
2023-07-10 09:47:42,786:INFO:_master_model_container: 3
2023-07-10 09:47:42,788:INFO:_display_container: 2
2023-07-10 09:47:42,790:INFO:Ridge(random_state=123)
2023-07-10 09:47:42,791:INFO:create_model() successfully completed......................................
2023-07-10 09:47:43,151:INFO:SubProcess create_model() end ==================================
2023-07-10 09:47:43,151:INFO:Creating metrics dataframe
2023-07-10 09:47:43,176:INFO:Initializing Elastic Net
2023-07-10 09:47:43,176:INFO:Total runtime is 0.3425651669502259 minutes
2023-07-10 09:47:43,182:INFO:SubProcess create_model() called ==================================
2023-07-10 09:47:43,183:INFO:Initializing create_model()
2023-07-10 09:47:43,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa670163340>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:47:43,183:INFO:Checking exceptions
2023-07-10 09:47:43,184:INFO:Importing libraries
2023-07-10 09:47:43,184:INFO:Copying training dataset
2023-07-10 09:47:43,207:INFO:Defining folds
2023-07-10 09:47:43,207:INFO:Declaring metric variables
2023-07-10 09:47:43,225:INFO:Importing untrained model
2023-07-10 09:47:43,231:INFO:Elastic Net Imported successfully
2023-07-10 09:47:43,252:INFO:Starting cross validation
2023-07-10 09:47:43,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:47:51,370:INFO:Initializing compare_models()
2023-07-10 09:47:51,370:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-10 09:47:51,370:INFO:Checking exceptions
2023-07-10 09:47:51,374:INFO:Preparing display monitor
2023-07-10 09:47:51,437:INFO:Initializing Linear Regression
2023-07-10 09:47:51,437:INFO:Total runtime is 3.3338864644368488e-06 minutes
2023-07-10 09:47:51,444:INFO:SubProcess create_model() called ==================================
2023-07-10 09:47:51,444:INFO:Initializing create_model()
2023-07-10 09:47:51,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:47:51,444:INFO:Checking exceptions
2023-07-10 09:47:51,445:INFO:Importing libraries
2023-07-10 09:47:51,445:INFO:Copying training dataset
2023-07-10 09:47:51,452:INFO:Defining folds
2023-07-10 09:47:51,452:INFO:Declaring metric variables
2023-07-10 09:47:51,457:INFO:Importing untrained model
2023-07-10 09:47:51,461:INFO:Linear Regression Imported successfully
2023-07-10 09:47:51,472:INFO:Starting cross validation
2023-07-10 09:47:51,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:01,740:INFO:Calculating mean and std
2023-07-10 09:48:01,750:INFO:Creating metrics dataframe
2023-07-10 09:48:02,124:INFO:Uploading results into container
2023-07-10 09:48:02,127:INFO:Uploading model into container now
2023-07-10 09:48:02,128:INFO:_master_model_container: 4
2023-07-10 09:48:02,128:INFO:_display_container: 2
2023-07-10 09:48:02,129:INFO:LinearRegression(n_jobs=-1)
2023-07-10 09:48:02,129:INFO:create_model() successfully completed......................................
2023-07-10 09:48:02,342:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:02,343:INFO:Creating metrics dataframe
2023-07-10 09:48:02,364:INFO:Initializing Lasso Regression
2023-07-10 09:48:02,364:INFO:Total runtime is 0.18211690187454221 minutes
2023-07-10 09:48:02,378:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:02,380:INFO:Initializing create_model()
2023-07-10 09:48:02,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:02,381:INFO:Checking exceptions
2023-07-10 09:48:02,381:INFO:Importing libraries
2023-07-10 09:48:02,381:INFO:Copying training dataset
2023-07-10 09:48:02,393:INFO:Defining folds
2023-07-10 09:48:02,394:INFO:Declaring metric variables
2023-07-10 09:48:02,402:INFO:Importing untrained model
2023-07-10 09:48:02,407:INFO:Lasso Regression Imported successfully
2023-07-10 09:48:02,422:INFO:Starting cross validation
2023-07-10 09:48:02,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:08,495:INFO:Calculating mean and std
2023-07-10 09:48:08,499:INFO:Creating metrics dataframe
2023-07-10 09:48:08,650:INFO:Uploading results into container
2023-07-10 09:48:08,651:INFO:Uploading model into container now
2023-07-10 09:48:08,652:INFO:_master_model_container: 5
2023-07-10 09:48:08,652:INFO:_display_container: 2
2023-07-10 09:48:08,652:INFO:Lasso(random_state=123)
2023-07-10 09:48:08,652:INFO:create_model() successfully completed......................................
2023-07-10 09:48:08,796:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:08,796:INFO:Creating metrics dataframe
2023-07-10 09:48:08,810:INFO:Initializing Ridge Regression
2023-07-10 09:48:08,810:INFO:Total runtime is 0.28955999612808225 minutes
2023-07-10 09:48:08,818:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:08,819:INFO:Initializing create_model()
2023-07-10 09:48:08,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:08,819:INFO:Checking exceptions
2023-07-10 09:48:08,819:INFO:Importing libraries
2023-07-10 09:48:08,819:INFO:Copying training dataset
2023-07-10 09:48:08,829:INFO:Defining folds
2023-07-10 09:48:08,830:INFO:Declaring metric variables
2023-07-10 09:48:08,836:INFO:Importing untrained model
2023-07-10 09:48:08,843:INFO:Ridge Regression Imported successfully
2023-07-10 09:48:08,853:INFO:Starting cross validation
2023-07-10 09:48:08,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:10,137:INFO:Calculating mean and std
2023-07-10 09:48:10,138:INFO:Creating metrics dataframe
2023-07-10 09:48:10,265:INFO:Uploading results into container
2023-07-10 09:48:10,266:INFO:Uploading model into container now
2023-07-10 09:48:10,266:INFO:_master_model_container: 6
2023-07-10 09:48:10,267:INFO:_display_container: 2
2023-07-10 09:48:10,267:INFO:Ridge(random_state=123)
2023-07-10 09:48:10,267:INFO:create_model() successfully completed......................................
2023-07-10 09:48:10,410:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:10,411:INFO:Creating metrics dataframe
2023-07-10 09:48:10,429:INFO:Initializing Elastic Net
2023-07-10 09:48:10,429:INFO:Total runtime is 0.31653376817703244 minutes
2023-07-10 09:48:10,437:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:10,438:INFO:Initializing create_model()
2023-07-10 09:48:10,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:10,438:INFO:Checking exceptions
2023-07-10 09:48:10,439:INFO:Importing libraries
2023-07-10 09:48:10,439:INFO:Copying training dataset
2023-07-10 09:48:10,448:INFO:Defining folds
2023-07-10 09:48:10,448:INFO:Declaring metric variables
2023-07-10 09:48:10,455:INFO:Importing untrained model
2023-07-10 09:48:10,465:INFO:Elastic Net Imported successfully
2023-07-10 09:48:10,477:INFO:Starting cross validation
2023-07-10 09:48:10,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:11,724:INFO:Calculating mean and std
2023-07-10 09:48:11,726:INFO:Creating metrics dataframe
2023-07-10 09:48:11,854:INFO:Uploading results into container
2023-07-10 09:48:11,855:INFO:Uploading model into container now
2023-07-10 09:48:11,855:INFO:_master_model_container: 7
2023-07-10 09:48:11,855:INFO:_display_container: 2
2023-07-10 09:48:11,855:INFO:ElasticNet(random_state=123)
2023-07-10 09:48:11,856:INFO:create_model() successfully completed......................................
2023-07-10 09:48:12,009:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:12,009:INFO:Creating metrics dataframe
2023-07-10 09:48:12,027:INFO:Initializing Least Angle Regression
2023-07-10 09:48:12,027:INFO:Total runtime is 0.34316544930140175 minutes
2023-07-10 09:48:12,036:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:12,037:INFO:Initializing create_model()
2023-07-10 09:48:12,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:12,037:INFO:Checking exceptions
2023-07-10 09:48:12,037:INFO:Importing libraries
2023-07-10 09:48:12,038:INFO:Copying training dataset
2023-07-10 09:48:12,045:INFO:Defining folds
2023-07-10 09:48:12,046:INFO:Declaring metric variables
2023-07-10 09:48:12,059:INFO:Importing untrained model
2023-07-10 09:48:12,066:INFO:Least Angle Regression Imported successfully
2023-07-10 09:48:12,080:INFO:Starting cross validation
2023-07-10 09:48:12,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:12,212:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,218:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,273:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,312:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,595:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,596:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,615:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,631:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,879:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:12,920:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:13,397:INFO:Calculating mean and std
2023-07-10 09:48:13,399:INFO:Creating metrics dataframe
2023-07-10 09:48:13,544:INFO:Uploading results into container
2023-07-10 09:48:13,544:INFO:Uploading model into container now
2023-07-10 09:48:13,545:INFO:_master_model_container: 8
2023-07-10 09:48:13,545:INFO:_display_container: 2
2023-07-10 09:48:13,545:INFO:Lars(random_state=123)
2023-07-10 09:48:13,545:INFO:create_model() successfully completed......................................
2023-07-10 09:48:13,691:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:13,691:INFO:Creating metrics dataframe
2023-07-10 09:48:13,721:INFO:Initializing Lasso Least Angle Regression
2023-07-10 09:48:13,721:INFO:Total runtime is 0.3713992794354756 minutes
2023-07-10 09:48:13,732:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:13,733:INFO:Initializing create_model()
2023-07-10 09:48:13,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:13,733:INFO:Checking exceptions
2023-07-10 09:48:13,733:INFO:Importing libraries
2023-07-10 09:48:13,733:INFO:Copying training dataset
2023-07-10 09:48:13,742:INFO:Defining folds
2023-07-10 09:48:13,742:INFO:Declaring metric variables
2023-07-10 09:48:13,754:INFO:Importing untrained model
2023-07-10 09:48:13,766:INFO:Lasso Least Angle Regression Imported successfully
2023-07-10 09:48:13,779:INFO:Starting cross validation
2023-07-10 09:48:13,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:13,917:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:13,932:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:13,944:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:13,971:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:14,249:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:14,251:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:14,263:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:14,275:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:14,473:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:14,473:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 09:48:15,015:INFO:Calculating mean and std
2023-07-10 09:48:15,017:INFO:Creating metrics dataframe
2023-07-10 09:48:15,153:INFO:Uploading results into container
2023-07-10 09:48:15,154:INFO:Uploading model into container now
2023-07-10 09:48:15,155:INFO:_master_model_container: 9
2023-07-10 09:48:15,155:INFO:_display_container: 2
2023-07-10 09:48:15,155:INFO:LassoLars(random_state=123)
2023-07-10 09:48:15,155:INFO:create_model() successfully completed......................................
2023-07-10 09:48:15,305:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:15,306:INFO:Creating metrics dataframe
2023-07-10 09:48:15,334:INFO:Initializing Orthogonal Matching Pursuit
2023-07-10 09:48:15,334:INFO:Total runtime is 0.39828304847081497 minutes
2023-07-10 09:48:15,343:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:15,343:INFO:Initializing create_model()
2023-07-10 09:48:15,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:15,344:INFO:Checking exceptions
2023-07-10 09:48:15,344:INFO:Importing libraries
2023-07-10 09:48:15,344:INFO:Copying training dataset
2023-07-10 09:48:15,355:INFO:Defining folds
2023-07-10 09:48:15,356:INFO:Declaring metric variables
2023-07-10 09:48:15,376:INFO:Importing untrained model
2023-07-10 09:48:15,391:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-10 09:48:15,404:INFO:Starting cross validation
2023-07-10 09:48:15,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:15,509:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,539:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,570:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,593:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,882:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,897:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,902:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:15,953:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:16,318:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:16,331:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 09:48:17,106:INFO:Calculating mean and std
2023-07-10 09:48:17,109:INFO:Creating metrics dataframe
2023-07-10 09:48:17,525:INFO:Uploading results into container
2023-07-10 09:48:17,526:INFO:Uploading model into container now
2023-07-10 09:48:17,527:INFO:_master_model_container: 10
2023-07-10 09:48:17,528:INFO:_display_container: 2
2023-07-10 09:48:17,528:INFO:OrthogonalMatchingPursuit()
2023-07-10 09:48:17,528:INFO:create_model() successfully completed......................................
2023-07-10 09:48:17,692:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:17,692:INFO:Creating metrics dataframe
2023-07-10 09:48:17,723:INFO:Initializing Bayesian Ridge
2023-07-10 09:48:17,723:INFO:Total runtime is 0.43809847036997474 minutes
2023-07-10 09:48:17,809:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:17,810:INFO:Initializing create_model()
2023-07-10 09:48:17,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:17,810:INFO:Checking exceptions
2023-07-10 09:48:17,810:INFO:Importing libraries
2023-07-10 09:48:17,810:INFO:Copying training dataset
2023-07-10 09:48:17,817:INFO:Defining folds
2023-07-10 09:48:17,817:INFO:Declaring metric variables
2023-07-10 09:48:17,824:INFO:Importing untrained model
2023-07-10 09:48:17,830:INFO:Bayesian Ridge Imported successfully
2023-07-10 09:48:17,841:INFO:Starting cross validation
2023-07-10 09:48:17,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:19,611:INFO:Calculating mean and std
2023-07-10 09:48:19,613:INFO:Creating metrics dataframe
2023-07-10 09:48:19,770:INFO:Uploading results into container
2023-07-10 09:48:19,771:INFO:Uploading model into container now
2023-07-10 09:48:19,772:INFO:_master_model_container: 11
2023-07-10 09:48:19,772:INFO:_display_container: 2
2023-07-10 09:48:19,772:INFO:BayesianRidge()
2023-07-10 09:48:19,773:INFO:create_model() successfully completed......................................
2023-07-10 09:48:19,924:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:19,924:INFO:Creating metrics dataframe
2023-07-10 09:48:19,943:INFO:Initializing Passive Aggressive Regressor
2023-07-10 09:48:19,944:INFO:Total runtime is 0.4751109321912129 minutes
2023-07-10 09:48:19,948:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:19,949:INFO:Initializing create_model()
2023-07-10 09:48:19,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:19,950:INFO:Checking exceptions
2023-07-10 09:48:19,950:INFO:Importing libraries
2023-07-10 09:48:19,950:INFO:Copying training dataset
2023-07-10 09:48:19,959:INFO:Defining folds
2023-07-10 09:48:19,959:INFO:Declaring metric variables
2023-07-10 09:48:19,966:INFO:Importing untrained model
2023-07-10 09:48:19,973:INFO:Passive Aggressive Regressor Imported successfully
2023-07-10 09:48:19,985:INFO:Starting cross validation
2023-07-10 09:48:19,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:21,339:INFO:Calculating mean and std
2023-07-10 09:48:21,341:INFO:Creating metrics dataframe
2023-07-10 09:48:21,474:INFO:Uploading results into container
2023-07-10 09:48:21,475:INFO:Uploading model into container now
2023-07-10 09:48:21,475:INFO:_master_model_container: 12
2023-07-10 09:48:21,475:INFO:_display_container: 2
2023-07-10 09:48:21,475:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-10 09:48:21,475:INFO:create_model() successfully completed......................................
2023-07-10 09:48:21,622:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:21,622:INFO:Creating metrics dataframe
2023-07-10 09:48:21,645:INFO:Initializing Huber Regressor
2023-07-10 09:48:21,645:INFO:Total runtime is 0.5034691174825032 minutes
2023-07-10 09:48:21,652:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:21,653:INFO:Initializing create_model()
2023-07-10 09:48:21,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:21,654:INFO:Checking exceptions
2023-07-10 09:48:21,654:INFO:Importing libraries
2023-07-10 09:48:21,654:INFO:Copying training dataset
2023-07-10 09:48:21,662:INFO:Defining folds
2023-07-10 09:48:21,663:INFO:Declaring metric variables
2023-07-10 09:48:21,671:INFO:Importing untrained model
2023-07-10 09:48:21,678:INFO:Huber Regressor Imported successfully
2023-07-10 09:48:21,696:INFO:Starting cross validation
2023-07-10 09:48:21,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:23,378:INFO:Calculating mean and std
2023-07-10 09:48:23,380:INFO:Creating metrics dataframe
2023-07-10 09:48:23,605:INFO:Uploading results into container
2023-07-10 09:48:23,606:INFO:Uploading model into container now
2023-07-10 09:48:23,610:INFO:_master_model_container: 13
2023-07-10 09:48:23,611:INFO:_display_container: 2
2023-07-10 09:48:23,611:INFO:HuberRegressor()
2023-07-10 09:48:23,611:INFO:create_model() successfully completed......................................
2023-07-10 09:48:23,869:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:23,870:INFO:Creating metrics dataframe
2023-07-10 09:48:23,896:INFO:Initializing K Neighbors Regressor
2023-07-10 09:48:23,897:INFO:Total runtime is 0.5409949978192647 minutes
2023-07-10 09:48:23,925:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:23,927:INFO:Initializing create_model()
2023-07-10 09:48:23,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:23,928:INFO:Checking exceptions
2023-07-10 09:48:23,931:INFO:Importing libraries
2023-07-10 09:48:23,931:INFO:Copying training dataset
2023-07-10 09:48:23,965:INFO:Defining folds
2023-07-10 09:48:23,965:INFO:Declaring metric variables
2023-07-10 09:48:23,976:INFO:Importing untrained model
2023-07-10 09:48:23,987:INFO:K Neighbors Regressor Imported successfully
2023-07-10 09:48:24,000:INFO:Starting cross validation
2023-07-10 09:48:24,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:25,673:INFO:Calculating mean and std
2023-07-10 09:48:25,675:INFO:Creating metrics dataframe
2023-07-10 09:48:25,807:INFO:Uploading results into container
2023-07-10 09:48:25,809:INFO:Uploading model into container now
2023-07-10 09:48:25,810:INFO:_master_model_container: 14
2023-07-10 09:48:25,810:INFO:_display_container: 2
2023-07-10 09:48:25,810:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-10 09:48:25,810:INFO:create_model() successfully completed......................................
2023-07-10 09:48:25,976:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:25,977:INFO:Creating metrics dataframe
2023-07-10 09:48:25,999:INFO:Initializing Decision Tree Regressor
2023-07-10 09:48:26,000:INFO:Total runtime is 0.5760446468989054 minutes
2023-07-10 09:48:26,004:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:26,005:INFO:Initializing create_model()
2023-07-10 09:48:26,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:26,005:INFO:Checking exceptions
2023-07-10 09:48:26,005:INFO:Importing libraries
2023-07-10 09:48:26,006:INFO:Copying training dataset
2023-07-10 09:48:26,016:INFO:Defining folds
2023-07-10 09:48:26,018:INFO:Declaring metric variables
2023-07-10 09:48:26,026:INFO:Importing untrained model
2023-07-10 09:48:26,033:INFO:Decision Tree Regressor Imported successfully
2023-07-10 09:48:26,043:INFO:Starting cross validation
2023-07-10 09:48:26,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:27,385:INFO:Calculating mean and std
2023-07-10 09:48:27,387:INFO:Creating metrics dataframe
2023-07-10 09:48:27,588:INFO:Uploading results into container
2023-07-10 09:48:27,589:INFO:Uploading model into container now
2023-07-10 09:48:27,589:INFO:_master_model_container: 15
2023-07-10 09:48:27,589:INFO:_display_container: 2
2023-07-10 09:48:27,590:INFO:DecisionTreeRegressor(random_state=123)
2023-07-10 09:48:27,590:INFO:create_model() successfully completed......................................
2023-07-10 09:48:27,739:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:27,739:INFO:Creating metrics dataframe
2023-07-10 09:48:27,763:INFO:Initializing Random Forest Regressor
2023-07-10 09:48:27,763:INFO:Total runtime is 0.6054354310035706 minutes
2023-07-10 09:48:27,769:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:27,770:INFO:Initializing create_model()
2023-07-10 09:48:27,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:27,770:INFO:Checking exceptions
2023-07-10 09:48:27,770:INFO:Importing libraries
2023-07-10 09:48:27,770:INFO:Copying training dataset
2023-07-10 09:48:27,793:INFO:Defining folds
2023-07-10 09:48:27,793:INFO:Declaring metric variables
2023-07-10 09:48:27,802:INFO:Importing untrained model
2023-07-10 09:48:27,818:INFO:Random Forest Regressor Imported successfully
2023-07-10 09:48:27,832:INFO:Starting cross validation
2023-07-10 09:48:27,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:30,319:INFO:Calculating mean and std
2023-07-10 09:48:30,321:INFO:Creating metrics dataframe
2023-07-10 09:48:30,507:INFO:Uploading results into container
2023-07-10 09:48:30,508:INFO:Uploading model into container now
2023-07-10 09:48:30,509:INFO:_master_model_container: 16
2023-07-10 09:48:30,509:INFO:_display_container: 2
2023-07-10 09:48:30,509:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:48:30,510:INFO:create_model() successfully completed......................................
2023-07-10 09:48:30,681:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:30,682:INFO:Creating metrics dataframe
2023-07-10 09:48:30,713:INFO:Initializing Extra Trees Regressor
2023-07-10 09:48:30,714:INFO:Total runtime is 0.6546114166577657 minutes
2023-07-10 09:48:30,721:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:30,721:INFO:Initializing create_model()
2023-07-10 09:48:30,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:30,722:INFO:Checking exceptions
2023-07-10 09:48:30,722:INFO:Importing libraries
2023-07-10 09:48:30,722:INFO:Copying training dataset
2023-07-10 09:48:30,733:INFO:Defining folds
2023-07-10 09:48:30,733:INFO:Declaring metric variables
2023-07-10 09:48:30,746:INFO:Importing untrained model
2023-07-10 09:48:30,757:INFO:Extra Trees Regressor Imported successfully
2023-07-10 09:48:30,770:INFO:Starting cross validation
2023-07-10 09:48:30,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:32,995:INFO:Calculating mean and std
2023-07-10 09:48:32,997:INFO:Creating metrics dataframe
2023-07-10 09:48:33,266:INFO:Uploading results into container
2023-07-10 09:48:33,269:INFO:Uploading model into container now
2023-07-10 09:48:33,270:INFO:_master_model_container: 17
2023-07-10 09:48:33,270:INFO:_display_container: 2
2023-07-10 09:48:33,271:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:48:33,272:INFO:create_model() successfully completed......................................
2023-07-10 09:48:33,496:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:33,496:INFO:Creating metrics dataframe
2023-07-10 09:48:33,516:INFO:Initializing AdaBoost Regressor
2023-07-10 09:48:33,516:INFO:Total runtime is 0.7013244191805521 minutes
2023-07-10 09:48:33,521:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:33,522:INFO:Initializing create_model()
2023-07-10 09:48:33,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:33,522:INFO:Checking exceptions
2023-07-10 09:48:33,522:INFO:Importing libraries
2023-07-10 09:48:33,523:INFO:Copying training dataset
2023-07-10 09:48:33,589:INFO:Defining folds
2023-07-10 09:48:33,590:INFO:Declaring metric variables
2023-07-10 09:48:33,603:INFO:Importing untrained model
2023-07-10 09:48:33,607:INFO:AdaBoost Regressor Imported successfully
2023-07-10 09:48:33,625:INFO:Starting cross validation
2023-07-10 09:48:33,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:35,468:INFO:Calculating mean and std
2023-07-10 09:48:35,469:INFO:Creating metrics dataframe
2023-07-10 09:48:35,605:INFO:Uploading results into container
2023-07-10 09:48:35,606:INFO:Uploading model into container now
2023-07-10 09:48:35,606:INFO:_master_model_container: 18
2023-07-10 09:48:35,606:INFO:_display_container: 2
2023-07-10 09:48:35,607:INFO:AdaBoostRegressor(random_state=123)
2023-07-10 09:48:35,607:INFO:create_model() successfully completed......................................
2023-07-10 09:48:35,767:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:35,767:INFO:Creating metrics dataframe
2023-07-10 09:48:35,802:INFO:Initializing Gradient Boosting Regressor
2023-07-10 09:48:35,803:INFO:Total runtime is 0.7394396026929219 minutes
2023-07-10 09:48:35,819:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:35,820:INFO:Initializing create_model()
2023-07-10 09:48:35,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:35,821:INFO:Checking exceptions
2023-07-10 09:48:35,821:INFO:Importing libraries
2023-07-10 09:48:35,821:INFO:Copying training dataset
2023-07-10 09:48:35,831:INFO:Defining folds
2023-07-10 09:48:35,831:INFO:Declaring metric variables
2023-07-10 09:48:35,842:INFO:Importing untrained model
2023-07-10 09:48:35,851:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 09:48:35,861:INFO:Starting cross validation
2023-07-10 09:48:35,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:37,870:INFO:Calculating mean and std
2023-07-10 09:48:37,872:INFO:Creating metrics dataframe
2023-07-10 09:48:38,020:INFO:Uploading results into container
2023-07-10 09:48:38,021:INFO:Uploading model into container now
2023-07-10 09:48:38,021:INFO:_master_model_container: 19
2023-07-10 09:48:38,021:INFO:_display_container: 2
2023-07-10 09:48:38,022:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 09:48:38,022:INFO:create_model() successfully completed......................................
2023-07-10 09:48:38,169:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:38,170:INFO:Creating metrics dataframe
2023-07-10 09:48:38,199:INFO:Initializing Extreme Gradient Boosting
2023-07-10 09:48:38,199:INFO:Total runtime is 0.7793731490770974 minutes
2023-07-10 09:48:38,217:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:38,218:INFO:Initializing create_model()
2023-07-10 09:48:38,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:38,218:INFO:Checking exceptions
2023-07-10 09:48:38,219:INFO:Importing libraries
2023-07-10 09:48:38,219:INFO:Copying training dataset
2023-07-10 09:48:38,228:INFO:Defining folds
2023-07-10 09:48:38,228:INFO:Declaring metric variables
2023-07-10 09:48:38,237:INFO:Importing untrained model
2023-07-10 09:48:38,245:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 09:48:38,261:INFO:Starting cross validation
2023-07-10 09:48:38,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:39,801:INFO:Calculating mean and std
2023-07-10 09:48:39,802:INFO:Creating metrics dataframe
2023-07-10 09:48:39,940:INFO:Uploading results into container
2023-07-10 09:48:39,941:INFO:Uploading model into container now
2023-07-10 09:48:39,941:INFO:_master_model_container: 20
2023-07-10 09:48:39,941:INFO:_display_container: 2
2023-07-10 09:48:39,942:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2023-07-10 09:48:39,942:INFO:create_model() successfully completed......................................
2023-07-10 09:48:40,197:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:40,197:INFO:Creating metrics dataframe
2023-07-10 09:48:40,237:INFO:Initializing Light Gradient Boosting Machine
2023-07-10 09:48:40,237:INFO:Total runtime is 0.8133350491523741 minutes
2023-07-10 09:48:40,244:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:40,245:INFO:Initializing create_model()
2023-07-10 09:48:40,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:40,245:INFO:Checking exceptions
2023-07-10 09:48:40,246:INFO:Importing libraries
2023-07-10 09:48:40,246:INFO:Copying training dataset
2023-07-10 09:48:40,258:INFO:Defining folds
2023-07-10 09:48:40,259:INFO:Declaring metric variables
2023-07-10 09:48:40,275:INFO:Importing untrained model
2023-07-10 09:48:40,283:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 09:48:40,293:INFO:Starting cross validation
2023-07-10 09:48:40,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:43,863:INFO:Calculating mean and std
2023-07-10 09:48:43,865:INFO:Creating metrics dataframe
2023-07-10 09:48:44,037:INFO:Uploading results into container
2023-07-10 09:48:44,038:INFO:Uploading model into container now
2023-07-10 09:48:44,038:INFO:_master_model_container: 21
2023-07-10 09:48:44,038:INFO:_display_container: 2
2023-07-10 09:48:44,039:INFO:LGBMRegressor(random_state=123)
2023-07-10 09:48:44,039:INFO:create_model() successfully completed......................................
2023-07-10 09:48:44,242:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:44,243:INFO:Creating metrics dataframe
2023-07-10 09:48:44,300:INFO:Initializing CatBoost Regressor
2023-07-10 09:48:44,300:INFO:Total runtime is 0.8810518980026243 minutes
2023-07-10 09:48:44,311:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:44,312:INFO:Initializing create_model()
2023-07-10 09:48:44,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:44,312:INFO:Checking exceptions
2023-07-10 09:48:44,313:INFO:Importing libraries
2023-07-10 09:48:44,313:INFO:Copying training dataset
2023-07-10 09:48:44,320:INFO:Defining folds
2023-07-10 09:48:44,321:INFO:Declaring metric variables
2023-07-10 09:48:44,326:INFO:Importing untrained model
2023-07-10 09:48:44,332:INFO:CatBoost Regressor Imported successfully
2023-07-10 09:48:44,341:INFO:Starting cross validation
2023-07-10 09:48:44,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:45,118:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,121:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,123:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,127:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,578:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,585:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,585:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,616:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:45,988:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:46,111:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 09:48:46,972:INFO:Calculating mean and std
2023-07-10 09:48:46,974:INFO:Creating metrics dataframe
2023-07-10 09:48:47,183:INFO:Uploading results into container
2023-07-10 09:48:47,184:INFO:Uploading model into container now
2023-07-10 09:48:47,184:INFO:_master_model_container: 22
2023-07-10 09:48:47,184:INFO:_display_container: 2
2023-07-10 09:48:47,185:INFO:<catboost.core.CatBoostRegressor object at 0x7fa66b6b76d0>
2023-07-10 09:48:47,185:INFO:create_model() successfully completed......................................
2023-07-10 09:48:47,339:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:47,339:INFO:Creating metrics dataframe
2023-07-10 09:48:47,374:INFO:Initializing Dummy Regressor
2023-07-10 09:48:47,375:INFO:Total runtime is 0.932298680146535 minutes
2023-07-10 09:48:47,387:INFO:SubProcess create_model() called ==================================
2023-07-10 09:48:47,387:INFO:Initializing create_model()
2023-07-10 09:48:47,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa6530a6b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:47,387:INFO:Checking exceptions
2023-07-10 09:48:47,388:INFO:Importing libraries
2023-07-10 09:48:47,388:INFO:Copying training dataset
2023-07-10 09:48:47,408:INFO:Defining folds
2023-07-10 09:48:47,409:INFO:Declaring metric variables
2023-07-10 09:48:47,422:INFO:Importing untrained model
2023-07-10 09:48:47,436:INFO:Dummy Regressor Imported successfully
2023-07-10 09:48:47,448:INFO:Starting cross validation
2023-07-10 09:48:47,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 09:48:48,947:INFO:Calculating mean and std
2023-07-10 09:48:48,948:INFO:Creating metrics dataframe
2023-07-10 09:48:49,081:INFO:Uploading results into container
2023-07-10 09:48:49,082:INFO:Uploading model into container now
2023-07-10 09:48:49,083:INFO:_master_model_container: 23
2023-07-10 09:48:49,083:INFO:_display_container: 2
2023-07-10 09:48:49,083:INFO:DummyRegressor()
2023-07-10 09:48:49,083:INFO:create_model() successfully completed......................................
2023-07-10 09:48:49,258:INFO:SubProcess create_model() end ==================================
2023-07-10 09:48:49,259:INFO:Creating metrics dataframe
2023-07-10 09:48:49,301:INFO:Initializing create_model()
2023-07-10 09:48:49,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fa66b6b76d0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:49,301:INFO:Checking exceptions
2023-07-10 09:48:49,305:INFO:Importing libraries
2023-07-10 09:48:49,305:INFO:Copying training dataset
2023-07-10 09:48:49,312:INFO:Defining folds
2023-07-10 09:48:49,312:INFO:Declaring metric variables
2023-07-10 09:48:49,313:INFO:Importing untrained model
2023-07-10 09:48:49,314:INFO:Declaring custom model
2023-07-10 09:48:49,314:INFO:CatBoost Regressor Imported successfully
2023-07-10 09:48:49,316:INFO:Cross validation set to False
2023-07-10 09:48:49,316:INFO:Fitting Model
2023-07-10 09:48:49,439:INFO:<catboost.core.CatBoostRegressor object at 0x7fa670865b20>
2023-07-10 09:48:49,439:INFO:create_model() successfully completed......................................
2023-07-10 09:48:49,613:INFO:Initializing create_model()
2023-07-10 09:48:49,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:49,614:INFO:Checking exceptions
2023-07-10 09:48:49,617:INFO:Importing libraries
2023-07-10 09:48:49,617:INFO:Copying training dataset
2023-07-10 09:48:49,623:INFO:Defining folds
2023-07-10 09:48:49,623:INFO:Declaring metric variables
2023-07-10 09:48:49,624:INFO:Importing untrained model
2023-07-10 09:48:49,624:INFO:Declaring custom model
2023-07-10 09:48:49,626:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 09:48:49,627:INFO:Cross validation set to False
2023-07-10 09:48:49,628:INFO:Fitting Model
2023-07-10 09:48:49,804:INFO:LGBMRegressor(random_state=123)
2023-07-10 09:48:49,804:INFO:create_model() successfully completed......................................
2023-07-10 09:48:49,981:INFO:Initializing create_model()
2023-07-10 09:48:49,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:49,981:INFO:Checking exceptions
2023-07-10 09:48:49,986:INFO:Importing libraries
2023-07-10 09:48:49,986:INFO:Copying training dataset
2023-07-10 09:48:49,993:INFO:Defining folds
2023-07-10 09:48:49,994:INFO:Declaring metric variables
2023-07-10 09:48:49,994:INFO:Importing untrained model
2023-07-10 09:48:49,995:INFO:Declaring custom model
2023-07-10 09:48:49,996:INFO:Extra Trees Regressor Imported successfully
2023-07-10 09:48:49,997:INFO:Cross validation set to False
2023-07-10 09:48:49,997:INFO:Fitting Model
2023-07-10 09:48:50,177:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 09:48:50,178:INFO:create_model() successfully completed......................................
2023-07-10 09:48:50,339:INFO:Initializing create_model()
2023-07-10 09:48:50,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:50,339:INFO:Checking exceptions
2023-07-10 09:48:50,343:INFO:Importing libraries
2023-07-10 09:48:50,343:INFO:Copying training dataset
2023-07-10 09:48:50,351:INFO:Defining folds
2023-07-10 09:48:50,351:INFO:Declaring metric variables
2023-07-10 09:48:50,352:INFO:Importing untrained model
2023-07-10 09:48:50,352:INFO:Declaring custom model
2023-07-10 09:48:50,354:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 09:48:50,356:INFO:Cross validation set to False
2023-07-10 09:48:50,356:INFO:Fitting Model
2023-07-10 09:48:50,573:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 09:48:50,573:INFO:create_model() successfully completed......................................
2023-07-10 09:48:50,732:INFO:Initializing create_model()
2023-07-10 09:48:50,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 09:48:50,733:INFO:Checking exceptions
2023-07-10 09:48:50,737:INFO:Importing libraries
2023-07-10 09:48:50,738:INFO:Copying training dataset
2023-07-10 09:48:50,744:INFO:Defining folds
2023-07-10 09:48:50,744:INFO:Declaring metric variables
2023-07-10 09:48:50,745:INFO:Importing untrained model
2023-07-10 09:48:50,745:INFO:Declaring custom model
2023-07-10 09:48:50,749:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 09:48:50,751:INFO:Cross validation set to False
2023-07-10 09:48:50,751:INFO:Fitting Model
2023-07-10 09:48:50,917:INFO:XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...)
2023-07-10 09:48:50,917:INFO:create_model() successfully completed......................................
2023-07-10 09:48:51,211:INFO:_master_model_container: 23
2023-07-10 09:48:51,212:INFO:_display_container: 2
2023-07-10 09:48:51,217:INFO:[<catboost.core.CatBoostRegressor object at 0x7fa670865b20>, LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123), XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...)]
2023-07-10 09:48:51,217:INFO:compare_models() successfully completed......................................
2023-07-10 09:48:52,072:INFO:Initializing plot_model()
2023-07-10 09:48:52,072:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7fa670865b20>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, system=True)
2023-07-10 09:48:52,073:INFO:Checking exceptions
2023-07-10 09:48:52,081:INFO:Preloading libraries
2023-07-10 09:48:52,084:INFO:Copying training dataset
2023-07-10 09:48:52,084:INFO:Plot type: feature_all
2023-07-10 09:48:52,113:WARNING:No coef_ found. Trying feature_importances_
2023-07-10 09:48:52,380:INFO:Visual Rendered Successfully
2023-07-10 09:48:52,555:INFO:plot_model() successfully completed......................................
2023-07-10 09:48:53,519:INFO:Initializing plot_model()
2023-07-10 09:48:53,519:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, system=True)
2023-07-10 09:48:53,520:INFO:Checking exceptions
2023-07-10 09:48:53,528:INFO:Preloading libraries
2023-07-10 09:48:53,542:INFO:Copying training dataset
2023-07-10 09:48:53,542:INFO:Plot type: feature_all
2023-07-10 09:48:53,577:WARNING:No coef_ found. Trying feature_importances_
2023-07-10 09:48:53,794:INFO:Visual Rendered Successfully
2023-07-10 09:48:53,962:INFO:plot_model() successfully completed......................................
2023-07-10 09:48:55,567:INFO:Initializing plot_model()
2023-07-10 09:48:55,567:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, system=True)
2023-07-10 09:48:55,567:INFO:Checking exceptions
2023-07-10 09:48:55,601:INFO:Preloading libraries
2023-07-10 09:48:55,630:INFO:Copying training dataset
2023-07-10 09:48:55,630:INFO:Plot type: feature_all
2023-07-10 09:48:55,677:WARNING:No coef_ found. Trying feature_importances_
2023-07-10 09:48:55,843:INFO:Visual Rendered Successfully
2023-07-10 09:48:56,005:INFO:plot_model() successfully completed......................................
2023-07-10 09:48:57,976:INFO:Initializing plot_model()
2023-07-10 09:48:57,976:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa66f0c8af0>, system=True)
2023-07-10 09:48:57,976:INFO:Checking exceptions
2023-07-10 09:48:57,985:INFO:Preloading libraries
2023-07-10 09:48:58,013:INFO:Copying training dataset
2023-07-10 09:48:58,013:INFO:Plot type: feature_all
2023-07-10 09:48:58,062:WARNING:No coef_ found. Trying feature_importances_
2023-07-10 09:48:58,316:INFO:Visual Rendered Successfully
2023-07-10 09:48:58,507:INFO:plot_model() successfully completed......................................
2023-07-10 09:55:17,969:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
960 fits failed out of a total of 960.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
960 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
TypeError: fit() got an unexpected keyword argument 'scoring'

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-10 09:55:17,976:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
  warnings.warn(

2023-07-10 10:14:51,016:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 187, in _parallel_build_trees
    tree.fit(X, y, sample_weight=sample_weight, check_input=False)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1315, in fit
    super().fit(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 250, in fit
    raise ValueError(
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 450, in fit
    trees = Parallel(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 446, in result
    return self.__get_result()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-10 10:14:51,027:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-20.66030647 -23.58241423 -27.69544518 -21.68434474 -23.48857033
 -28.81975982          nan -29.08935723 -27.5661795           nan]
  warnings.warn(

2023-07-10 10:21:02,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:02,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:02,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:02,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:16,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:16,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:16,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:16,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-10 10:21:29,670:INFO:PyCaret RegressionExperiment
2023-07-10 10:21:29,670:INFO:Logging name: reg-default-name
2023-07-10 10:21:29,670:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-10 10:21:29,670:INFO:version 3.0.4
2023-07-10 10:21:29,670:INFO:Initializing setup()
2023-07-10 10:21:29,670:INFO:self.USI: ad72
2023-07-10 10:21:29,670:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'fold_generator', 'X_test', 'gpu_n_jobs_param', 'pipeline', 'fold_shuffle_param', 'X_train', 'transform_target_param', 'memory', 'y_train', '_ml_usecase', 'n_jobs_param', 'target_param', 'data', 'log_plots_param', 'logging_param', 'USI', 'y', 'html_param', 'seed', 'exp_name_log', '_available_plots', 'fold_groups_param', 'y_test', 'idx', 'X'}
2023-07-10 10:21:29,670:INFO:Checking environment
2023-07-10 10:21:29,670:INFO:python_version: 3.9.12
2023-07-10 10:21:29,670:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-07-10 10:21:29,670:INFO:machine: x86_64
2023-07-10 10:21:29,670:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-10 10:21:29,670:INFO:Memory: svmem(total=17179869184, available=6723145728, percent=60.9, used=9651978240, free=563253248, active=6155919360, inactive=6133121024, wired=3496058880)
2023-07-10 10:21:29,671:INFO:Physical Core: 2
2023-07-10 10:21:29,671:INFO:Logical Core: 4
2023-07-10 10:21:29,671:INFO:Checking libraries
2023-07-10 10:21:29,671:INFO:System:
2023-07-10 10:21:29,671:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-07-10 10:21:29,671:INFO:executable: /Users/chinmayasukumar/opt/anaconda3/bin/python
2023-07-10 10:21:29,671:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-10 10:21:29,671:INFO:PyCaret required dependencies:
2023-07-10 10:21:29,673:INFO:                 pip: 21.2.4
2023-07-10 10:21:29,673:INFO:          setuptools: 60.10.0
2023-07-10 10:21:29,673:INFO:             pycaret: 3.0.4
2023-07-10 10:21:29,673:INFO:             IPython: 8.2.0
2023-07-10 10:21:29,673:INFO:          ipywidgets: 7.6.5
2023-07-10 10:21:29,673:INFO:                tqdm: 4.64.0
2023-07-10 10:21:29,673:INFO:               numpy: 1.22.4
2023-07-10 10:21:29,673:INFO:              pandas: 1.5.2
2023-07-10 10:21:29,673:INFO:              jinja2: 3.0.0
2023-07-10 10:21:29,673:INFO:               scipy: 1.7.3
2023-07-10 10:21:29,673:INFO:              joblib: 1.2.0
2023-07-10 10:21:29,673:INFO:             sklearn: 1.0.2
2023-07-10 10:21:29,673:INFO:                pyod: 1.0.9
2023-07-10 10:21:29,673:INFO:            imblearn: 0.9.1
2023-07-10 10:21:29,673:INFO:   category_encoders: 2.5.1.post0
2023-07-10 10:21:29,674:INFO:            lightgbm: 3.3.2
2023-07-10 10:21:29,674:INFO:               numba: 0.55.1
2023-07-10 10:21:29,674:INFO:            requests: 2.27.1
2023-07-10 10:21:29,674:INFO:          matplotlib: 3.5.1
2023-07-10 10:21:29,674:INFO:          scikitplot: 0.3.7
2023-07-10 10:21:29,674:INFO:         yellowbrick: 1.4
2023-07-10 10:21:29,674:INFO:              plotly: 5.6.0
2023-07-10 10:21:29,674:INFO:    plotly-resampler: Not installed
2023-07-10 10:21:29,674:INFO:             kaleido: 0.2.1
2023-07-10 10:21:29,674:INFO:           schemdraw: 0.15
2023-07-10 10:21:29,674:INFO:         statsmodels: 0.13.2
2023-07-10 10:21:29,674:INFO:              sktime: 0.17.0
2023-07-10 10:21:29,674:INFO:               tbats: 1.1.3
2023-07-10 10:21:29,674:INFO:            pmdarima: 2.0.1
2023-07-10 10:21:29,674:INFO:              psutil: 5.9.5
2023-07-10 10:21:29,674:INFO:          markupsafe: 2.0.1
2023-07-10 10:21:29,674:INFO:             pickle5: Not installed
2023-07-10 10:21:29,674:INFO:         cloudpickle: 2.0.0
2023-07-10 10:21:29,674:INFO:         deprecation: 2.1.0
2023-07-10 10:21:29,674:INFO:              xxhash: 3.2.0
2023-07-10 10:21:29,674:INFO:           wurlitzer: 3.0.2
2023-07-10 10:21:29,674:INFO:PyCaret optional dependencies:
2023-07-10 10:21:29,696:INFO:                shap: 0.41.0
2023-07-10 10:21:29,696:INFO:           interpret: Not installed
2023-07-10 10:21:29,696:INFO:                umap: 0.5.3
2023-07-10 10:21:29,696:INFO:    pandas_profiling: 3.2.0
2023-07-10 10:21:29,696:INFO:  explainerdashboard: Not installed
2023-07-10 10:21:29,696:INFO:             autoviz: 0.1.58
2023-07-10 10:21:29,696:INFO:           fairlearn: Not installed
2023-07-10 10:21:29,696:INFO:          deepchecks: Not installed
2023-07-10 10:21:29,696:INFO:             xgboost: 1.6.1
2023-07-10 10:21:29,696:INFO:            catboost: 1.0.6
2023-07-10 10:21:29,696:INFO:              kmodes: 0.12.1
2023-07-10 10:21:29,697:INFO:             mlxtend: 0.20.0
2023-07-10 10:21:29,697:INFO:       statsforecast: Not installed
2023-07-10 10:21:29,697:INFO:        tune_sklearn: Not installed
2023-07-10 10:21:29,697:INFO:                 ray: Not installed
2023-07-10 10:21:29,697:INFO:            hyperopt: Not installed
2023-07-10 10:21:29,697:INFO:              optuna: 3.2.0
2023-07-10 10:21:29,697:INFO:               skopt: Not installed
2023-07-10 10:21:29,697:INFO:              mlflow: 1.26.1
2023-07-10 10:21:29,697:INFO:              gradio: Not installed
2023-07-10 10:21:29,697:INFO:             fastapi: Not installed
2023-07-10 10:21:29,697:INFO:             uvicorn: Not installed
2023-07-10 10:21:29,697:INFO:              m2cgen: Not installed
2023-07-10 10:21:29,697:INFO:           evidently: Not installed
2023-07-10 10:21:29,697:INFO:               fugue: Not installed
2023-07-10 10:21:29,697:INFO:           streamlit: Not installed
2023-07-10 10:21:29,697:INFO:             prophet: Not installed
2023-07-10 10:21:29,697:INFO:None
2023-07-10 10:21:29,698:INFO:Set up data.
2023-07-10 10:21:29,706:INFO:Set up train/test split.
2023-07-10 10:21:29,710:INFO:Set up index.
2023-07-10 10:21:29,710:INFO:Set up folding strategy.
2023-07-10 10:21:29,710:INFO:Assigning column types.
2023-07-10 10:21:29,715:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-10 10:21:29,716:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-10 10:21:29,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 10:21:29,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 10:21:29,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:29,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:29,895:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:30,334:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:30,389:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-10 10:21:30,416:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 10:21:30,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 10:21:30,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:30,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:30,858:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:30,866:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:30,866:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-10 10:21:30,879:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 10:21:30,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,143:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:31,150:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:31,160:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,173:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,356:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:31,360:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:31,361:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-10 10:21:31,374:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,522:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:31,525:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:31,536:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,604:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,685:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,685:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:31,691:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:31,692:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-10 10:21:31,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:31,904:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:31,907:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:31,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:32,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-10 10:21:32,046:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:32,051:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:32,052:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-10 10:21:32,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:32,216:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:32,223:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:32,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-10 10:21:32,417:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:32,420:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:32,420:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-10 10:21:32,550:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:32,554:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:32,685:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:32,688:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:32,691:INFO:Preparing preprocessing pipeline...
2023-07-10 10:21:32,692:INFO:Set up simple imputation.
2023-07-10 10:21:32,693:INFO:Set up column name cleaning.
2023-07-10 10:21:32,717:INFO:Finished creating preprocessing pipeline.
2023-07-10 10:21:32,722:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/mh/9l7f5q2x0bsc05929xvm2nnh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['c', 'si', 'mn', 'p', 's', 'ni',
                                             'cr', 'mo', 'cu', 'v', 'al', 'n',
                                             'nb+ta', 'temp'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-10 10:21:32,723:INFO:Creating final display dataframe.
2023-07-10 10:21:32,795:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (618, 15)
4        Transformed data shape         (618, 15)
5   Transformed train set shape         (432, 15)
6    Transformed test set shape         (186, 15)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ad72
2023-07-10 10:21:32,962:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:32,966:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:33,196:INFO:Soft dependency imported: xgboost: 1.6.1
2023-07-10 10:21:33,200:INFO:Soft dependency imported: catboost: 1.0.6
2023-07-10 10:21:33,202:INFO:setup() successfully completed in 3.69s...............
2023-07-10 10:21:36,172:INFO:Initializing compare_models()
2023-07-10 10:21:36,172:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-10 10:21:36,174:INFO:Checking exceptions
2023-07-10 10:21:36,177:INFO:Preparing display monitor
2023-07-10 10:21:36,303:INFO:Initializing Linear Regression
2023-07-10 10:21:36,303:INFO:Total runtime is 8.900960286458334e-06 minutes
2023-07-10 10:21:36,310:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:36,311:INFO:Initializing create_model()
2023-07-10 10:21:36,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:36,312:INFO:Checking exceptions
2023-07-10 10:21:36,312:INFO:Importing libraries
2023-07-10 10:21:36,312:INFO:Copying training dataset
2023-07-10 10:21:36,321:INFO:Defining folds
2023-07-10 10:21:36,321:INFO:Declaring metric variables
2023-07-10 10:21:36,328:INFO:Importing untrained model
2023-07-10 10:21:36,338:INFO:Linear Regression Imported successfully
2023-07-10 10:21:36,353:INFO:Starting cross validation
2023-07-10 10:21:36,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:46,147:INFO:Calculating mean and std
2023-07-10 10:21:46,151:INFO:Creating metrics dataframe
2023-07-10 10:21:46,300:INFO:Uploading results into container
2023-07-10 10:21:46,301:INFO:Uploading model into container now
2023-07-10 10:21:46,302:INFO:_master_model_container: 1
2023-07-10 10:21:46,302:INFO:_display_container: 2
2023-07-10 10:21:46,302:INFO:LinearRegression(n_jobs=-1)
2023-07-10 10:21:46,302:INFO:create_model() successfully completed......................................
2023-07-10 10:21:46,411:INFO:SubProcess create_model() end ==================================
2023-07-10 10:21:46,412:INFO:Creating metrics dataframe
2023-07-10 10:21:46,426:INFO:Initializing Lasso Regression
2023-07-10 10:21:46,427:INFO:Total runtime is 0.16873155037562054 minutes
2023-07-10 10:21:46,434:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:46,435:INFO:Initializing create_model()
2023-07-10 10:21:46,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:46,436:INFO:Checking exceptions
2023-07-10 10:21:46,436:INFO:Importing libraries
2023-07-10 10:21:46,436:INFO:Copying training dataset
2023-07-10 10:21:46,444:INFO:Defining folds
2023-07-10 10:21:46,444:INFO:Declaring metric variables
2023-07-10 10:21:46,451:INFO:Importing untrained model
2023-07-10 10:21:46,458:INFO:Lasso Regression Imported successfully
2023-07-10 10:21:46,472:INFO:Starting cross validation
2023-07-10 10:21:46,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:47,687:INFO:Calculating mean and std
2023-07-10 10:21:47,689:INFO:Creating metrics dataframe
2023-07-10 10:21:47,828:INFO:Uploading results into container
2023-07-10 10:21:47,829:INFO:Uploading model into container now
2023-07-10 10:21:47,829:INFO:_master_model_container: 2
2023-07-10 10:21:47,829:INFO:_display_container: 2
2023-07-10 10:21:47,830:INFO:Lasso(random_state=123)
2023-07-10 10:21:47,830:INFO:create_model() successfully completed......................................
2023-07-10 10:21:47,919:INFO:SubProcess create_model() end ==================================
2023-07-10 10:21:47,919:INFO:Creating metrics dataframe
2023-07-10 10:21:47,936:INFO:Initializing Ridge Regression
2023-07-10 10:21:47,937:INFO:Total runtime is 0.19389871358871463 minutes
2023-07-10 10:21:47,945:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:47,946:INFO:Initializing create_model()
2023-07-10 10:21:47,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:47,946:INFO:Checking exceptions
2023-07-10 10:21:47,947:INFO:Importing libraries
2023-07-10 10:21:47,947:INFO:Copying training dataset
2023-07-10 10:21:47,956:INFO:Defining folds
2023-07-10 10:21:47,956:INFO:Declaring metric variables
2023-07-10 10:21:47,962:INFO:Importing untrained model
2023-07-10 10:21:47,971:INFO:Ridge Regression Imported successfully
2023-07-10 10:21:47,984:INFO:Starting cross validation
2023-07-10 10:21:47,986:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:54,249:INFO:Calculating mean and std
2023-07-10 10:21:54,251:INFO:Creating metrics dataframe
2023-07-10 10:21:54,391:INFO:Uploading results into container
2023-07-10 10:21:54,392:INFO:Uploading model into container now
2023-07-10 10:21:54,393:INFO:_master_model_container: 3
2023-07-10 10:21:54,393:INFO:_display_container: 2
2023-07-10 10:21:54,393:INFO:Ridge(random_state=123)
2023-07-10 10:21:54,394:INFO:create_model() successfully completed......................................
2023-07-10 10:21:54,488:INFO:SubProcess create_model() end ==================================
2023-07-10 10:21:54,488:INFO:Creating metrics dataframe
2023-07-10 10:21:54,504:INFO:Initializing Elastic Net
2023-07-10 10:21:54,504:INFO:Total runtime is 0.3033592502276103 minutes
2023-07-10 10:21:54,509:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:54,509:INFO:Initializing create_model()
2023-07-10 10:21:54,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:54,510:INFO:Checking exceptions
2023-07-10 10:21:54,510:INFO:Importing libraries
2023-07-10 10:21:54,511:INFO:Copying training dataset
2023-07-10 10:21:54,518:INFO:Defining folds
2023-07-10 10:21:54,518:INFO:Declaring metric variables
2023-07-10 10:21:54,524:INFO:Importing untrained model
2023-07-10 10:21:54,534:INFO:Elastic Net Imported successfully
2023-07-10 10:21:54,544:INFO:Starting cross validation
2023-07-10 10:21:54,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:55,977:INFO:Calculating mean and std
2023-07-10 10:21:55,981:INFO:Creating metrics dataframe
2023-07-10 10:21:56,117:INFO:Uploading results into container
2023-07-10 10:21:56,118:INFO:Uploading model into container now
2023-07-10 10:21:56,119:INFO:_master_model_container: 4
2023-07-10 10:21:56,119:INFO:_display_container: 2
2023-07-10 10:21:56,119:INFO:ElasticNet(random_state=123)
2023-07-10 10:21:56,119:INFO:create_model() successfully completed......................................
2023-07-10 10:21:56,213:INFO:SubProcess create_model() end ==================================
2023-07-10 10:21:56,214:INFO:Creating metrics dataframe
2023-07-10 10:21:56,229:INFO:Initializing Least Angle Regression
2023-07-10 10:21:56,230:INFO:Total runtime is 0.3321151693662008 minutes
2023-07-10 10:21:56,234:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:56,234:INFO:Initializing create_model()
2023-07-10 10:21:56,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:56,235:INFO:Checking exceptions
2023-07-10 10:21:56,235:INFO:Importing libraries
2023-07-10 10:21:56,235:INFO:Copying training dataset
2023-07-10 10:21:56,243:INFO:Defining folds
2023-07-10 10:21:56,243:INFO:Declaring metric variables
2023-07-10 10:21:56,249:INFO:Importing untrained model
2023-07-10 10:21:56,255:INFO:Least Angle Regression Imported successfully
2023-07-10 10:21:56,265:INFO:Starting cross validation
2023-07-10 10:21:56,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:56,376:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,391:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,400:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,409:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,707:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,781:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,796:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,826:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:56,972:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:57,049:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:57,517:INFO:Calculating mean and std
2023-07-10 10:21:57,519:INFO:Creating metrics dataframe
2023-07-10 10:21:57,650:INFO:Uploading results into container
2023-07-10 10:21:57,651:INFO:Uploading model into container now
2023-07-10 10:21:57,652:INFO:_master_model_container: 5
2023-07-10 10:21:57,652:INFO:_display_container: 2
2023-07-10 10:21:57,652:INFO:Lars(random_state=123)
2023-07-10 10:21:57,653:INFO:create_model() successfully completed......................................
2023-07-10 10:21:57,747:INFO:SubProcess create_model() end ==================================
2023-07-10 10:21:57,747:INFO:Creating metrics dataframe
2023-07-10 10:21:57,765:INFO:Initializing Lasso Least Angle Regression
2023-07-10 10:21:57,765:INFO:Total runtime is 0.35770678520202637 minutes
2023-07-10 10:21:57,770:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:57,770:INFO:Initializing create_model()
2023-07-10 10:21:57,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:57,771:INFO:Checking exceptions
2023-07-10 10:21:57,771:INFO:Importing libraries
2023-07-10 10:21:57,771:INFO:Copying training dataset
2023-07-10 10:21:57,781:INFO:Defining folds
2023-07-10 10:21:57,782:INFO:Declaring metric variables
2023-07-10 10:21:57,789:INFO:Importing untrained model
2023-07-10 10:21:57,797:INFO:Lasso Least Angle Regression Imported successfully
2023-07-10 10:21:57,807:INFO:Starting cross validation
2023-07-10 10:21:57,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:57,965:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,027:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,059:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,079:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,467:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,496:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,542:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,562:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,901:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:58,904:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-10 10:21:59,414:INFO:Calculating mean and std
2023-07-10 10:21:59,416:INFO:Creating metrics dataframe
2023-07-10 10:21:59,572:INFO:Uploading results into container
2023-07-10 10:21:59,572:INFO:Uploading model into container now
2023-07-10 10:21:59,573:INFO:_master_model_container: 6
2023-07-10 10:21:59,573:INFO:_display_container: 2
2023-07-10 10:21:59,574:INFO:LassoLars(random_state=123)
2023-07-10 10:21:59,574:INFO:create_model() successfully completed......................................
2023-07-10 10:21:59,673:INFO:SubProcess create_model() end ==================================
2023-07-10 10:21:59,674:INFO:Creating metrics dataframe
2023-07-10 10:21:59,692:INFO:Initializing Orthogonal Matching Pursuit
2023-07-10 10:21:59,692:INFO:Total runtime is 0.38982723553975424 minutes
2023-07-10 10:21:59,699:INFO:SubProcess create_model() called ==================================
2023-07-10 10:21:59,700:INFO:Initializing create_model()
2023-07-10 10:21:59,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:21:59,700:INFO:Checking exceptions
2023-07-10 10:21:59,701:INFO:Importing libraries
2023-07-10 10:21:59,701:INFO:Copying training dataset
2023-07-10 10:21:59,709:INFO:Defining folds
2023-07-10 10:21:59,709:INFO:Declaring metric variables
2023-07-10 10:21:59,719:INFO:Importing untrained model
2023-07-10 10:21:59,725:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-10 10:21:59,740:INFO:Starting cross validation
2023-07-10 10:21:59,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:21:59,847:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:21:59,871:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,023:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,046:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,503:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,512:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,637:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,667:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:00,936:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:01,021:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-10 10:22:02,122:INFO:Calculating mean and std
2023-07-10 10:22:02,140:INFO:Creating metrics dataframe
2023-07-10 10:22:02,483:INFO:Uploading results into container
2023-07-10 10:22:02,484:INFO:Uploading model into container now
2023-07-10 10:22:02,485:INFO:_master_model_container: 7
2023-07-10 10:22:02,486:INFO:_display_container: 2
2023-07-10 10:22:02,486:INFO:OrthogonalMatchingPursuit()
2023-07-10 10:22:02,486:INFO:create_model() successfully completed......................................
2023-07-10 10:22:02,599:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:02,599:INFO:Creating metrics dataframe
2023-07-10 10:22:02,620:INFO:Initializing Bayesian Ridge
2023-07-10 10:22:02,620:INFO:Total runtime is 0.43862369855244954 minutes
2023-07-10 10:22:02,630:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:02,632:INFO:Initializing create_model()
2023-07-10 10:22:02,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:02,632:INFO:Checking exceptions
2023-07-10 10:22:02,632:INFO:Importing libraries
2023-07-10 10:22:02,633:INFO:Copying training dataset
2023-07-10 10:22:02,642:INFO:Defining folds
2023-07-10 10:22:02,642:INFO:Declaring metric variables
2023-07-10 10:22:02,648:INFO:Importing untrained model
2023-07-10 10:22:02,656:INFO:Bayesian Ridge Imported successfully
2023-07-10 10:22:02,675:INFO:Starting cross validation
2023-07-10 10:22:02,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:04,492:INFO:Calculating mean and std
2023-07-10 10:22:04,494:INFO:Creating metrics dataframe
2023-07-10 10:22:04,765:INFO:Uploading results into container
2023-07-10 10:22:04,765:INFO:Uploading model into container now
2023-07-10 10:22:04,766:INFO:_master_model_container: 8
2023-07-10 10:22:04,766:INFO:_display_container: 2
2023-07-10 10:22:04,766:INFO:BayesianRidge()
2023-07-10 10:22:04,767:INFO:create_model() successfully completed......................................
2023-07-10 10:22:04,933:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:04,933:INFO:Creating metrics dataframe
2023-07-10 10:22:04,959:INFO:Initializing Passive Aggressive Regressor
2023-07-10 10:22:04,959:INFO:Total runtime is 0.47760963439941406 minutes
2023-07-10 10:22:04,965:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:04,965:INFO:Initializing create_model()
2023-07-10 10:22:04,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:04,966:INFO:Checking exceptions
2023-07-10 10:22:04,966:INFO:Importing libraries
2023-07-10 10:22:04,966:INFO:Copying training dataset
2023-07-10 10:22:04,977:INFO:Defining folds
2023-07-10 10:22:04,977:INFO:Declaring metric variables
2023-07-10 10:22:04,983:INFO:Importing untrained model
2023-07-10 10:22:04,994:INFO:Passive Aggressive Regressor Imported successfully
2023-07-10 10:22:05,014:INFO:Starting cross validation
2023-07-10 10:22:05,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:07,494:INFO:Calculating mean and std
2023-07-10 10:22:07,496:INFO:Creating metrics dataframe
2023-07-10 10:22:07,650:INFO:Uploading results into container
2023-07-10 10:22:07,651:INFO:Uploading model into container now
2023-07-10 10:22:07,651:INFO:_master_model_container: 9
2023-07-10 10:22:07,651:INFO:_display_container: 2
2023-07-10 10:22:07,652:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-10 10:22:07,652:INFO:create_model() successfully completed......................................
2023-07-10 10:22:07,742:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:07,748:INFO:Creating metrics dataframe
2023-07-10 10:22:07,771:INFO:Initializing Huber Regressor
2023-07-10 10:22:07,771:INFO:Total runtime is 0.5244666337966919 minutes
2023-07-10 10:22:07,777:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:07,777:INFO:Initializing create_model()
2023-07-10 10:22:07,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:07,778:INFO:Checking exceptions
2023-07-10 10:22:07,778:INFO:Importing libraries
2023-07-10 10:22:07,778:INFO:Copying training dataset
2023-07-10 10:22:07,790:INFO:Defining folds
2023-07-10 10:22:07,790:INFO:Declaring metric variables
2023-07-10 10:22:07,798:INFO:Importing untrained model
2023-07-10 10:22:07,806:INFO:Huber Regressor Imported successfully
2023-07-10 10:22:07,819:INFO:Starting cross validation
2023-07-10 10:22:07,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:09,485:INFO:Calculating mean and std
2023-07-10 10:22:09,488:INFO:Creating metrics dataframe
2023-07-10 10:22:09,678:INFO:Uploading results into container
2023-07-10 10:22:09,679:INFO:Uploading model into container now
2023-07-10 10:22:09,680:INFO:_master_model_container: 10
2023-07-10 10:22:09,680:INFO:_display_container: 2
2023-07-10 10:22:09,681:INFO:HuberRegressor()
2023-07-10 10:22:09,681:INFO:create_model() successfully completed......................................
2023-07-10 10:22:09,773:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:09,773:INFO:Creating metrics dataframe
2023-07-10 10:22:09,792:INFO:Initializing K Neighbors Regressor
2023-07-10 10:22:09,792:INFO:Total runtime is 0.5581582029660542 minutes
2023-07-10 10:22:09,797:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:09,797:INFO:Initializing create_model()
2023-07-10 10:22:09,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:09,798:INFO:Checking exceptions
2023-07-10 10:22:09,798:INFO:Importing libraries
2023-07-10 10:22:09,798:INFO:Copying training dataset
2023-07-10 10:22:09,807:INFO:Defining folds
2023-07-10 10:22:09,807:INFO:Declaring metric variables
2023-07-10 10:22:09,813:INFO:Importing untrained model
2023-07-10 10:22:09,821:INFO:K Neighbors Regressor Imported successfully
2023-07-10 10:22:09,830:INFO:Starting cross validation
2023-07-10 10:22:09,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:11,251:INFO:Calculating mean and std
2023-07-10 10:22:11,253:INFO:Creating metrics dataframe
2023-07-10 10:22:11,510:INFO:Uploading results into container
2023-07-10 10:22:11,511:INFO:Uploading model into container now
2023-07-10 10:22:11,511:INFO:_master_model_container: 11
2023-07-10 10:22:11,511:INFO:_display_container: 2
2023-07-10 10:22:11,512:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-10 10:22:11,512:INFO:create_model() successfully completed......................................
2023-07-10 10:22:11,631:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:11,632:INFO:Creating metrics dataframe
2023-07-10 10:22:11,659:INFO:Initializing Decision Tree Regressor
2023-07-10 10:22:11,660:INFO:Total runtime is 0.5892819682757059 minutes
2023-07-10 10:22:11,672:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:11,673:INFO:Initializing create_model()
2023-07-10 10:22:11,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:11,673:INFO:Checking exceptions
2023-07-10 10:22:11,674:INFO:Importing libraries
2023-07-10 10:22:11,674:INFO:Copying training dataset
2023-07-10 10:22:11,681:INFO:Defining folds
2023-07-10 10:22:11,682:INFO:Declaring metric variables
2023-07-10 10:22:11,692:INFO:Importing untrained model
2023-07-10 10:22:11,706:INFO:Decision Tree Regressor Imported successfully
2023-07-10 10:22:11,716:INFO:Starting cross validation
2023-07-10 10:22:11,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:12,955:INFO:Calculating mean and std
2023-07-10 10:22:12,957:INFO:Creating metrics dataframe
2023-07-10 10:22:13,093:INFO:Uploading results into container
2023-07-10 10:22:13,094:INFO:Uploading model into container now
2023-07-10 10:22:13,094:INFO:_master_model_container: 12
2023-07-10 10:22:13,094:INFO:_display_container: 2
2023-07-10 10:22:13,095:INFO:DecisionTreeRegressor(random_state=123)
2023-07-10 10:22:13,095:INFO:create_model() successfully completed......................................
2023-07-10 10:22:13,183:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:13,183:INFO:Creating metrics dataframe
2023-07-10 10:22:13,202:INFO:Initializing Random Forest Regressor
2023-07-10 10:22:13,202:INFO:Total runtime is 0.6149913311004638 minutes
2023-07-10 10:22:13,209:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:13,210:INFO:Initializing create_model()
2023-07-10 10:22:13,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:13,210:INFO:Checking exceptions
2023-07-10 10:22:13,210:INFO:Importing libraries
2023-07-10 10:22:13,210:INFO:Copying training dataset
2023-07-10 10:22:13,219:INFO:Defining folds
2023-07-10 10:22:13,220:INFO:Declaring metric variables
2023-07-10 10:22:13,225:INFO:Importing untrained model
2023-07-10 10:22:13,232:INFO:Random Forest Regressor Imported successfully
2023-07-10 10:22:13,242:INFO:Starting cross validation
2023-07-10 10:22:13,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:15,196:INFO:Calculating mean and std
2023-07-10 10:22:15,197:INFO:Creating metrics dataframe
2023-07-10 10:22:15,325:INFO:Uploading results into container
2023-07-10 10:22:15,326:INFO:Uploading model into container now
2023-07-10 10:22:15,326:INFO:_master_model_container: 13
2023-07-10 10:22:15,326:INFO:_display_container: 2
2023-07-10 10:22:15,327:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-10 10:22:15,327:INFO:create_model() successfully completed......................................
2023-07-10 10:22:15,415:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:15,415:INFO:Creating metrics dataframe
2023-07-10 10:22:15,434:INFO:Initializing Extra Trees Regressor
2023-07-10 10:22:15,434:INFO:Total runtime is 0.6521922985712686 minutes
2023-07-10 10:22:15,438:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:15,439:INFO:Initializing create_model()
2023-07-10 10:22:15,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:15,439:INFO:Checking exceptions
2023-07-10 10:22:15,440:INFO:Importing libraries
2023-07-10 10:22:15,440:INFO:Copying training dataset
2023-07-10 10:22:15,447:INFO:Defining folds
2023-07-10 10:22:15,448:INFO:Declaring metric variables
2023-07-10 10:22:15,453:INFO:Importing untrained model
2023-07-10 10:22:15,460:INFO:Extra Trees Regressor Imported successfully
2023-07-10 10:22:15,470:INFO:Starting cross validation
2023-07-10 10:22:15,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:17,078:INFO:Calculating mean and std
2023-07-10 10:22:17,081:INFO:Creating metrics dataframe
2023-07-10 10:22:17,210:INFO:Uploading results into container
2023-07-10 10:22:17,211:INFO:Uploading model into container now
2023-07-10 10:22:17,211:INFO:_master_model_container: 14
2023-07-10 10:22:17,211:INFO:_display_container: 2
2023-07-10 10:22:17,212:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 10:22:17,212:INFO:create_model() successfully completed......................................
2023-07-10 10:22:17,301:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:17,301:INFO:Creating metrics dataframe
2023-07-10 10:22:17,320:INFO:Initializing AdaBoost Regressor
2023-07-10 10:22:17,320:INFO:Total runtime is 0.6836174805959064 minutes
2023-07-10 10:22:17,324:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:17,325:INFO:Initializing create_model()
2023-07-10 10:22:17,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:17,325:INFO:Checking exceptions
2023-07-10 10:22:17,325:INFO:Importing libraries
2023-07-10 10:22:17,325:INFO:Copying training dataset
2023-07-10 10:22:17,333:INFO:Defining folds
2023-07-10 10:22:17,333:INFO:Declaring metric variables
2023-07-10 10:22:17,337:INFO:Importing untrained model
2023-07-10 10:22:17,346:INFO:AdaBoost Regressor Imported successfully
2023-07-10 10:22:17,357:INFO:Starting cross validation
2023-07-10 10:22:17,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:18,636:INFO:Calculating mean and std
2023-07-10 10:22:18,638:INFO:Creating metrics dataframe
2023-07-10 10:22:18,768:INFO:Uploading results into container
2023-07-10 10:22:18,769:INFO:Uploading model into container now
2023-07-10 10:22:18,770:INFO:_master_model_container: 15
2023-07-10 10:22:18,770:INFO:_display_container: 2
2023-07-10 10:22:18,770:INFO:AdaBoostRegressor(random_state=123)
2023-07-10 10:22:18,770:INFO:create_model() successfully completed......................................
2023-07-10 10:22:18,857:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:18,857:INFO:Creating metrics dataframe
2023-07-10 10:22:18,881:INFO:Initializing Gradient Boosting Regressor
2023-07-10 10:22:18,881:INFO:Total runtime is 0.7096417864163715 minutes
2023-07-10 10:22:18,888:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:18,888:INFO:Initializing create_model()
2023-07-10 10:22:18,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:18,889:INFO:Checking exceptions
2023-07-10 10:22:18,889:INFO:Importing libraries
2023-07-10 10:22:18,889:INFO:Copying training dataset
2023-07-10 10:22:18,895:INFO:Defining folds
2023-07-10 10:22:18,895:INFO:Declaring metric variables
2023-07-10 10:22:18,901:INFO:Importing untrained model
2023-07-10 10:22:18,910:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 10:22:18,921:INFO:Starting cross validation
2023-07-10 10:22:18,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:20,274:INFO:Calculating mean and std
2023-07-10 10:22:20,276:INFO:Creating metrics dataframe
2023-07-10 10:22:20,401:INFO:Uploading results into container
2023-07-10 10:22:20,402:INFO:Uploading model into container now
2023-07-10 10:22:20,402:INFO:_master_model_container: 16
2023-07-10 10:22:20,402:INFO:_display_container: 2
2023-07-10 10:22:20,403:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 10:22:20,403:INFO:create_model() successfully completed......................................
2023-07-10 10:22:20,493:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:20,494:INFO:Creating metrics dataframe
2023-07-10 10:22:20,516:INFO:Initializing Extreme Gradient Boosting
2023-07-10 10:22:20,516:INFO:Total runtime is 0.7368904511133828 minutes
2023-07-10 10:22:20,522:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:20,523:INFO:Initializing create_model()
2023-07-10 10:22:20,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:20,523:INFO:Checking exceptions
2023-07-10 10:22:20,523:INFO:Importing libraries
2023-07-10 10:22:20,523:INFO:Copying training dataset
2023-07-10 10:22:20,531:INFO:Defining folds
2023-07-10 10:22:20,531:INFO:Declaring metric variables
2023-07-10 10:22:20,536:INFO:Importing untrained model
2023-07-10 10:22:20,545:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 10:22:20,557:INFO:Starting cross validation
2023-07-10 10:22:20,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:21,971:INFO:Calculating mean and std
2023-07-10 10:22:21,973:INFO:Creating metrics dataframe
2023-07-10 10:22:22,142:INFO:Uploading results into container
2023-07-10 10:22:22,143:INFO:Uploading model into container now
2023-07-10 10:22:22,143:INFO:_master_model_container: 17
2023-07-10 10:22:22,143:INFO:_display_container: 2
2023-07-10 10:22:22,144:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2023-07-10 10:22:22,144:INFO:create_model() successfully completed......................................
2023-07-10 10:22:22,234:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:22,234:INFO:Creating metrics dataframe
2023-07-10 10:22:22,256:INFO:Initializing Light Gradient Boosting Machine
2023-07-10 10:22:22,256:INFO:Total runtime is 0.76589271624883 minutes
2023-07-10 10:22:22,264:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:22,265:INFO:Initializing create_model()
2023-07-10 10:22:22,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:22,265:INFO:Checking exceptions
2023-07-10 10:22:22,265:INFO:Importing libraries
2023-07-10 10:22:22,265:INFO:Copying training dataset
2023-07-10 10:22:22,275:INFO:Defining folds
2023-07-10 10:22:22,275:INFO:Declaring metric variables
2023-07-10 10:22:22,285:INFO:Importing untrained model
2023-07-10 10:22:22,293:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 10:22:22,308:INFO:Starting cross validation
2023-07-10 10:22:22,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:25,445:INFO:Calculating mean and std
2023-07-10 10:22:25,449:INFO:Creating metrics dataframe
2023-07-10 10:22:25,605:INFO:Uploading results into container
2023-07-10 10:22:25,606:INFO:Uploading model into container now
2023-07-10 10:22:25,607:INFO:_master_model_container: 18
2023-07-10 10:22:25,607:INFO:_display_container: 2
2023-07-10 10:22:25,607:INFO:LGBMRegressor(random_state=123)
2023-07-10 10:22:25,607:INFO:create_model() successfully completed......................................
2023-07-10 10:22:25,696:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:25,696:INFO:Creating metrics dataframe
2023-07-10 10:22:25,716:INFO:Initializing CatBoost Regressor
2023-07-10 10:22:25,716:INFO:Total runtime is 0.8235597332318623 minutes
2023-07-10 10:22:25,724:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:25,725:INFO:Initializing create_model()
2023-07-10 10:22:25,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:25,725:INFO:Checking exceptions
2023-07-10 10:22:25,725:INFO:Importing libraries
2023-07-10 10:22:25,725:INFO:Copying training dataset
2023-07-10 10:22:25,732:INFO:Defining folds
2023-07-10 10:22:25,733:INFO:Declaring metric variables
2023-07-10 10:22:25,739:INFO:Importing untrained model
2023-07-10 10:22:25,753:INFO:CatBoost Regressor Imported successfully
2023-07-10 10:22:25,771:INFO:Starting cross validation
2023-07-10 10:22:25,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:26,265:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,266:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,268:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,271:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,576:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,584:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,589:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,601:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,881:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:26,908:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,

2023-07-10 10:22:27,334:INFO:Calculating mean and std
2023-07-10 10:22:27,336:INFO:Creating metrics dataframe
2023-07-10 10:22:27,457:INFO:Uploading results into container
2023-07-10 10:22:27,458:INFO:Uploading model into container now
2023-07-10 10:22:27,458:INFO:_master_model_container: 19
2023-07-10 10:22:27,459:INFO:_display_container: 2
2023-07-10 10:22:27,459:INFO:<catboost.core.CatBoostRegressor object at 0x7f9b620aaf40>
2023-07-10 10:22:27,459:INFO:create_model() successfully completed......................................
2023-07-10 10:22:27,551:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:27,551:INFO:Creating metrics dataframe
2023-07-10 10:22:27,573:INFO:Initializing Dummy Regressor
2023-07-10 10:22:27,573:INFO:Total runtime is 0.8545001308123269 minutes
2023-07-10 10:22:27,578:INFO:SubProcess create_model() called ==================================
2023-07-10 10:22:27,578:INFO:Initializing create_model()
2023-07-10 10:22:27,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b5b5884f0>, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:27,579:INFO:Checking exceptions
2023-07-10 10:22:27,579:INFO:Importing libraries
2023-07-10 10:22:27,579:INFO:Copying training dataset
2023-07-10 10:22:27,587:INFO:Defining folds
2023-07-10 10:22:27,588:INFO:Declaring metric variables
2023-07-10 10:22:27,592:INFO:Importing untrained model
2023-07-10 10:22:27,600:INFO:Dummy Regressor Imported successfully
2023-07-10 10:22:27,611:INFO:Starting cross validation
2023-07-10 10:22:27,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-10 10:22:28,910:INFO:Calculating mean and std
2023-07-10 10:22:28,912:INFO:Creating metrics dataframe
2023-07-10 10:22:29,035:INFO:Uploading results into container
2023-07-10 10:22:29,036:INFO:Uploading model into container now
2023-07-10 10:22:29,036:INFO:_master_model_container: 20
2023-07-10 10:22:29,037:INFO:_display_container: 2
2023-07-10 10:22:29,037:INFO:DummyRegressor()
2023-07-10 10:22:29,037:INFO:create_model() successfully completed......................................
2023-07-10 10:22:29,126:INFO:SubProcess create_model() end ==================================
2023-07-10 10:22:29,126:INFO:Creating metrics dataframe
2023-07-10 10:22:29,172:INFO:Initializing create_model()
2023-07-10 10:22:29,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=<catboost.core.CatBoostRegressor object at 0x7f9b620aaf40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:29,174:INFO:Checking exceptions
2023-07-10 10:22:29,177:INFO:Importing libraries
2023-07-10 10:22:29,177:INFO:Copying training dataset
2023-07-10 10:22:29,181:INFO:Defining folds
2023-07-10 10:22:29,181:INFO:Declaring metric variables
2023-07-10 10:22:29,182:INFO:Importing untrained model
2023-07-10 10:22:29,182:INFO:Declaring custom model
2023-07-10 10:22:29,182:INFO:CatBoost Regressor Imported successfully
2023-07-10 10:22:29,183:INFO:Cross validation set to False
2023-07-10 10:22:29,183:INFO:Fitting Model
2023-07-10 10:22:29,312:INFO:<catboost.core.CatBoostRegressor object at 0x7f9b625cb220>
2023-07-10 10:22:29,312:INFO:create_model() successfully completed......................................
2023-07-10 10:22:29,410:INFO:Initializing create_model()
2023-07-10 10:22:29,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:29,411:INFO:Checking exceptions
2023-07-10 10:22:29,414:INFO:Importing libraries
2023-07-10 10:22:29,415:INFO:Copying training dataset
2023-07-10 10:22:29,421:INFO:Defining folds
2023-07-10 10:22:29,422:INFO:Declaring metric variables
2023-07-10 10:22:29,422:INFO:Importing untrained model
2023-07-10 10:22:29,423:INFO:Declaring custom model
2023-07-10 10:22:29,423:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-10 10:22:29,424:INFO:Cross validation set to False
2023-07-10 10:22:29,425:INFO:Fitting Model
2023-07-10 10:22:29,565:INFO:LGBMRegressor(random_state=123)
2023-07-10 10:22:29,565:INFO:create_model() successfully completed......................................
2023-07-10 10:22:29,674:INFO:Initializing create_model()
2023-07-10 10:22:29,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:29,674:INFO:Checking exceptions
2023-07-10 10:22:29,678:INFO:Importing libraries
2023-07-10 10:22:29,678:INFO:Copying training dataset
2023-07-10 10:22:29,684:INFO:Defining folds
2023-07-10 10:22:29,684:INFO:Declaring metric variables
2023-07-10 10:22:29,685:INFO:Importing untrained model
2023-07-10 10:22:29,685:INFO:Declaring custom model
2023-07-10 10:22:29,686:INFO:Extra Trees Regressor Imported successfully
2023-07-10 10:22:29,687:INFO:Cross validation set to False
2023-07-10 10:22:29,687:INFO:Fitting Model
2023-07-10 10:22:29,852:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-10 10:22:29,852:INFO:create_model() successfully completed......................................
2023-07-10 10:22:29,945:INFO:Initializing create_model()
2023-07-10 10:22:29,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:29,946:INFO:Checking exceptions
2023-07-10 10:22:29,950:INFO:Importing libraries
2023-07-10 10:22:29,951:INFO:Copying training dataset
2023-07-10 10:22:29,959:INFO:Defining folds
2023-07-10 10:22:29,959:INFO:Declaring metric variables
2023-07-10 10:22:29,960:INFO:Importing untrained model
2023-07-10 10:22:29,960:INFO:Declaring custom model
2023-07-10 10:22:29,961:INFO:Gradient Boosting Regressor Imported successfully
2023-07-10 10:22:29,961:INFO:Cross validation set to False
2023-07-10 10:22:29,961:INFO:Fitting Model
2023-07-10 10:22:30,163:INFO:GradientBoostingRegressor(random_state=123)
2023-07-10 10:22:30,163:INFO:create_model() successfully completed......................................
2023-07-10 10:22:30,265:INFO:Initializing create_model()
2023-07-10 10:22:30,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9b61bfaca0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-10 10:22:30,265:INFO:Checking exceptions
2023-07-10 10:22:30,268:INFO:Importing libraries
2023-07-10 10:22:30,269:INFO:Copying training dataset
2023-07-10 10:22:30,275:INFO:Defining folds
2023-07-10 10:22:30,275:INFO:Declaring metric variables
2023-07-10 10:22:30,276:INFO:Importing untrained model
2023-07-10 10:22:30,276:INFO:Declaring custom model
2023-07-10 10:22:30,278:INFO:Extreme Gradient Boosting Imported successfully
2023-07-10 10:22:30,279:INFO:Cross validation set to False
2023-07-10 10:22:30,279:INFO:Fitting Model
2023-07-10 10:22:30,418:INFO:XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...)
2023-07-10 10:22:30,418:INFO:create_model() successfully completed......................................
2023-07-10 10:22:30,558:INFO:_master_model_container: 20
2023-07-10 10:22:30,558:INFO:_display_container: 2
2023-07-10 10:22:30,562:INFO:[<catboost.core.CatBoostRegressor object at 0x7f9b625cb220>, LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123), XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,
             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
             importance_type=None, interaction_constraints='',
             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
             missing=nan, monotone_constraints='()', n_estimators=100,
             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=123,
             reg_alpha=0, reg_lambda=1, ...)]
2023-07-10 10:22:30,562:INFO:compare_models() successfully completed......................................
2023-07-10 10:51:19,105:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
50 fits failed out of a total of 250.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
50 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 187, in _parallel_build_trees
    tree.fit(X, y, sample_weight=sample_weight, check_input=False)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1315, in fit
    super().fit(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 250, in fit
    raise ValueError(
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 450, in fit
    trees = Parallel(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 446, in result
    return self.__get_result()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-10 10:51:19,108:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan -20.66118631 -19.49684263 -27.90043739          nan
 -32.76757212 -18.59103716 -28.89017125 -27.26428147 -28.89017125
 -21.65733231          nan -23.4568575           nan          nan
 -28.89017125 -21.59405831 -21.51984586 -18.93337186          nan
 -20.59981076          nan -20.36699304 -27.82361404 -22.29276834
 -31.32088295 -20.76073497 -29.19637867 -19.50322782          nan
 -20.77205402          nan -20.30331506          nan -20.36699304
 -29.17574547 -21.78355516 -20.89047407 -28.82319821 -29.04992972
 -23.40804301 -22.29276834 -29.33744142 -27.73957937 -23.4568575
 -21.59405831 -19.95438353 -29.08935723 -20.86345878 -23.48857033]
  warnings.warn(

2023-07-10 10:54:52,416:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
70 fits failed out of a total of 250.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
70 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 187, in _parallel_build_trees
    tree.fit(X, y, sample_weight=sample_weight, check_input=False)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 1315, in fit
    super().fit(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py", line 250, in fit
    raise ValueError(
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py", line 450, in fit
    trees = Parallel(
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 446, in result
    return self.__get_result()
  File "/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-07-10 10:54:52,419:WARNING:/Users/chinmayasukumar/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan -19.97157538          nan -20.58894311 -29.08935723
          nan          nan -20.66118631          nan          nan
 -23.58241423 -20.30722822 -20.03980338 -23.80630269 -27.7980383
          nan -27.51097005 -23.13904719 -20.12521243 -28.91083651
          nan          nan -29.59143858 -23.55816535 -18.83545676
 -29.19637867 -28.89017125 -29.08935723          nan -20.12555356
 -20.77205402          nan -21.61128186 -21.3534908  -28.89017125
          nan -28.91083651 -18.8401999  -20.7970203  -21.42605025
 -21.19229445 -19.65877248          nan -21.65733231 -29.19637867
          nan -23.53168457 -28.69259327 -21.04606927 -20.12555356]
  warnings.warn(

2023-07-12 09:44:12,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-12 09:44:12,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-12 09:44:12,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-12 09:44:12,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-12 09:51:37,674:INFO:Initializing load_model()
2023-07-12 09:51:37,683:INFO:load_model(model_name=/Users/chinmayasukumar/Documents/Capstone Projects/Capstone-2_Modelling_streel_strength/models/best_xt.h5, platform=None, authentication=None, verbose=True)
